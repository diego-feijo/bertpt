{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre-training ALBERT from scratch with cloud TPU - Wikipedia",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diego-feijo/bertpt/blob/master/Pre_training_ALBERT_from_scratch_with_cloud_TPU_Wikipedia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2XB_l-Hgzq_",
        "colab_type": "text"
      },
      "source": [
        "# Pre-training ALBERT from Wikipedia Dump"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZPgpRl5g2e2",
        "colab_type": "text"
      },
      "source": [
        "This notebook pre-trains an [ALBERT](https://github.com/google-research/ALBERT) model from Wikipedia dump using free Colab TPU v2.\n",
        "\n",
        "These are the steps to follow:\n",
        "\n",
        "1. Setting Up the Environment\n",
        "2. Download and Prepare Data\n",
        "3. Extract Raw Text\n",
        "4. Build SentencePiece Model\n",
        "5. Generate pre-training data\n",
        "6. Train the model\n",
        "\n",
        "As we will be using Colab TPU, it is required a [Google Cloud Storage bucket](https://cloud.google.com/tpu/docs/quickstart).  New users receive [$300 free credit](https://cloud.google.com/free/) for one year to get started with any GCP product. \n",
        "\n",
        "After each step, we save persistent data so we can always stop and resume from the last finished step.\n",
        "\n",
        "**Note** \n",
        "The only parameter you *really have to set* is BUCKET_NAME in steps 5 and 6. Everything else has default values which should work for most use-cases.\n",
        "\n",
        "**Note** \n",
        "Pre-training a ALBERT-Base model on a TPU v2 will take about 17 hours. Google Colab is not designed for executing such long-running jobs and will interrupt the training process every 8 hours or so. For uninterrupted training, consider using a preemptible TPUv2 instance. \n",
        "\n",
        "**Credits**\n",
        "This tutorial is adapted from https://towardsdatascience.com/pre-training-bert-from-scratch-with-cloud-tpu-6e2f71028379"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODimOhBR05yR",
        "colab_type": "text"
      },
      "source": [
        "MIT License\n",
        "\n",
        "Copyright (c) [2019] [Diego de Vargas Feijo]\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjad5jsr9YaM",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Setting Up the Environment\n",
        "Install dependencies, import globally required packages and authorize with Google Account to access Colab TPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S4CiOh3RzFW",
        "colab_type": "code",
        "outputId": "812c8cd5-1825-4e38-dd69-e98a31dac6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!pip install --upgrade -q sentencepiece\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import nltk\n",
        "import os\n",
        "import random\n",
        "import sentencepiece as spm\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from glob import glob\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "  \n",
        "# configure logging\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "\n",
        "# create formatter and add it to the handlers\n",
        "formatter = logging.Formatter('%(asctime)s:  %(message)s')\n",
        "sh = logging.StreamHandler()\n",
        "sh.setLevel(logging.INFO)\n",
        "sh.setFormatter(formatter)\n",
        "log.handlers = [sh]\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  log.info(\"Using TPU runtime\")\n",
        "  USE_TPU = True\n",
        "  TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(TPU_ADDRESS) as session:\n",
        "    log.info('TPU address is ' + TPU_ADDRESS)\n",
        "    # Upload credentials to TPU.\n",
        "    with open('/content/adc.json', 'r') as f:\n",
        "      auth_info = json.load(f)\n",
        "    tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "    \n",
        "else:\n",
        "  log.warning('Not connected to TPU runtime')\n",
        "  USE_TPU = False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 21.6MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 3.5MB/s \n",
            "\u001b[?25hWARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-09 19:16:48,080:  Using TPU runtime\n",
            "2019-12-09 19:16:48,082:  TPU address is grpc://10.80.30.250:8470\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j532CiG7iQSx",
        "colab_type": "text"
      },
      "source": [
        "Clone and Patch ALBERT sources\n",
        "\n",
        "Some Albert sources use deprecated API that generate a lot of warnings. We also make some minor changes to the scripts can run smoothly on Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b3TXHowYu-j",
        "colab_type": "code",
        "outputId": "60294eb2-2731-4efe-9856-712976da2f41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Clone the repository\n",
        "!test -d ALBERT || git clone https://github.com/google-research/ALBERT.git ALBERT\n",
        "\n",
        "# Avoid deprecated warnings\n",
        "!sed -i 's/tf.logging/tf.compat.v1.logging/' ALBERT/*.py\n",
        "!sed -i 's/tf.app.run/tf.compat.v1.app.run/' ALBERT/*.py\n",
        "\n",
        "# Avoid error when the line contains only one number\n",
        "!sed -i 's/i.lower()/str(i).lower()/' ALBERT/create_pretraining_data.py\n",
        "\n",
        "# Create Dummy flag (Colab Bug)\n",
        "!sed -i 's/FLAGS = flags.FLAGS/FLAGS=flags.FLAGS\\n\\nflags.DEFINE_string(\"f\", \"\", \"Dummy flag. Not used.\")/' ALBERT/run_pretraining.py\n",
        "\n",
        "# Mute too verbose output\n",
        "!sed -i 's/tf.compat.v1.logging.info/# tf.compat.v1.logging.info/' ALBERT/tokenization.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ALBERT'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 56 (delta 28), reused 37 (delta 9), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptsoXM_qgtms",
        "colab_type": "code",
        "outputId": "ec379eef-41c9-4928-ac02-1795b864d8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if not 'ALBERT' in sys.path:\n",
        "  sys.path += ['ALBERT']\n",
        "\n",
        "import modeling, optimization, tokenization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-09 19:16:57,732:  From ALBERT/lamb_optimizer.py:33: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGVXMoC-aMy1",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Download and Prepare Data\n",
        "\n",
        "Wikipedia dump is available in XML format. We need to extract the raw text from it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0PSBfMurgxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LANG = \"pt\"  #@param ['en', 'es', 'it', 'fr', 'pt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxW6d4o0dN4j",
        "colab_type": "text"
      },
      "source": [
        "The latest Wikipedia dump can be from the day 1 or 20, but the date when dump is finished can vary. Instead of complicated inspecting in the page, we are guessing when the dump is ready."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHZU9byCnj72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "\n",
        "def get_last_dump():\n",
        "  today = datetime.datetime.now()\n",
        "\n",
        "  if today.day > 8 and today.day < 25:\n",
        "    day = 1\n",
        "    month = today.month\n",
        "  elif today.day >= 25:\n",
        "    day = 20\n",
        "    month = today.month\n",
        "  else:\n",
        "    day = 1\n",
        "    month = today.month - 1\n",
        "  return '{}{:02d}{:02d}'.format(today.year, month, day)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEOzdsF9k5uH",
        "colab_type": "code",
        "outputId": "d4e601d3-6e07-4d6f-c225-3d6a430e91ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "last_dump = get_last_dump()\n",
        "corpus = tf.keras.utils.get_file(\n",
        "    \"{}wiki.bz2\".format(LANG),\n",
        "    \"https://dumps.wikimedia.org/{}wiki/{}/{}wiki-{}-pages-articles-multistream.xml.bz2\".format(\n",
        "        LANG,\n",
        "        last_dump,\n",
        "        LANG,\n",
        "        last_dump\n",
        "    ))\n",
        "!bzip2 -d {corpus}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://dumps.wikimedia.org/ptwiki/20191201/ptwiki-20191201-pages-articles-multistream.xml.bz2\n",
            "1782988800/1782983972 [==============================] - 861s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0c7tasirPFL",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Extract Raw Text\n",
        "Uses WikiExtractor to remove XML tags and keep only raw text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLaXliDWldgB",
        "colab_type": "code",
        "outputId": "3597e84c-092a-42a8-ce49-0d75ab99d348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!test -d wikiextractor || git clone https://github.com/attardi/wikiextractor.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'wikiextractor'...\n",
            "remote: Enumerating objects: 607, done.\u001b[K\n",
            "Receiving objects:   0% (1/607)   \rReceiving objects:   1% (7/607)   \rReceiving objects:   2% (13/607)   \rReceiving objects:   3% (19/607)   \rReceiving objects:   4% (25/607)   \rReceiving objects:   5% (31/607)   \rReceiving objects:   6% (37/607)   \rReceiving objects:   7% (43/607)   \rReceiving objects:   8% (49/607)   \rReceiving objects:   9% (55/607)   \rReceiving objects:  10% (61/607)   \rReceiving objects:  11% (67/607)   \rReceiving objects:  12% (73/607)   \rReceiving objects:  13% (79/607)   \rReceiving objects:  14% (85/607)   \rReceiving objects:  15% (92/607)   \rReceiving objects:  16% (98/607)   \rReceiving objects:  17% (104/607)   \rReceiving objects:  18% (110/607)   \rReceiving objects:  19% (116/607)   \rReceiving objects:  20% (122/607)   \rReceiving objects:  21% (128/607)   \rReceiving objects:  22% (134/607)   \rReceiving objects:  23% (140/607)   \rReceiving objects:  24% (146/607)   \rReceiving objects:  25% (152/607)   \rReceiving objects:  26% (158/607)   \rReceiving objects:  27% (164/607)   \rReceiving objects:  28% (170/607)   \rReceiving objects:  29% (177/607)   \rReceiving objects:  30% (183/607)   \rReceiving objects:  31% (189/607)   \rReceiving objects:  32% (195/607)   \rReceiving objects:  33% (201/607)   \rReceiving objects:  34% (207/607)   \rReceiving objects:  35% (213/607)   \rReceiving objects:  36% (219/607)   \rReceiving objects:  37% (225/607)   \rReceiving objects:  38% (231/607)   \rReceiving objects:  39% (237/607)   \rReceiving objects:  40% (243/607)   \rReceiving objects:  41% (249/607)   \rReceiving objects:  42% (255/607)   \rReceiving objects:  43% (262/607)   \rReceiving objects:  44% (268/607)   \rReceiving objects:  45% (274/607)   \rReceiving objects:  46% (280/607)   \rReceiving objects:  47% (286/607)   \rReceiving objects:  48% (292/607)   \rReceiving objects:  49% (298/607)   \rReceiving objects:  50% (304/607)   \rReceiving objects:  51% (310/607)   \rReceiving objects:  52% (316/607)   \rReceiving objects:  53% (322/607)   \rReceiving objects:  54% (328/607)   \rReceiving objects:  55% (334/607)   \rReceiving objects:  56% (340/607)   \rReceiving objects:  57% (346/607)   \rReceiving objects:  58% (353/607)   \rReceiving objects:  59% (359/607)   \rReceiving objects:  60% (365/607)   \rReceiving objects:  61% (371/607)   \rReceiving objects:  62% (377/607)   \rReceiving objects:  63% (383/607)   \rReceiving objects:  64% (389/607)   \rReceiving objects:  65% (395/607)   \rReceiving objects:  66% (401/607)   \rReceiving objects:  67% (407/607)   \rReceiving objects:  68% (413/607)   \rReceiving objects:  69% (419/607)   \rReceiving objects:  70% (425/607)   \rReceiving objects:  71% (431/607)   \rReceiving objects:  72% (438/607)   \rReceiving objects:  73% (444/607)   \rReceiving objects:  74% (450/607)   \rReceiving objects:  75% (456/607)   \rReceiving objects:  76% (462/607)   \rReceiving objects:  77% (468/607)   \rReceiving objects:  78% (474/607)   \rReceiving objects:  79% (480/607)   \rReceiving objects:  80% (486/607)   \rReceiving objects:  81% (492/607)   \rReceiving objects:  82% (498/607)   \rReceiving objects:  83% (504/607)   \rReceiving objects:  84% (510/607)   \rremote: Total 607 (delta 0), reused 0 (delta 0), pack-reused 607\u001b[K\n",
            "Receiving objects:  85% (516/607)   \rReceiving objects:  86% (523/607)   \rReceiving objects:  87% (529/607)   \rReceiving objects:  88% (535/607)   \rReceiving objects:  89% (541/607)   \rReceiving objects:  90% (547/607)   \rReceiving objects:  91% (553/607)   \rReceiving objects:  92% (559/607)   \rReceiving objects:  93% (565/607)   \rReceiving objects:  94% (571/607)   \rReceiving objects:  95% (577/607)   \rReceiving objects:  96% (583/607)   \rReceiving objects:  97% (589/607)   \rReceiving objects:  98% (595/607)   \rReceiving objects:  99% (601/607)   \rReceiving objects: 100% (607/607)   \rReceiving objects: 100% (607/607), 1.21 MiB | 9.19 MiB/s, done.\n",
            "Resolving deltas:   0% (0/348)   \rResolving deltas:   2% (8/348)   \rResolving deltas:   4% (15/348)   \rResolving deltas:   9% (34/348)   \rResolving deltas:  26% (92/348)   \rResolving deltas:  27% (95/348)   \rResolving deltas:  28% (98/348)   \rResolving deltas:  37% (131/348)   \rResolving deltas:  44% (156/348)   \rResolving deltas:  47% (166/348)   \rResolving deltas:  50% (175/348)   \rResolving deltas:  52% (182/348)   \rResolving deltas:  53% (185/348)   \rResolving deltas:  54% (190/348)   \rResolving deltas:  55% (192/348)   \rResolving deltas:  58% (203/348)   \rResolving deltas:  82% (286/348)   \rResolving deltas:  85% (296/348)   \rResolving deltas:  86% (301/348)   \rResolving deltas:  87% (303/348)   \rResolving deltas:  88% (309/348)   \rResolving deltas:  93% (327/348)   \rResolving deltas: 100% (348/348)   \rResolving deltas: 100% (348/348), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEDAwhI5lzgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WIKI_INPUT_FILE, _ = os.path.splitext(corpus)\n",
        "WIKI_EXTRACTED_DIR = \"wikimedia\" \n",
        "\n",
        "tf.io.gfile.makedirs(WIKI_EXTRACTED_DIR)\n",
        "!python3 wikiextractor/WikiExtractor.py -q -c -o {WIKI_EXTRACTED_DIR} {WIKI_INPUT_FILE}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzgKtLGjEIYb",
        "colab_type": "code",
        "outputId": "c6d6034a-2c49-4eee-8b64-7722a5f0e571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Snowball Stemmers\n",
        "LANG_STM = \"portuguese\" # @param ['danish', 'english', 'finnish', 'french', 'german', 'hugarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish']\n",
        "\n",
        "sent_tokenizer = nltk.data.load('tokenizers/punkt/{}.pickle'.format(LANG_STM))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY-Kvnx6sUFS",
        "colab_type": "text"
      },
      "source": [
        "Prepare input for create_pretraining_data script.\n",
        "\n",
        "Input file format requires:\n",
        "- One sentence per line. These should ideally be actual sentences, not entire paragraphs or arbitrary spans of text. (Because we use the sentence boundaries for the \"next sentence prediction\" task).\n",
        "- Blank lines between documents. Document boundaries are needed so that the \"next sentence prediction\" task doesn't span between documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr9Rau_WEbpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bz2\n",
        "\n",
        "PRC_DATA_FPATH = \"proc_wikimedia.txt\" #@param {type: \"string\"}\n",
        "\n",
        "with open(PRC_DATA_FPATH, \"w\", encoding=\"utf-8\") as fo:\n",
        "  for group in os.listdir(WIKI_EXTRACTED_DIR):\n",
        "    basedir = os.path.join(WIKI_EXTRACTED_DIR, group)\n",
        "    for fz in os.listdir(basedir):\n",
        "      if fz.endswith('.bz2'):\n",
        "        with bz2.BZ2File(os.path.join(basedir, fz), 'r') as fi:\n",
        "          contents = fi.read()\n",
        "        is_title = False\n",
        "        text = contents.decode('utf-8')\n",
        "        for l in text.splitlines():\n",
        "          # print (l)\n",
        "          if l.startswith('</doc>'):\n",
        "            # Empty line for each new document\n",
        "            fo.write(\"\\n\")\n",
        "          elif len(l) == 1:\n",
        "            # Empty lines must be ignored\n",
        "            pass\n",
        "          elif l.startswith('<doc'):\n",
        "            # After the heading, there is a title\n",
        "            is_title = True\n",
        "          elif is_title:\n",
        "            # Ignore this line, reset variable\n",
        "            is_title = False\n",
        "          else:\n",
        "            # Wikipedia uses multiple sentences in on line\n",
        "            # We need to split one sentence per line\n",
        "            sentences = sent_tokenizer.tokenize(l)\n",
        "            for sentence in sentences:\n",
        "              fo.write(sentence + \"\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e49ef20e-b0d1-4040-9f9d-1a778eebff29",
        "id": "FfBamX6BHfDD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "BUCKET_NAME = \"<Insert Bucket Name Here>\" # @param string\n",
        "\n",
        "!head {PRC_DATA_FPATH}\n",
        "!test -f {PRC_DATA_FPATH}.gz || gzip < {PRC_DATA_FPATH} > {PRC_DATA_FPATH}.gz\n",
        "tf.gfile.MakeDirs(\"gs://{}/datasets/\".format(BUCKET_NAME))\n",
        "!gsutil -m cp {PRC_DATA_FPATH}.gz gs://{BUCKET_NAME}/datasets/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O termo Stock Car refere-se a uma forma de corrida automobilística popular principalmente nos Estados Unidos, no Canadá, no México, na Grã-Bretanha, na Austrália, no Brasil, entre outros países.\n",
            "Os \"Stock Cars\" em seu senso original descrevem um automóvel de passeio usado em competições que não possui modificações especiais para corrida.\n",
            "Posteriormente passaram a ser carros de passeios modificados para corridas.\n",
            "Atualmente, muitas categorias usam carros especiais feitos exclusivamente para as corridas, mas mantendo o design parecido com os carros de passeio, ao contrário dos carros de monoposto, com pneus a mostra.\n",
            "Atualmente, as corridas de Stock Cars são considerados como sendo uma categoria das corridas de turismo.\n",
            "Também chamado de \"street stock\", são os veículos que podem ser comprados pelo público em geral, os chamados carros de produção, geralmente somente modificações por questões de segurança são permitidas nesses modelos.\n",
            "Semelhantes ao \"pure stock\", mas com permissão de modificação nos motores e nos pneus.\n",
            "\"Late models\" são a mais alta classe dos stock cars, geralmente feitos com chassi tubular e motores próprios.\n",
            "A maior associação de stock cars do mundo é a NASCAR nos Estados Unidos, possui 3 categorias principais (Cup Series, Xfinity Series e Truck Series) e várias categorias regionais e locais (as chamadas Home Tracks) como a Pro Series East e Pro Series West, a Modified Tour, a All-American Series, categorias que correm em mais de 30 etapas ao longo do ano, correndo em sua maior parte em circuitos ovais.\n",
            "No México, existe a Corona Series, categoria de propriedade da NASCAR americana, consistindo também, em sua maioria, em circuitos ovais, no Canadá a Canada Series e na Europa a Europe Series.\n",
            "Copying file://proc_wikimedia.txt.gz [Content-Type=text/plain]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "-\n",
            "Operation completed over 1 objects/550.1 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVO9EnUwrluQ",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Build SentencePiece Model\n",
        "In this step we will be generating the config files and the encoder to covert text to integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUPhcVtlT_Hb",
        "colab_type": "code",
        "outputId": "6e6ce728-f4e5-4112-bf78-61161a4fc4aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "BUCKET_NAME = \"<Insert Bucket Name Here>\" # @param {type: \"string\"}\n",
        "\n",
        "MODEL_DIR = \"albert_cased_L-12_H-768_A-12\" #@param {type: \"string\"}\n",
        "VOC_SIZE = 30000 #@param {type:\"integer\"}\n",
        "\n",
        "!test -f {PRC_DATA_FPATH}.gz || gsutil -m cp gs://{BUCKET_NAME}/datasets/{PRC_DATA_FPATH}.gz .\n",
        "!test -f {PRC_DATA_FPATH} || gzip -d < {PRC_DATA_FPATH}.gz > {PRC_DATA_FPATH}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://diego-feijo_datasets/datasets/proc_wikimedia.txt.gz...\n",
            "/ [1/1 files][550.1 MiB/550.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/550.1 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YigCcV-hSHVH",
        "colab_type": "text"
      },
      "source": [
        "Build ALBERT Configuration Base model:\n",
        "- Base Model: https://tfhub.dev/google/albert_base/2\n",
        "- Large Model: https://tfhub.dev/google/albert_large/2\n",
        "- X-Large Model: https://tfhub.dev/google/albert_xlarge/2\n",
        "- XX-Large Model: https://tfhub.dev/google/albert_xxlarge/2\n",
        "\n",
        "It is not feasible to create pre-training data for models bigger than Large using Colab. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEpSGpUKReKW",
        "colab_type": "code",
        "outputId": "31752bcd-1b7a-4d88-bb6f-62765e474587",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# use this for ALBERT-base\n",
        "albert_config = {\n",
        "  \"attention_probs_dropout_prob\": 0.1, \n",
        "  \"hidden_act\": \"gelu\", \n",
        "  \"hidden_dropout_prob\": 0.1, \n",
        "  \"embedding_size\": 128,\n",
        "  \"hidden_size\": 768, \n",
        "  \"initializer_range\": 0.02, \n",
        "  \"intermediate_size\": 3072, \n",
        "  \"max_position_embeddings\": 512, \n",
        "  \"num_attention_heads\": 12,\n",
        "  \"num_hidden_layers\": 12,\n",
        "  \"num_hidden_groups\": 1,\n",
        "  \"net_structure_type\": 0,\n",
        "  \"gap_size\": 0, \n",
        "  \"num_memory_blocks\": 0, \n",
        "  \"inner_group_num\": 1,\n",
        "  \"down_scale_factor\": 1,\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"vocab_size\": VOC_SIZE\n",
        "}\n",
        "\n",
        "with open(\"albert_config.json\", \"w\") as fo:\n",
        "  json.dump(albert_config, fo, indent=2)\n",
        "!gsutil -m cp albert_config.json gs://{BUCKET_NAME}/{MODEL_DIR}/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://albert_config.json [Content-Type=application/json]...\n",
            "/ [1/1 files][  483.0 B/  483.0 B] 100% Done                                    \n",
            "Operation completed over 1 objects/483.0 B.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8WA6AmImJeK",
        "colab_type": "text"
      },
      "source": [
        "[SentencePiece](https://github.com/google/sentencepiece) will be used to encode the text.\n",
        "\n",
        "We need to train the SentencePiece model and build our vocabulary. It is required a lot of RAM. Even 35GB RAM offered by Colab may not be enough if all the raw text is used. We use SUBSAMPLE_SIZE to control how much memory is used.\n",
        "\n",
        "In case of Out of Memory, it is possible to reduce SUBSAMPLE_SIZE.\n",
        "\n",
        "The VOC_SIZE used by monolingual BERT and ALBERT papers are 30000. The multilingual uses 129000 tokens. It is not clear if increasing the VOC_SIZE will improve the model.\n",
        "\n",
        "NUM_PLACEHOLDERS can be used after the pre-training during the fine-tunning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doUwCk-oT4Em",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRC_DATA_FPATH = \"proc_wikimedia.txt\"  #@param {type: \"string\"}\n",
        "MODEL_PREFIX = 'tokenizer' #@param {type:\"string\"}\n",
        "SUBSAMPLE_SIZE = 10000000 #@param {type:\"integer\"}\n",
        "# Number of reserved tokens at end of vocabulary\n",
        "# This should only be used when training data contains a small but very\n",
        "# frequent tokens.\n",
        "NUM_PLACEHOLDERS = 0 #@param {type:\"integer\"}\n",
        "\n",
        "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
        "               '--vocab_size={} --input_sentence_size={} '\n",
        "               '--shuffle_input_sentence=true ' \n",
        "               '--pad_piece=[PAD] '\n",
        "               '--unk_piece=[UNK] '\n",
        "               '--pad_id=0 --unk_id=1 --user_defined_symbols=[CLS],[SEP],[MASK] ' \n",
        "               '--bos_id=-1 --eos_id=-1 ').format(\n",
        "               PRC_DATA_FPATH, MODEL_PREFIX, \n",
        "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfIXHcpCP3ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEMO_MODE = True # @param {type: \"boolean\"}\n",
        "\n",
        "# Reduce the number of lines to train faster\n",
        "if DEMO_MODE:\n",
        "  !head -1000000 {PRC_DATA_FPATH} > {PRC_DATA_FPATH}.tmp\n",
        "  !mv {PRC_DATA_FPATH}.tmp {PRC_DATA_FPATH}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh9yz4DMj1fr",
        "colab_type": "text"
      },
      "source": [
        "This training can take a while. Grab a coffee."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18nn6eW_s-fV",
        "colab_type": "code",
        "outputId": "2cbe8a4e-45ea-4b4e-b330-96a4faa2c07f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "spm.SentencePieceTrainer.Train(SPM_COMMAND)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzahx55mFwmL",
        "colab_type": "code",
        "outputId": "f0d36e95-88e7-4048-cf10-5bde91244a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!test -f {MODEL_PREFIX}.tar.gz && rm {MODEL_PREFIX}.tar.gz\n",
        "!tar czvf {MODEL_PREFIX}.tar.gz {MODEL_PREFIX}.*\n",
        "tf.gfile.MakeDirs(\"gs://{}/{}/\".format(BUCKET_NAME, MODEL_DIR))\n",
        "!gsutil -m cp {MODEL_PREFIX}.tar.gz gs://{BUCKET_NAME}/{MODEL_DIR}/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenizer.model\n",
            "tokenizer.vocab\n",
            "Copying file://tokenizer.tar.gz [Content-Type=application/x-tar]...\n",
            "/ [1/1 files][575.0 KiB/575.0 KiB] 100% Done                                    \n",
            "Operation completed over 1 objects/575.0 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAowCoH2u1iZ",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how we can make SentencePiece tokenizer work for the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYlBqiv5UD-j",
        "colab_type": "text"
      },
      "source": [
        "SentencePiece has created two files: tokenizer.model and tokenizer.vocab. Let's have a look at the learned vocabulary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDJ9QmNMUEQf",
        "colab_type": "code",
        "outputId": "03527267-c443-4c25-e4ec-977f04a511e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "VOC_FNAME = \"{}.vocab\".format(MODEL_PREFIX)\n",
        "MDL_FNAME = \"{}.model\".format(MODEL_PREFIX)\n",
        "\n",
        "!head {VOC_FNAME}\n",
        "!wc -l {VOC_FNAME}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD]\t0\n",
            "[UNK]\t0\n",
            "[CLS]\t0\n",
            "[SEP]\t0\n",
            "[MASK]\t0\n",
            ",\t-3.0199\n",
            "▁de\t-3.14827\n",
            ".\t-3.52606\n",
            "▁a\t-3.82674\n",
            "▁e\t-3.85135\n",
            "30000 tokenizer.vocab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MqXZnc3FCuY",
        "colab_type": "text"
      },
      "source": [
        "Now let's see how the new vocabulary works in practice:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsSOnEnC-jG1",
        "colab_type": "code",
        "outputId": "d16331b9-70a2-4cf8-8759-783181daa0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "testcase = \"[CLS] [MASK] Sentença de mérito. [SEP] Embargos de declaração 普通话.[SEP]\"\n",
        "\n",
        "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME, do_lower_case=False, spm_model_file=MDL_FNAME)\n",
        "tokens = bert_tokenizer.tokenize(testcase)\n",
        "ids = bert_tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(tokens)\n",
        "print(ids)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁', '[CLS]', '▁', '[MASK]', '▁Se', 'nte', 'nça', '▁de', '▁mérito', '.', '▁', '[SEP]', '▁Em', 'bar', 'gos', '▁de', '▁declaração', '▁', '普通话', '.', '[SEP]']\n",
            "[19, 2, 19, 4, 332, 291, 2601, 6, 10323, 7, 19, 3, 43, 2466, 3362, 6, 5711, 19, 1, 7, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DauD8ndhEA-z",
        "colab_type": "text"
      },
      "source": [
        "Looking good!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwFtStCo__QX",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Generate Pre-training Data\n",
        "Pre-training data is a collection of tfrecord files containing replacing the text by its encoded ids, masking and setting if one sentence follows the other.\n",
        "\n",
        "So, a text:\n",
        "\n",
        "- \"This is just one of many samples. This a sentence that follows. \" \n",
        "\n",
        "would be converted to:\n",
        "- \"\\[CLS\\] \\[SEP\\] 23 45 \\[MASK\\] ... \\[SEP\\] 67 89 ... \\[PAD\\] \\[PAD\\]\"\n",
        "\n",
        "\n",
        "SentencePiece model is used to encode text into Ids. The create_pretraining_data will append special tokens ('\\[CLS\\]', '\\[SEP\\]', '\\[UNK\\]', '\\[PAD\\]')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHWl4SD6boUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUCKET_NAME = \"<Insert Bucket Name Here>\" # @param {type: \"string\"}\n",
        "\n",
        "MODEL_DIR = 'albert_cased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "MODEL_PREFIX = 'tokenizer' #@param {type:\"string\"}\n",
        "VOC_FNAME = \"{}.vocab\".format(MODEL_PREFIX)\n",
        "MDL_FNAME = \"{}.model\".format(MODEL_PREFIX)\n",
        "PRC_DATA_FPATH = \"proc_wikimedia.txt\" #@param {type:\"string\"}\n",
        "\n",
        "!test -f {PRC_DATA_FPATH}.gz || gsutil -m cp gs://{BUCKET_NAME}/datasets/{PRC_DATA_FPATH}.gz .\n",
        "!test -f {PRC_DATA_FPATH} || gzip -d < {PRC_DATA_FPATH}.gz > {PRC_DATA_FPATH}\n",
        "!test -f {MODEL_PREFIX}.tar.gz || gsutil -m cp gs://{BUCKET_NAME}/{MODEL_DIR}/{MODEL_PREFIX}.tar.gz .\n",
        "!test -f {VOC_FNAME} || tar xzvf {MODEL_PREFIX}.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzIuGpA5rxDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEMO_MODE = True # @param {type: \"boolean\"}\n",
        "\n",
        "# Reduce the number of lines to train faster\n",
        "if DEMO_MODE:\n",
        "  !head -1000000 {PRC_DATA_FPATH} > {PRC_DATA_FPATH}.tmp\n",
        "  !mv {PRC_DATA_FPATH}.tmp {PRC_DATA_FPATH}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZiOSjK7iqWh",
        "colab_type": "text"
      },
      "source": [
        "Since our corpus can be large, we will split it into shards:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyN1nI04-uKV",
        "colab_type": "code",
        "outputId": "86e2713f-c747-4c9a-947d-c23ace0e8313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm -rf ./shards\n",
        "!mkdir ./shards\n",
        "!split -a 4 -l 256000 -d {PRC_DATA_FPATH} ./shards/shard_\n",
        "!ls ./shards/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shard_0000  shard_0001\tshard_0002  shard_0003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-FSq3zNFvLs",
        "colab_type": "text"
      },
      "source": [
        "The **MAX_SEQ_LENGTH** (maximum sequence length) supported for the model is 512, but training time will be a lot slower because the complexity is quadratic to the length of sentences. Albert authors trained 90% of time using length 128 and the remaining using 512.\n",
        "\n",
        "To simulate this behaviour, it is necessary to create training using length 128,and then create pre-training data again using 512 and change the configuration file.\n",
        "\n",
        "The **DUPE_FACTOR** defines how many times each sequence will be used. Each sequence is randomly masked so it is a good use of the data to have as many duplicates as possible. However, using values larger than 20 may generate files larger than 1GB per shard. Larger files will not make the pre-training to run slowly, but will require a lot of space.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnZcD0yIBGPd",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param {type: \"number\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "# Strip diacritics and Lowercase\n",
        "DO_LOWER_CASE = False #@param {type:\"boolean\"}\n",
        "DO_WHOLE_WORD_MASK = True #@param {type:\"boolean\"}\n",
        "PROCESSES = 2 #@param {type:\"integer\"}\n",
        "PRETRAINING_DIR = \"gs://{}/{}/pretraining_data_{}\".format(BUCKET_NAME, MODEL_DIR, MAX_SEQ_LENGTH)\n",
        "DUPE_FACTOR = 4 #@param {type:\"integer\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMv84ixhtyEX",
        "colab_type": "code",
        "outputId": "5fbf5c4c-714f-4d86-a75f-349dd9d351a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "PRETRAINING_DIR"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-MibOBkFam2",
        "colab_type": "text"
      },
      "source": [
        "Now, for each shard we need to call *create_pretraining_data.py* script. To that end, we will employ the  *xargs* command. \n",
        "\n",
        "This step will take a while to run. We will be saving generated data from each shards in the permanent storage.\n",
        "\n",
        "If you need to resume this step, you can check the bucket for generated files and manually delete the local shards that were already generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl6VDAdRA4vT",
        "colab_type": "code",
        "outputId": "9810068b-02c3-4d89-c769-046a16710163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "XARGS_CMD = ('ls ./shards | '\n",
        "      'xargs -n 1 -P {} -I{} '\n",
        "      'python3 ALBERT/create_pretraining_data.py '\n",
        "      '--input_file=./shards/{} '\n",
        "      '--output_file={}/{}.tfrecord '\n",
        "      '--vocab_file={} '\n",
        "      '--spm_model_file={} '\n",
        "      '--do_lower_case={} '\n",
        "      '--do_whole_word_mask={} '\n",
        "      '--max_predictions_per_seq={} '\n",
        "      '--max_seq_length={} '\n",
        "      '--masked_lm_prob={} '\n",
        "      '--dupe_factor={} ')\n",
        "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}',\n",
        "                             PRETRAINING_DIR, '{}', \n",
        "                             VOC_FNAME, MDL_FNAME, DO_LOWER_CASE,\n",
        "                             DO_WHOLE_WORD_MASK, MAX_PREDICTIONS, \n",
        "                             MAX_SEQ_LENGTH, MASKED_LM_PROB, DUPE_FACTOR)\n",
        "!$XARGS_CMD"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1209 17:25:41.247547 140407190394752 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1209 17:25:41.308561 140687693150080 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1209 17:25:41.325810 140407190394752 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I1209 17:25:41.326774 140407190394752 create_pretraining_data.py:628] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0001\n",
            "I1209 17:25:41.326937 140407190394752 create_pretraining_data.py:630]   ./shards/shard_0001\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1209 17:25:41.327742 140407190394752 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1209 17:25:41.386187 140687693150080 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I1209 17:25:41.387139 140687693150080 create_pretraining_data.py:628] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0000\n",
            "I1209 17:25:41.387344 140687693150080 create_pretraining_data.py:630]   ./shards/shard_0000\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1209 17:25:41.388086 140687693150080 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:number of instances: 272922\n",
            "I1209 17:37:22.065366 140407190394752 create_pretraining_data.py:638] number of instances: 272922\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I1209 17:37:22.066263 140407190394752 create_pretraining_data.py:641] *** Writing to output files ***\n",
            "INFO:tensorflow:  gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0001.tfrecord\n",
            "I1209 17:37:22.066365 140407190394752 create_pretraining_data.py:643]   gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0001.tfrecord\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1209 17:37:22.066607 140407190394752 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.068024 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Sua ▁capital ▁e ▁Ibrahimovi ▁cidade ▁de ▁A co bamba [MASK] [SEP] ▁A co bamba [MASK] [MASK] ▁provi ncia ▁do [MASK] ▁localizada ▁na ▁re gia o ▁de ▁Hu a nca ve lica . [SEP]\n",
            "I1209 17:37:22.068198 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Sua ▁capital ▁e ▁Ibrahimovi ▁cidade ▁de ▁A co bamba [MASK] [SEP] ▁A co bamba [MASK] [MASK] ▁provi ncia ▁do [MASK] ▁localizada ▁na ▁re gia o ▁de ▁Hu a nca ve lica . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 381 369 9 29099 83 6 28 238 19072 4 3 28 238 19072 4 4 9629 4428 12 4 429 25 172 2094 52 6 1524 49 3970 398 4256 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.068363 140407190394752 create_pretraining_data.py:197] input_ids: 2 381 369 9 29099 83 6 28 238 19072 4 3 28 238 19072 4 4 9629 4428 12 4 429 25 172 2094 52 6 1524 49 3970 398 4256 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.068469 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.068567 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.068657 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 10 15 16 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.068725 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 4 10 15 16 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 8 7 9 18 2569 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.068788 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 8 7 9 18 2569 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.068886 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.068947 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.069451 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Ber le ▁ficou ▁conhecido ▁por ▁protagonizar ▁os ▁programas ▁\" Te [MASK] co [MASK] ▁Theatre \", ▁\" The ▁Bu ick - Ber le ▁Show \" [MASK] ▁\" The ▁Milton ▁Ber le ▁Show \" ▁(19 66 –19 67 ), ▁que ▁eram ▁transmitidos ▁pela ▁rede ▁estadunidense ▁NBC . [SEP] [MASK] ▁cu [MASK] [MASK] ▁a ▁fazer ▁tele vis ao , ▁ele ▁praticamente ▁inventou ▁o ▁formato ▁de ▁programa ▁de ▁variedades , [MASK] [MASK] [MASK] [MASK] ▁em ▁que ▁a ▁TV ▁deixou ▁de ▁ser ▁um ▁entretenimento ▁de ▁elite ▁e ▁virou ▁diversa o ▁das [MASK] . [SEP]\n",
            "I1209 17:37:22.069578 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Ber le ▁ficou ▁conhecido ▁por ▁protagonizar ▁os ▁programas ▁\" Te [MASK] co [MASK] ▁Theatre \", ▁\" The ▁Bu ick - Ber le ▁Show \" [MASK] ▁\" The ▁Milton ▁Ber le ▁Show \" ▁(19 66 –19 67 ), ▁que ▁eram ▁transmitidos ▁pela ▁rede ▁estadunidense ▁NBC . [SEP] [MASK] ▁cu [MASK] [MASK] ▁a ▁fazer ▁tele vis ao , ▁ele ▁praticamente ▁inventou ▁o ▁formato ▁de ▁programa ▁de ▁variedades , [MASK] [MASK] [MASK] [MASK] ▁em ▁que ▁a ▁TV ▁deixou ▁de ▁ser ▁um ▁entretenimento ▁de ▁elite ▁e ▁virou ▁diversa o ▁das [MASK] . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 2029 199 484 255 26 21795 32 1094 17 3311 4 238 4 11025 47 17 300 1794 6315 16 14310 199 2460 27 4 17 300 8485 2029 199 2460 27 607 3664 9501 4410 59 15 259 16159 54 874 1591 13718 7 3 4 4443 4 4 8 350 4461 2959 8372 5 69 2639 23231 11 1526 6 301 6 8322 5 4 4 4 4 14 15 8 492 960 6 55 20 8405 6 3991 9 8254 23163 52 53 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.069695 140407190394752 create_pretraining_data.py:197] input_ids: 2 2029 199 484 255 26 21795 32 1094 17 3311 4 238 4 11025 47 17 300 1794 6315 16 14310 199 2460 27 4 17 300 8485 2029 199 2460 27 607 3664 9501 4410 59 15 259 16159 54 874 1591 13718 7 3 4 4443 4 4 8 350 4461 2959 8372 5 69 2639 23231 11 1526 6 301 6 8322 5 4 4 4 4 14 15 8 492 960 6 55 20 8405 6 3991 9 8254 23163 52 53 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.069792 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.069882 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.069971 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 11 12 13 25 47 48 49 50 67 68 69 70 87 88 0 0 0 0 0 0\n",
            "I1209 17:37:22.070036 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 11 12 13 25 47 48 49 50 67 68 69 70 87 88 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 2130 238 2359 9 486 21 70 4465 4549 25 9 11725 9287 7 0 0 0 0 0 0\n",
            "I1209 17:37:22.070100 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 2130 238 2359 9 486 21 70 4465 4549 25 9 11725 9287 7 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.070163 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.070220 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.070700 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Max ▁Fel d man , ▁ Estudo ▁e ▁Sim ula ca o ▁de ▁um ▁Con verso r ▁A / D ▁do ▁tipo ▁Red is trib u ica o [MASK] ▁carga [MASK] [MASK] ▁Alegre , ▁2013. ▁I DO ETA , ▁I . ▁V . ▁& [MASK] [MASK] U ▁Norte ▁Chapada , [MASK] [MASK] [MASK] . ▁\" Ele mentos ▁de ▁Eletro nica ▁Digital \", ▁Editora ▁Eric a ▁Ltda , ▁2012 [SEP] ▁& ▁Alves , ▁S . ▁R . , ▁Amp l ificado r ▁Opera cional , ▁Livro s ▁Editora [MASK] [MASK] [MASK] [MASK] , ▁1985 , ▁Sa o ▁Paulo , ▁Brasil . [SEP]\n",
            "I1209 17:37:22.070830 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Max ▁Fel d man , ▁ Estudo ▁e ▁Sim ula ca o ▁de ▁um ▁Con verso r ▁A / D ▁do ▁tipo ▁Red is trib u ica o [MASK] ▁carga [MASK] [MASK] ▁Alegre , ▁2013. ▁I DO ETA , ▁I . ▁V . ▁& [MASK] [MASK] U ▁Norte ▁Chapada , [MASK] [MASK] [MASK] . ▁\" Ele mentos ▁de ▁Eletro nica ▁Digital \", ▁Editora ▁Eric a ▁Ltda , ▁2012 [SEP] ▁& ▁Alves , ▁S . ▁R . , ▁Amp l ificado r ▁Opera cional , ▁Livro s ▁Editora [MASK] [MASK] [MASK] [MASK] , ▁1985 , ▁Sa o ▁Paulo , ▁Brasil . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 3103 10160 143 460 5 19 18377 9 4852 4050 228 52 6 20 890 9266 41 28 104 397 12 444 3073 194 14579 64 1840 52 4 2681 4 4 1625 5 2220 160 10428 23697 5 160 7 543 7 752 4 4 884 594 25120 5 4 4 4 7 17 6706 2767 6 20132 4334 8941 47 4598 3860 49 20955 5 1206 3 752 2936 5 193 7 399 7 5 18623 106 7735 41 7658 2769 5 4233 10 4598 4 4 4 4 5 4080 5 499 52 165 5 94 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.070943 140407190394752 create_pretraining_data.py:197] input_ids: 2 3103 10160 143 460 5 19 18377 9 4852 4050 228 52 6 20 890 9266 41 28 104 397 12 444 3073 194 14579 64 1840 52 4 2681 4 4 1625 5 2220 160 10428 23697 5 160 7 543 7 752 4 4 884 594 25120 5 4 4 4 7 17 6706 2767 6 20132 4334 8941 47 4598 3860 49 20955 5 1206 3 752 2936 5 193 7 399 7 5 18623 106 7735 41 7658 2769 5 4233 10 4598 4 4 4 4 5 4080 5 499 52 165 5 94 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.071040 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.071132 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.071221 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 29 31 32 45 46 47 48 49 51 52 53 88 89 90 91 0 0 0 0 0\n",
            "I1209 17:37:22.071285 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 29 31 32 45 46 47 48 49 51 52 53 88 89 90 91 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 6 5 619 19 20223 884 89 15149 437 7 465 3860 49 20955 7 0 0 0 0 0\n",
            "I1209 17:37:22.071371 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 6 5 619 19 20223 884 89 15149 437 7 465 3860 49 20955 7 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.071436 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.071494 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.071954 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [MASK] ges ▁Ludovico ▁Teixeira , ▁a ▁Pra ca ▁Ci vi ca , ▁remonta ▁a ▁ideia ▁original [MASK] [MASK] [MASK] [MASK] [MASK] ▁um ▁polo ▁de ▁irradia ca o ▁para ▁compor ▁uma ▁nova [MASK] ▁de ▁modelo ▁radio cent rico , ▁projetada ▁por ▁A ti lio ▁Corre a ▁Lima . ▁No ▁plano ▁ urban is tico ▁de ▁Go ia nia , ▁o ▁arquiteto ▁desenho u ▁o ▁Centro ▁Ci vi co ▁na ▁parte ▁mais ▁alta ▁da ▁futura ▁cidade , ▁permitindo ▁assim ▁visibilidade ▁maior ▁e ▁mais ▁e stra te gica ▁do ▁Pala cio ▁das ▁Esmeralda s ▁( res id encia ▁oficial ▁do ▁governador ▁de [SEP] ▁Em [MASK] [MASK] [MASK] [MASK] ▁obras ▁Competi [MASK] ca [MASK] [MASK] ▁pra ca ▁foram ▁conclui das , ▁a pos [MASK] ▁dois ▁anos ▁de ▁obras . [SEP]\n",
            "I1209 17:37:22.072087 140407190394752 create_pretraining_data.py:187] tokens: [CLS] [MASK] [MASK] ges ▁Ludovico ▁Teixeira , ▁a ▁Pra ca ▁Ci vi ca , ▁remonta ▁a ▁ideia ▁original [MASK] [MASK] [MASK] [MASK] [MASK] ▁um ▁polo ▁de ▁irradia ca o ▁para ▁compor ▁uma ▁nova [MASK] ▁de ▁modelo ▁radio cent rico , ▁projetada ▁por ▁A ti lio ▁Corre a ▁Lima . ▁No ▁plano ▁ urban is tico ▁de ▁Go ia nia , ▁o ▁arquiteto ▁desenho u ▁o ▁Centro ▁Ci vi co ▁na ▁parte ▁mais ▁alta ▁da ▁futura ▁cidade , ▁permitindo ▁assim ▁visibilidade ▁maior ▁e ▁mais ▁e stra te gica ▁do ▁Pala cio ▁das ▁Esmeralda s ▁( res id encia ▁oficial ▁do ▁governador ▁de [SEP] ▁Em [MASK] [MASK] [MASK] [MASK] ▁obras ▁Competi [MASK] ca [MASK] [MASK] ▁pra ca ▁foram ▁conclui das , ▁a pos [MASK] ▁dois ▁anos ▁de ▁obras . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 4 4344 29464 5818 5 8 3643 228 1726 514 228 5 5829 8 1025 605 4 4 4 4 4 20 11997 6 20783 228 52 24 6734 18 314 4 6 699 5734 4141 4463 5 8573 26 28 560 3894 9217 49 2019 7 67 1226 19 12696 194 3116 6 1065 128 1747 5 11 4661 2122 64 11 575 1726 514 238 25 96 39 976 13 7399 83 5 3374 206 14846 130 9 39 9 2081 204 9581 12 12237 1888 53 15418 10 29 425 1051 7367 456 12 1215 6 3 43 4 4 4 4 535 21334 4 228 4 4 2672 228 75 14445 190 5 8 2718 4 97 66 6 535 7 3\n",
            "I1209 17:37:22.105763 140407190394752 create_pretraining_data.py:197] input_ids: 2 4 4 4344 29464 5818 5 8 3643 228 1726 514 228 5 5829 8 1025 605 4 4 4 4 4 20 11997 6 20783 228 52 24 6734 18 314 4 6 699 5734 4141 4463 5 8573 26 28 560 3894 9217 49 2019 7 67 1226 19 12696 194 3116 6 1065 128 1747 5 11 4661 2122 64 11 575 1726 514 238 25 96 39 976 13 7399 83 5 3374 206 14846 130 9 39 9 2081 204 9581 12 12237 1888 53 15418 10 29 425 1051 7367 456 12 1215 6 3 43 4 4 4 4 535 21334 4 228 4 4 2672 228 75 14445 190 5 8 2718 4 97 66 6 535 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.105906 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.106011 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.106105 140407190394752 create_pretraining_data.py:197] token_boundary: 1 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 3 18 19 20 21 22 33 103 104 105 106 108 109 110 111 112 121 0\n",
            "I1209 17:37:22.106173 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 1 2 3 18 19 20 21 22 33 103 104 105 106 108 109 110 111 112 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 228 5029 598 12 11879 238 31 92 369 389 6 1802 5 6 20798 228 52 13 529 0\n",
            "I1209 17:37:22.106238 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 228 5029 598 12 11879 238 31 92 369 389 6 1802 5 6 20798 228 52 13 529 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.106339 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.106403 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.106907 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Uma [MASK] ca [MASK] ▁ lux ada ▁so ▁pode ▁ser ▁' re duzida ' [MASK] [MASK] ▁por ▁um ▁medi co ▁treinado . [SEP] ▁Foi ▁produzido ▁por ▁Pedro ▁Al mo do var ▁e ▁Vista [MASK] [MASK] ▁Al mo do var , ▁com ▁di rec ao ▁de ▁arte ▁de ▁Ant x on ▁Gomez , ▁figurino ▁de ▁Pa co ▁Delgado ▁e ▁Jean - Paul ▁Gau l tier ▁e ▁e dica o ▁de ▁Jose [MASK] [MASK] [MASK] . [SEP]\n",
            "I1209 17:37:22.107040 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Uma [MASK] ca [MASK] ▁ lux ada ▁so ▁pode ▁ser ▁' re duzida ' [MASK] [MASK] ▁por ▁um ▁medi co ▁treinado . [SEP] ▁Foi ▁produzido ▁por ▁Pedro ▁Al mo do var ▁e ▁Vista [MASK] [MASK] ▁Al mo do var , ▁com ▁di rec ao ▁de ▁arte ▁de ▁Ant x on ▁Gomez , ▁figurino ▁de ▁Pa co ▁Delgado ▁e ▁Jean - Paul ▁Gau l tier ▁e ▁e dica o ▁de ▁Jose [MASK] [MASK] [MASK] . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 377 4 228 4 19 13965 497 2866 110 55 804 250 16466 121 4 4 26 20 8902 238 19006 7 3 142 1318 26 598 571 320 61 4294 9 7877 4 4 571 320 61 4294 5 21 719 6040 8372 6 868 6 6582 305 445 25517 5 20041 6 758 238 21429 9 2438 16 14236 9943 106 11131 9 9 4688 52 6 12428 4 4 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.107170 140407190394752 create_pretraining_data.py:197] input_ids: 2 377 4 228 4 19 13965 497 2866 110 55 804 250 16466 121 4 4 26 20 8902 238 19006 7 3 142 1318 26 598 571 320 61 4294 9 7877 4 4 571 320 61 4294 5 21 719 6040 8372 6 868 6 6582 305 445 25517 5 20041 6 758 238 21429 9 2438 16 14236 9943 106 11131 9 9 4688 52 6 12428 4 4 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.107270 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.107391 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.107481 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 2 3 4 15 16 33 34 35 71 72 73 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.107545 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 2 3 4 15 16 33 34 35 71 72 73 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 18176 228 52 21 308 28 1163 9474 2293 342 61 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.107609 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 18176 228 52 21 308 28 1163 9474 2293 342 61 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.107674 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.107731 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.108204 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [MASK] ▁cerca ▁de ▁60% ▁da ▁sua ▁pop ula ca o [MASK] ▁primeiro ▁por ▁emigra ca o ▁para ▁os ▁Estados ▁Unidos , [MASK] [MASK] ▁para ▁a ▁California , ▁e ▁depois ▁para ▁o ▁Canada [MASK] ▁Nessa s ▁circun sta ncia s [MASK] , ▁sendo ▁muito ▁dificil ▁o ▁acesso ▁a ▁cuidados ▁de ▁sau de , ▁Mon senhor ▁In oc en cio ▁foi ▁o ▁medi co ▁e ▁o [MASK] [MASK] ▁povo ▁da ▁freguesia ▁e ▁das ▁povo aco es ▁vizinhas [MASK] [SEP] ▁A ▁ unica ▁sai da ▁po ssi vel ▁para ▁mais ▁de ▁um ▁ter co ▁da ▁pop ula ca o ▁a co riana [MASK] [MASK] [MASK] [MASK] [MASK] , ▁sendo ▁as ▁estreia ▁mais ▁distantes ▁dos ▁centros ▁urbanos , ▁como ▁os ▁Alta res , ▁as ▁comunidades ▁mais [MASK] s [MASK] [SEP]\n",
            "I1209 17:37:22.108360 140407190394752 create_pretraining_data.py:187] tokens: [CLS] [MASK] [MASK] ▁cerca ▁de ▁60% ▁da ▁sua ▁pop ula ca o [MASK] ▁primeiro ▁por ▁emigra ca o ▁para ▁os ▁Estados ▁Unidos , [MASK] [MASK] ▁para ▁a ▁California , ▁e ▁depois ▁para ▁o ▁Canada [MASK] ▁Nessa s ▁circun sta ncia s [MASK] , ▁sendo ▁muito ▁dificil ▁o ▁acesso ▁a ▁cuidados ▁de ▁sau de , ▁Mon senhor ▁In oc en cio ▁foi ▁o ▁medi co ▁e ▁o [MASK] [MASK] ▁povo ▁da ▁freguesia ▁e ▁das ▁povo aco es ▁vizinhas [MASK] [SEP] ▁A ▁ unica ▁sai da ▁po ssi vel ▁para ▁mais ▁de ▁um ▁ter co ▁da ▁pop ula ca o ▁a co riana [MASK] [MASK] [MASK] [MASK] [MASK] , ▁sendo ▁as ▁estreia ▁mais ▁distantes ▁dos ▁centros ▁urbanos , ▁como ▁os ▁Alta res , ▁as ▁comunidades ▁mais [MASK] s [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 4 232 6 15538 13 38 2440 4050 228 52 4 86 26 11079 228 52 24 32 216 224 5 4 4 24 8 14603 5 9 115 24 11 21177 4 2494 10 13521 1198 4428 10 4 5 92 126 19776 11 892 8 6338 6 10464 103 5 2052 22699 603 5600 294 1888 30 11 8902 238 9 11 4 4 1210 13 2557 9 53 1210 6466 101 11557 4 3 28 19 20017 3319 62 2360 3397 1702 24 39 6 20 137 238 13 2440 4050 228 52 8 238 5927 4 4 4 4 4 5 92 40 965 39 13322 36 4118 8555 5 31 32 4952 425 5 40 3989 39 4 10 4 3\n",
            "I1209 17:37:22.108484 140407190394752 create_pretraining_data.py:197] input_ids: 2 4 4 232 6 15538 13 38 2440 4050 228 52 4 86 26 11079 228 52 24 32 216 224 5 4 4 24 8 14603 5 9 115 24 11 21177 4 2494 10 13521 1198 4428 10 4 5 92 126 19776 11 892 8 6338 6 10464 103 5 2052 22699 603 5600 294 1888 30 11 8902 238 9 11 4 4 1210 13 2557 9 53 1210 6466 101 11557 4 3 28 19 20017 3319 62 2360 3397 1702 24 39 6 20 137 238 13 2440 4050 228 52 8 238 5927 4 4 4 4 4 5 92 40 965 39 13322 36 4118 8555 5 31 32 4952 425 5 40 3989 39 4 10 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.108583 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.108673 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
            "I1209 17:37:22.108761 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 12 23 24 34 41 66 67 77 101 102 103 104 105 109 124 125 126 0\n",
            "I1209 17:37:22.108826 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 1 2 12 23 24 34 41 66 67 77 101 102 103 104 105 109 124 125 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 2557 1521 5 14 722 7 1112 6487 12 5 30 8 11079 228 52 11738 14417 10 7 0\n",
            "I1209 17:37:22.108890 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 2557 1521 5 14 722 7 1112 6487 12 5 30 8 11079 228 52 11738 14417 10 7 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.108954 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.109016 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.109488 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁O ▁resultado ▁final ▁e ▁revelado [MASK] [MASK] [MASK] [MASK] ▁Jeová [MASK] ▁da ▁primeira [MASK] ) ▁ao ▁vivo , ▁por ▁Zeca ▁Camargo . ▁A [MASK] [MASK] [MASK] [MASK] ▁do ▁programa ▁\" No ▁Li mite \" ▁se ▁deve ▁ao ▁fato ▁de ▁o ▁produtor ▁do [MASK] ▁\" Survivor \", ▁Mark ▁Burn ett , ▁ter ▁acusado [MASK] ▁programa ▁brasileiro ▁de ▁ter ▁copia do ▁a ▁ versa o ▁americana [SEP] ▁Segundo ▁ele , ▁na o ▁haveria [MASK] ▁se [MASK] ▁programa ▁fosse ▁um ▁formato ▁comprado ▁para ▁uma ▁adapta ca o [MASK] ▁Por ▁ter ▁sido ▁copia do ▁sem ▁autoriza ca o ▁da ▁emissora ▁detentor a ▁dos ▁direitos [MASK] ▁cair [MASK] ▁Rede ▁Globo ▁foi ▁processa da ▁e , ▁ciente ▁de ▁uma ▁derrota , ▁determinou ▁o ▁fim ▁tempo ra rio ▁do ▁No ▁Li mite . [SEP]\n",
            "I1209 17:37:22.109620 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁O ▁resultado ▁final ▁e ▁revelado [MASK] [MASK] [MASK] [MASK] ▁Jeová [MASK] ▁da ▁primeira [MASK] ) ▁ao ▁vivo , ▁por ▁Zeca ▁Camargo . ▁A [MASK] [MASK] [MASK] [MASK] ▁do ▁programa ▁\" No ▁Li mite \" ▁se ▁deve ▁ao ▁fato ▁de ▁o ▁produtor ▁do [MASK] ▁\" Survivor \", ▁Mark ▁Burn ett , ▁ter ▁acusado [MASK] ▁programa ▁brasileiro ▁de ▁ter ▁copia do ▁a ▁ versa o ▁americana [SEP] ▁Segundo ▁ele , ▁na o ▁haveria [MASK] ▁se [MASK] ▁programa ▁fosse ▁um ▁formato ▁comprado ▁para ▁uma ▁adapta ca o [MASK] ▁Por ▁ter ▁sido ▁copia do ▁sem ▁autoriza ca o ▁da ▁emissora ▁detentor a ▁dos ▁direitos [MASK] ▁cair [MASK] ▁Rede ▁Globo ▁foi ▁processa da ▁e , ▁ciente ▁de ▁uma ▁derrota , ▁determinou ▁o ▁fim ▁tempo ra rio ▁do ▁No ▁Li mite . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 33 774 182 9 4792 4 4 4 4 11021 4 13 100 4 46 37 1060 5 26 21052 8237 7 28 4 4 4 4 12 301 17 1773 897 6986 27 35 582 37 586 6 11 1779 12 4 17 29576 47 2762 12282 6349 5 137 4329 4 301 340 6 137 11112 61 8 19 5733 52 1987 3 662 69 5 25 52 10699 4 35 4 301 917 20 1526 9526 24 18 10130 228 52 4 262 137 131 11112 61 181 17331 228 52 13 1056 11209 49 36 1167 4 6060 4 783 698 30 15293 62 9 5 20230 6 18 1955 5 10830 11 297 152 153 1561 12 67 897 6986 7 3\n",
            "I1209 17:37:22.109738 140407190394752 create_pretraining_data.py:197] input_ids: 2 33 774 182 9 4792 4 4 4 4 11021 4 13 100 4 46 37 1060 5 26 21052 8237 7 28 4 4 4 4 12 301 17 1773 897 6986 27 35 582 37 586 6 11 1779 12 4 17 29576 47 2762 12282 6349 5 137 4329 4 301 340 6 137 11112 61 8 19 5733 52 1987 3 662 69 5 25 52 10699 4 35 4 301 917 20 1526 9526 24 18 10130 228 52 4 262 137 131 11112 61 181 17331 228 52 13 1056 11209 49 36 1167 4 6060 4 783 698 30 15293 62 9 5 20230 6 18 1955 5 10830 11 297 152 153 1561 12 67 897 6986 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.109838 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.109934 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1\n",
            "I1209 17:37:22.110022 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 7 8 9 10 11 14 24 25 26 27 43 53 72 74 85 101 102 103 0\n",
            "I1209 17:37:22.110087 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 6 7 8 9 10 11 14 24 25 26 27 43 53 72 74 85 101 102 103 0\n",
            "INFO:tensorflow:masked_lm_ids: 29 533 281 342 228 52 362 281 2597 228 52 301 11 683 11 7 2783 5 8 0\n",
            "I1209 17:37:22.110150 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 29 533 281 342 228 52 362 281 2597 228 52 301 11 683 11 7 2783 5 8 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.110214 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:22.110271 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.110680 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Stu ck ▁nasceu [MASK] ▁Te tten wei s , [MASK] ▁Baviera . [SEP] ▁Estende - se ▁por ▁uma [MASK] ▁juros ▁de ▁7 , 03 ▁km 2. [SEP]\n",
            "I1209 17:37:22.110778 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Stu ck ▁nasceu [MASK] ▁Te tten wei s , [MASK] ▁Baviera . [SEP] ▁Estende - se ▁por ▁uma [MASK] ▁juros ▁de ▁7 , 03 ▁km 2. [SEP]\n",
            "INFO:tensorflow:input_ids: 2 7336 676 909 4 1284 7911 18977 10 5 4 12844 7 3 161 16 34 26 18 4 10431 6 268 5 4674 90 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.110885 140407190394752 create_pretraining_data.py:197] input_ids: 2 7336 676 909 4 1284 7911 18977 10 5 4 12844 7 3 161 16 34 26 18 4 10431 6 268 5 4674 90 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.110983 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.111070 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.111158 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 10 19 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.111222 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 4 10 19 20 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 14 14 8 3711 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.111285 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 14 14 8 3711 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.111372 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.111430 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.111871 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Foi ▁estabelecido ▁em ▁1904 , ▁sendo ▁o ▁primeiro ▁parque ▁nacional ▁ao ▁leste ▁das ▁Montanha s ▁Ro cho sas . [SEP] ▁A ▁maior ▁parte ▁do ▁parque ▁e [MASK] [MASK] [MASK] ▁austro ▁somente ▁de ▁barco [MASK] [SEP]\n",
            "I1209 17:37:22.111983 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Foi ▁estabelecido ▁em ▁1904 , ▁sendo ▁o ▁primeiro ▁parque ▁nacional ▁ao ▁leste ▁das ▁Montanha s ▁Ro cho sas . [SEP] ▁A ▁maior ▁parte ▁do ▁parque ▁e [MASK] [MASK] [MASK] ▁austro ▁somente ▁de ▁barco [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 142 5413 14 7846 5 92 11 86 1728 446 37 1365 53 12021 10 997 1278 3191 7 3 28 130 96 12 1728 9 4 4 4 25161 753 6 9043 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.112097 140407190394752 create_pretraining_data.py:197] input_ids: 2 142 5413 14 7846 5 92 11 86 1728 446 37 1365 53 12021 10 997 1278 3191 7 3 28 130 96 12 1728 9 4 4 4 25161 753 6 9043 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.112195 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.112285 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.208692 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 27 28 29 30 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.208973 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 27 28 29 30 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 8 342 3397 1702 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.209053 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 8 342 3397 1702 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.209133 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:22.209200 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.209894 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] qui eu ▁e ▁evidente [MASK] ▁o ▁seguinte ▁do ▁Capi tu lo ▁XIII ▁do ▁Livro ▁XXI X : [MASK] ▁as ▁leis ▁civis ▁dependem ▁das ▁institui co es ▁poli tica s , ▁porque ▁eles ▁sa o ▁feitos ▁para [MASK] [MASK] ▁sociedade , ▁sempre ▁que ▁ha ▁um ▁projeto ▁de ▁a do ca o [MASK] Caldeirão ▁civil ▁de ▁outro ▁pais , ▁seria ▁adequado ▁para ▁analisar ▁de ▁ante [SEP] intitulado ▁\" Como ▁comparar ▁dois ▁sistemas ▁diferentes ▁de ▁leis \") ▁do ▁Livro ▁XXI [MASK] ▁ele [MASK] ▁que ▁\" para ▁determinar ▁qual ▁desses ▁sistemas ▁[ ou ▁seja , ▁os ▁sistemas ▁de ▁France s [MASK] ▁incapacita [MASK] ▁para ▁a [MASK] [MASK] [MASK] [MASK] ▁falsas ▁testemunhas ] ▁e ▁mais ▁a grada vel ▁a ▁ra za o ▁ , ▁devemos ▁leva - los ▁cada ▁um ▁como [SEP]\n",
            "I1209 17:37:22.210056 140407190394752 create_pretraining_data.py:187] tokens: [CLS] qui eu ▁e ▁evidente [MASK] ▁o ▁seguinte ▁do ▁Capi tu lo ▁XIII ▁do ▁Livro ▁XXI X : [MASK] ▁as ▁leis ▁civis ▁dependem ▁das ▁institui co es ▁poli tica s , ▁porque ▁eles ▁sa o ▁feitos ▁para [MASK] [MASK] ▁sociedade , ▁sempre ▁que ▁ha ▁um ▁projeto ▁de ▁a do ca o [MASK] Caldeirão ▁civil ▁de ▁outro ▁pais , ▁seria ▁adequado ▁para ▁analisar ▁de ▁ante [SEP] intitulado ▁\" Como ▁comparar ▁dois ▁sistemas ▁diferentes ▁de ▁leis \") ▁do ▁Livro ▁XXI [MASK] ▁ele [MASK] ▁que ▁\" para ▁determinar ▁qual ▁desses ▁sistemas ▁[ ou ▁seja , ▁os ▁sistemas ▁de ▁France s [MASK] ▁incapacita [MASK] ▁para ▁a [MASK] [MASK] [MASK] [MASK] ▁falsas ▁testemunhas ] ▁e ▁mais ▁a grada vel ▁a ▁ra za o ▁ , ▁devemos ▁leva - los ▁cada ▁um ▁como [SEP]\n",
            "INFO:tensorflow:input_ids: 2 879 2647 9 6297 4 11 322 12 12175 835 145 6017 12 4233 8469 1013 42 4 40 2470 3836 14483 53 15618 238 101 2128 2507 10 5 673 251 1577 52 2491 24 4 4 786 5 411 15 2909 20 451 6 8 61 228 52 4 28093 1546 6 309 1480 5 375 5872 24 8295 6 10412 3 22257 17 13182 19939 97 1132 509 6 2470 323 12 4233 8469 4 69 4 15 17 1650 4308 170 2025 1132 1310 158 329 5 32 1132 6 6605 10 4 24817 4 24 8 4 4 4 4 16749 13522 1222 9 39 8 6950 1702 8 1901 809 52 19 5 19000 1553 16 796 209 20 31 3\n",
            "I1209 17:37:22.210186 140407190394752 create_pretraining_data.py:197] input_ids: 2 879 2647 9 6297 4 11 322 12 12175 835 145 6017 12 4233 8469 1013 42 4 40 2470 3836 14483 53 15618 238 101 2128 2507 10 5 673 251 1577 52 2491 24 4 4 786 5 411 15 2909 20 451 6 8 61 228 52 4 28093 1546 6 309 1480 5 375 5872 24 8295 6 10412 3 22257 17 13182 19939 97 1132 509 6 2470 323 12 4233 8469 4 69 4 15 17 1650 4308 170 2025 1132 1310 158 329 5 32 1132 6 6605 10 4 24817 4 24 8 4 4 4 4 16749 13522 1222 9 39 8 6950 1702 8 1901 809 52 19 5 19000 1553 16 796 209 20 31 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.210285 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.210417 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            "I1209 17:37:22.210517 140407190394752 create_pretraining_data.py:197] token_boundary: 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 12 18 19 20 37 38 51 52 77 78 80 97 98 99 102 103 104 105 0\n",
            "I1209 17:37:22.210584 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 5 12 18 19 20 37 38 51 52 77 78 80 97 98 99 102 103 104 105 0\n",
            "INFO:tensorflow:masked_lm_ids: 9 6017 447 40 2470 8 394 12 646 8469 1013 12747 9 18927 1085 11260 228 52 6 0\n",
            "I1209 17:37:22.210649 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 9 6017 447 40 2470 8 394 12 646 8469 1013 12747 9 18927 1085 11260 228 52 6 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.210716 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.210772 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.211205 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [MASK] ▁in [MASK] ▁ LI VE time ▁e ▁o [MASK] ▁ao ▁vivo ▁duplo ▁da ▁banda ▁de ▁metal ▁progressivo ▁Dream ▁Theater , ▁gravado ▁em ▁dia ▁25 ▁de ▁Junho ▁de ▁1998 ▁no ▁La ▁Bata c lan ▁em ▁Paris ▁na ▁Franca , ▁foi ▁ lan cado ▁no ▁mesmo ▁ano . [SEP] ▁Estende - se [MASK] [MASK] [MASK] [MASK] [MASK] ▁17 , 11 ▁km 2. [SEP]\n",
            "I1209 17:37:22.211328 140407190394752 create_pretraining_data.py:187] tokens: [CLS] [MASK] [MASK] ▁in [MASK] ▁ LI VE time ▁e ▁o [MASK] ▁ao ▁vivo ▁duplo ▁da ▁banda ▁de ▁metal ▁progressivo ▁Dream ▁Theater , ▁gravado ▁em ▁dia ▁25 ▁de ▁Junho ▁de ▁1998 ▁no ▁La ▁Bata c lan ▁em ▁Paris ▁na ▁Franca , ▁foi ▁ lan cado ▁no ▁mesmo ▁ano . [SEP] ▁Estende - se [MASK] [MASK] [MASK] [MASK] [MASK] ▁17 , 11 ▁km 2. [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 4 188 4 19 9492 15772 8658 9 11 4 37 1060 4417 13 147 6 1229 12529 6995 16839 5 2119 14 123 546 6 1730 6 2204 22 321 16608 180 1818 14 901 25 12332 5 30 19 1818 7086 22 88 76 7 3 161 16 34 4 4 4 4 4 312 5 2884 90 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.211446 140407190394752 create_pretraining_data.py:197] input_ids: 2 4 4 188 4 19 9492 15772 8658 9 11 4 37 1060 4417 13 147 6 1229 12529 6995 16839 5 2119 14 123 546 6 1730 6 2204 22 321 16608 180 1818 14 901 25 12332 5 30 19 1818 7086 22 88 76 7 3 161 16 34 4 4 4 4 4 312 5 2884 90 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.211549 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.211640 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.211728 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 3 4 11 53 54 55 56 57 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.211791 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 1 2 3 4 11 53 54 55 56 57 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 33 1913 188 8 22876 26 18 8 3711 6 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.211853 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 33 1913 188 8 22876 26 18 8 3711 6 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.211917 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.211975 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.212446 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Jarrett [MASK] [MASK] ▁Naquele ▁me s , ▁Angle ▁assinou ▁um ▁contrato ▁de ▁ tre s ▁anos ▁com ▁a ▁TNA . ▁Sem ▁Karen , ▁Angle ▁derrotou ▁Jarrett ▁no ▁Slam mi versa ry ▁IX ▁para ▁manter [MASK] [MASK] [MASK] [MASK] [MASK] ▁e ▁se ▁tornar ▁o ▁desafiante ▁pelo ▁Campeonato ▁Mundial ▁dos ▁Pesos - Pesados ▁da ▁TNA [MASK] ▁No ▁entanto , [MASK] ▁\" Impact ▁Wrestling \" ▁seguinte , ▁Jarrett ▁desafiou ▁Angle ▁para ▁uma ▁briga ▁no ▁estacionamento , ▁assinando ▁um ▁contrato ▁que ▁o ▁obriga ria [SEP] ▁No ▁Lock down , ▁Jarrett ▁derrotou ▁Angle ▁em ▁uma ▁luta ▁de ▁duas ▁que das ▁numa ▁jaula , ▁com ▁ajuda ▁cultiva ▁Karen . ▁No ▁\" Impact !\" ▁de ▁12 ▁de ▁maio , ▁Angle [MASK] [MASK] ▁Ch [MASK] [MASK] ▁o ▁ajudar ia ▁contra ▁os ▁Jarrett s . [SEP]\n",
            "I1209 17:37:22.212584 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Jarrett [MASK] [MASK] ▁Naquele ▁me s , ▁Angle ▁assinou ▁um ▁contrato ▁de ▁ tre s ▁anos ▁com ▁a ▁TNA . ▁Sem ▁Karen , ▁Angle ▁derrotou ▁Jarrett ▁no ▁Slam mi versa ry ▁IX ▁para ▁manter [MASK] [MASK] [MASK] [MASK] [MASK] ▁e ▁se ▁tornar ▁o ▁desafiante ▁pelo ▁Campeonato ▁Mundial ▁dos ▁Pesos - Pesados ▁da ▁TNA [MASK] ▁No ▁entanto , [MASK] ▁\" Impact ▁Wrestling \" ▁seguinte , ▁Jarrett ▁desafiou ▁Angle ▁para ▁uma ▁briga ▁no ▁estacionamento , ▁assinando ▁um ▁contrato ▁que ▁o ▁obriga ria [SEP] ▁No ▁Lock down , ▁Jarrett ▁derrotou ▁Angle ▁em ▁uma ▁luta ▁de ▁duas ▁que das ▁numa ▁jaula , ▁com ▁ajuda ▁cultiva ▁Karen . ▁No ▁\" Impact !\" ▁de ▁12 ▁de ▁maio , ▁Angle [MASK] [MASK] ▁Ch [MASK] [MASK] ▁o ▁ajudar ia ▁contra ▁os ▁Jarrett s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 28901 4 4 8951 794 10 5 8031 2585 20 894 6 19 1678 10 66 21 8 19586 7 2810 20215 5 8031 3650 28901 22 18241 836 5733 717 6922 24 1173 4 4 4 4 4 9 35 1095 11 23061 57 421 642 36 18832 16 19270 13 19586 4 67 363 5 4 17 13086 7509 27 322 5 28901 22357 8031 24 18 6443 22 10648 5 17267 20 894 15 11 8729 269 3 67 23692 14954 5 28901 3650 8031 14 18 593 6 168 15 190 384 27608 5 21 1076 20347 20215 7 67 17 13086 3563 6 288 6 367 5 8031 4 4 3187 4 4 11 2205 128 138 32 28901 10 7 3\n",
            "I1209 17:37:22.212703 140407190394752 create_pretraining_data.py:197] input_ids: 2 28901 4 4 8951 794 10 5 8031 2585 20 894 6 19 1678 10 66 21 8 19586 7 2810 20215 5 8031 3650 28901 22 18241 836 5733 717 6922 24 1173 4 4 4 4 4 9 35 1095 11 23061 57 421 642 36 18832 16 19270 13 19586 4 67 363 5 4 17 13086 7509 27 322 5 28901 22357 8031 24 18 6443 22 10648 5 17267 20 894 15 11 8729 269 3 67 23692 14954 5 28901 3650 8031 14 18 593 6 168 15 190 384 27608 5 21 1076 20347 20215 7 67 17 13086 3563 6 288 6 367 5 8031 4 4 3187 4 4 11 2205 128 138 32 28901 10 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.212800 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.212895 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1\n",
            "I1209 17:37:22.212982 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 3 35 36 37 38 39 54 57 58 67 101 114 115 116 117 118 122 0\n",
            "I1209 17:37:22.213046 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 1 2 3 35 36 37 38 39 54 57 58 67 101 114 115 116 117 118 122 0\n",
            "INFO:tensorflow:masked_lm_ids: 28901 10 7 38 2435 11 4073 9366 7 5 22 8031 6 1256 15 3187 156 148 138 0\n",
            "I1209 17:37:22.213108 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 28901 10 7 38 2435 11 4073 9366 7 5 22 8031 6 1256 15 3187 156 148 138 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.213172 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.213229 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.213626 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Foi ▁ lan cado [MASK] ▁muitos ▁bu g s , ▁provavelmente ▁pelos ▁problemas ▁de ▁pro duc ao . [SEP] ▁America ▁1 [MASK] [MASK] ▁Americano [SEP]\n",
            "I1209 17:37:22.213724 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Foi ▁ lan cado [MASK] ▁muitos ▁bu g s , ▁provavelmente ▁pelos ▁problemas ▁de ▁pro duc ao . [SEP] ▁America ▁1 [MASK] [MASK] ▁Americano [SEP]\n",
            "INFO:tensorflow:input_ids: 2 142 19 1818 7086 4 379 2877 286 10 5 1676 203 683 6 818 12093 8372 7 3 4478 118 4 4 8124 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.213829 140407190394752 create_pretraining_data.py:197] input_ids: 2 142 19 1818 7086 4 379 2877 286 10 5 1676 203 683 6 818 12093 8372 7 3 4478 118 4 4 8124 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.310565 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.310773 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.310878 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 11 22 23 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.310952 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 5 11 22 23 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 21 1676 1162 144 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.311026 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 21 1676 1162 144 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.311097 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.311165 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.311755 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁E ▁comum ▁dizer ▁que , ▁em ▁principio s , ▁a ▁agricultura ▁convencional ▁se ▁o po e ▁a ▁organ ica . [SEP] ▁O ▁condado [MASK] ▁fundado ▁em [MASK] [MASK] [MASK] ▁de ▁1867 [MASK] [SEP]\n",
            "I1209 17:37:22.311882 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁E ▁comum ▁dizer ▁que , ▁em ▁principio s , ▁a ▁agricultura ▁convencional ▁se ▁o po e ▁a ▁organ ica . [SEP] ▁O ▁condado [MASK] ▁fundado ▁em [MASK] [MASK] [MASK] ▁de ▁1867 [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 179 675 1973 15 5 14 24620 10 5 8 4843 8225 35 11 741 70 8 13684 1840 7 3 33 633 4 1044 14 4 4 4 6 10994 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.312001 140407190394752 create_pretraining_data.py:197] input_ids: 2 179 675 1973 15 5 14 24620 10 5 8 4843 8225 35 11 741 70 8 13684 1840 7 3 33 633 4 1044 14 4 4 4 6 10994 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.312097 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.312188 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.312275 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 24 27 28 29 32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.312363 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 24 27 28 29 32 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 30 775 6 496 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.312428 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 30 775 6 496 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.312494 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.312552 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.313036 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁da ▁procura ▁do ▁mm c [MASK] 12 , ▁8 ). ▁O [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁ unica ▁diz ▁que ▁todo ▁o [MASK] ▁maior ▁que ▁1 ▁pode ▁ser ▁escrito ▁de ▁um ▁so [MASK] ▁rabino ▁um ▁produto ▁de ▁numero s ▁primos . ▁Os ▁numero s ▁primos ▁podem [MASK] [MASK] ▁como ▁os ▁elementos ▁ato mico s ▁que , ▁quando ▁combinado s , ▁formam ▁um ▁numero ▁composto . ▁Por ▁exemplo : ▁Aqui ▁temos ▁o ▁numero ▁composto ▁90 , ▁constitui do ▁por ▁um ▁a tomo ▁do ▁numero ▁primo ▁2 , ▁dois ▁ato mos ▁do ▁numero ▁primo ▁3 ▁e [SEP] ▁A ▁seguinte ▁maneira ▁tem ▁a ▁virtude [MASK] ▁coerência ▁este ▁passo ▁imp o ssi vel ▁de ▁esquecer ▁misericórdia [MASK] [MASK] ST ▁torna - se ▁de s nec essa rio ▁lembrar ). [SEP]\n",
            "I1209 17:37:22.313171 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁da ▁procura ▁do ▁mm c [MASK] 12 , ▁8 ). ▁O [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁ unica ▁diz ▁que ▁todo ▁o [MASK] ▁maior ▁que ▁1 ▁pode ▁ser ▁escrito ▁de ▁um ▁so [MASK] ▁rabino ▁um ▁produto ▁de ▁numero s ▁primos . ▁Os ▁numero s ▁primos ▁podem [MASK] [MASK] ▁como ▁os ▁elementos ▁ato mico s ▁que , ▁quando ▁combinado s , ▁formam ▁um ▁numero ▁composto . ▁Por ▁exemplo : ▁Aqui ▁temos ▁o ▁numero ▁composto ▁90 , ▁constitui do ▁por ▁um ▁a tomo ▁do ▁numero ▁primo ▁2 , ▁dois ▁ato mos ▁do ▁numero ▁primo ▁3 ▁e [SEP] ▁A ▁seguinte ▁maneira ▁tem ▁a ▁virtude [MASK] ▁coerência ▁este ▁passo ▁imp o ssi vel ▁de ▁esquecer ▁misericórdia [MASK] [MASK] ST ▁torna - se ▁de s nec essa rio ▁lembrar ). [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 2245 12 3640 180 4 3019 5 303 73 33 4 4 4 4 4 4 19 20017 853 15 311 11 4 130 15 118 110 55 1172 6 20 2866 4 21958 20 1942 6 19308 10 16081 7 87 19308 10 16081 258 4 4 31 32 969 3149 5622 10 15 5 91 9090 10 5 3746 20 19308 1450 7 262 313 42 5854 3828 11 19308 1450 2425 5 4144 61 26 20 8 19314 12 19308 3648 146 5 97 3149 511 12 19308 3648 144 9 3 28 322 941 93 8 4282 4 26686 211 3601 3923 52 3397 1702 6 15035 29647 4 4 6804 1111 16 34 6 10 10601 9671 1561 9252 73 3\n",
            "I1209 17:37:22.313291 140407190394752 create_pretraining_data.py:197] input_ids: 2 13 2245 12 3640 180 4 3019 5 303 73 33 4 4 4 4 4 4 19 20017 853 15 311 11 4 130 15 118 110 55 1172 6 20 2866 4 21958 20 1942 6 19308 10 16081 7 87 19308 10 16081 258 4 4 31 32 969 3149 5622 10 15 5 91 9090 10 5 3746 20 19308 1450 7 262 313 42 5854 3828 11 19308 1450 2425 5 4144 61 26 20 8 19314 12 19308 3648 146 5 97 3149 511 12 19308 3648 144 9 3 28 322 941 93 8 4282 4 26686 211 3601 3923 52 3397 1702 6 15035 29647 4 4 6804 1111 16 34 6 10 10601 9671 1561 9252 73 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.313424 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.313517 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1\n",
            "I1209 17:37:22.313607 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 12 13 14 15 16 17 24 34 35 47 48 49 103 104 113 114 115 116 0\n",
            "I1209 17:37:22.313672 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 6 12 13 14 15 16 17 24 34 35 47 48 49 103 104 113 114 115 116 0\n",
            "INFO:tensorflow:masked_lm_ids: 765 20456 13 2611 7741 4306 52 19308 648 31 258 55 3097 6 1095 29 13479 9240 122 0\n",
            "I1209 17:37:22.313736 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 765 20456 13 2611 7741 4306 52 19308 648 31 258 55 3097 6 1095 29 13479 9240 122 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.313802 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.313860 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.314338 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [MASK] ▁conta ▁que ▁em ▁Janeiro ▁de [MASK] 88 [MASK] ▁o ▁exercito ▁do ▁Mestre ▁de ▁Avis ▁a per tava ▁o ▁cerco ▁a te ▁as ▁muralhas ▁da ▁vila , ▁enquanto ▁no ▁arraial , ▁em ▁volta ▁de ▁fogueira s , ▁ou via m - se ▁mulheres ▁a ▁cantar ▁Ge [MASK] [MASK] [MASK] ▁ao ▁som ▁de ▁gaita s ▁e ▁a du fe s . [SEP] ▁ser [MASK] [MASK] ▁sobretudo ▁a tra ves ▁da ▁tra dica o ▁oral , ▁onde ▁os ▁pormenores ▁varia vam ▁de [MASK] [MASK] [MASK] ▁conta dor , ▁sendo ▁muito ▁raros ▁os ▁exemplares ▁escritos ▁ou ▁publicados [MASK] [MASK] , ▁anteriores ▁ao ▁se culo ▁predominância . ▁Uma ▁dessas ▁verso es ▁e ▁publicada ▁a ▁18 ▁de ▁Outubro ▁de ▁1927 , ▁pelo [MASK] ▁escritor [MASK] ▁medi co ▁e ▁diplomata ▁Julio [SEP]\n",
            "I1209 17:37:22.314480 140407190394752 create_pretraining_data.py:187] tokens: [CLS] [MASK] [MASK] ▁conta ▁que ▁em ▁Janeiro ▁de [MASK] 88 [MASK] ▁o ▁exercito ▁do ▁Mestre ▁de ▁Avis ▁a per tava ▁o ▁cerco ▁a te ▁as ▁muralhas ▁da ▁vila , ▁enquanto ▁no ▁arraial , ▁em ▁volta ▁de ▁fogueira s , ▁ou via m - se ▁mulheres ▁a ▁cantar ▁Ge [MASK] [MASK] [MASK] ▁ao ▁som ▁de ▁gaita s ▁e ▁a du fe s . [SEP] ▁ser [MASK] [MASK] ▁sobretudo ▁a tra ves ▁da ▁tra dica o ▁oral , ▁onde ▁os ▁pormenores ▁varia vam ▁de [MASK] [MASK] [MASK] ▁conta dor , ▁sendo ▁muito ▁raros ▁os ▁exemplares ▁escritos ▁ou ▁publicados [MASK] [MASK] , ▁anteriores ▁ao ▁se culo ▁predominância . ▁Uma ▁dessas ▁verso es ▁e ▁publicada ▁a ▁18 ▁de ▁Outubro ▁de ▁1927 , ▁pelo [MASK] ▁escritor [MASK] ▁medi co ▁e ▁diplomata ▁Julio [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 4 414 15 14 245 6 4 3702 4 11 27156 12 4782 6 17592 8 895 11919 11 5420 8 204 40 9519 13 1925 5 271 22 29709 5 14 386 6 26711 10 5 51 1057 48 16 34 974 8 4322 2343 4 4 4 37 1193 6 15614 10 9 8 950 872 10 7 3 55 4 4 2637 8 797 2704 13 2383 4688 52 8538 5 80 32 29266 3117 373 6 4 4 4 414 472 5 92 126 11672 32 4976 3383 51 5081 4 4 5 1568 37 35 7224 22626 7 377 2377 10220 101 9 1279 8 519 6 1641 6 5141 5 57 4 1383 4 8902 238 9 9399 12308 3\n",
            "I1209 17:37:22.314600 140407190394752 create_pretraining_data.py:197] input_ids: 2 4 4 414 15 14 245 6 4 3702 4 11 27156 12 4782 6 17592 8 895 11919 11 5420 8 204 40 9519 13 1925 5 271 22 29709 5 14 386 6 26711 10 5 51 1057 48 16 34 974 8 4322 2343 4 4 4 37 1193 6 15614 10 9 8 950 872 10 7 3 55 4 4 2637 8 797 2704 13 2383 4688 52 8538 5 80 32 29266 3117 373 6 4 4 4 414 472 5 92 126 11672 32 4976 3383 51 5081 4 4 5 1568 37 35 7224 22626 7 377 2377 10220 101 9 1279 8 519 6 1641 6 5141 5 57 4 1383 4 8902 238 9 9399 12308 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.314697 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.314788 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            "I1209 17:37:22.314876 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 8 10 47 48 49 50 64 65 82 83 84 96 97 103 119 120 121 0\n",
            "I1209 17:37:22.314941 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 1 2 8 10 47 48 49 50 64 65 82 83 84 96 97 103 119 120 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 12695 5 366 5 9 1542 2903 41 18671 5 414 472 24 513 5485 1417 11 1383 5 0\n",
            "I1209 17:37:22.315004 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 12695 5 366 5 9 1542 2903 41 18671 5 414 472 24 513 5485 1417 11 1383 5 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.315068 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.315124 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.315605 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁O ▁clube ▁foi [MASK] [MASK] ▁ex - jogador ▁E der lane [MASK] , [MASK] [MASK] ▁proposta ▁de ▁resgatar ▁as ▁conquistas ▁do ▁futebol ▁da ▁cidade , ▁e nta o ▁bastante ▁Mongólia [MASK] ▁a mbi to ▁estadual [MASK] ▁gra cas ▁a ▁times ▁como ▁o ▁Conquista ▁EC , ▁Hu ma ita , ▁( lice ncia dos ) ▁o ▁Conquista ▁FC ▁e ▁o ▁Serrano [MASK] [MASK] . [SEP] ▁iniciado , ▁de ▁fato , ▁em ▁2001 , [MASK] [MASK] [MASK] ▁voltado ▁para ▁a ▁inclusa o ▁social [MASK] [MASK] [MASK] ▁de ▁preparar ▁os ▁futuros ▁atletas ▁para ▁o ▁clube ▁profissional . ▁Essa ▁proposta ▁e ▁consolida da ▁com ▁algumas ▁participa co es ▁em ▁campeonatos ▁locais ▁e ▁com ▁a ▁ex pan sa o ▁do ▁e nta o ▁examina [MASK] ▁Primeiro ▁Passo \" ▁para ▁outras ▁re [SEP]\n",
            "I1209 17:37:22.315737 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁O ▁clube ▁foi [MASK] [MASK] ▁ex - jogador ▁E der lane [MASK] , [MASK] [MASK] ▁proposta ▁de ▁resgatar ▁as ▁conquistas ▁do ▁futebol ▁da ▁cidade , ▁e nta o ▁bastante ▁Mongólia [MASK] ▁a mbi to ▁estadual [MASK] ▁gra cas ▁a ▁times ▁como ▁o ▁Conquista ▁EC , ▁Hu ma ita , ▁( lice ncia dos ) ▁o ▁Conquista ▁FC ▁e ▁o ▁Serrano [MASK] [MASK] . [SEP] ▁iniciado , ▁de ▁fato , ▁em ▁2001 , [MASK] [MASK] [MASK] ▁voltado ▁para ▁a ▁inclusa o ▁social [MASK] [MASK] [MASK] ▁de ▁preparar ▁os ▁futuros ▁atletas ▁para ▁o ▁clube ▁profissional . ▁Essa ▁proposta ▁e ▁consolida da ▁com ▁algumas ▁participa co es ▁em ▁campeonatos ▁locais ▁e ▁com ▁a ▁ex pan sa o ▁do ▁e nta o ▁examina [MASK] ▁Primeiro ▁Passo \" ▁para ▁outras ▁re [SEP]\n",
            "INFO:tensorflow:input_ids: 2 33 252 30 4 4 281 16 6742 179 690 16027 4 5 4 4 1941 6 13836 40 6284 12 503 13 83 5 9 1883 52 856 24562 4 8 3169 177 1697 4 4496 1607 8 4913 31 11 16128 13037 5 1524 295 808 5 29 5868 4428 174 46 11 16128 3537 9 11 16522 4 4 7 3 4628 5 6 586 5 14 1897 5 4 4 4 8383 24 8 29104 52 614 4 4 4 6 7940 32 10547 3846 24 11 252 943 7 1181 1941 9 12037 62 21 341 3553 238 101 14 5636 927 9 21 8 281 3287 372 52 12 9 1883 52 10723 4 3636 23290 27 24 205 172 3\n",
            "I1209 17:37:22.412984 140407190394752 create_pretraining_data.py:197] input_ids: 2 33 252 30 4 4 281 16 6742 179 690 16027 4 5 4 4 1941 6 13836 40 6284 12 503 13 83 5 9 1883 52 856 24562 4 8 3169 177 1697 4 4496 1607 8 4913 31 11 16128 13037 5 1524 295 808 5 29 5868 4428 174 46 11 16128 3537 9 11 16522 4 4 7 3 4628 5 6 586 5 14 1897 5 4 4 4 8383 24 8 29104 52 614 4 4 4 6 7940 32 10547 3846 24 11 252 943 7 1181 1941 9 12037 62 21 341 3553 238 101 14 5636 927 9 21 8 281 3287 372 52 12 9 1883 52 10723 4 3636 23290 27 24 205 172 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.413157 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.413264 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
            "I1209 17:37:22.413394 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 4 5 12 13 14 15 30 31 36 61 62 73 74 75 82 83 84 119 120 0\n",
            "I1209 17:37:22.413467 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 4 5 12 13 14 15 30 31 36 61 62 73 74 75 82 83 84 119 120 0\n",
            "INFO:tensorflow:masked_lm_ids: 1044 57 19584 5 21 8 1786 14 5 4053 1743 21 20 253 5 21 859 17 24781 0\n",
            "I1209 17:37:22.413534 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 1044 57 19584 5 21 8 1786 14 5 4053 1743 21 20 253 5 21 859 17 24781 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:22.413609 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:22.413671 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.414336 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] hara [MASK] ▁Barroso ▁clube ▁sabia ▁que ▁do ▁Nacional ▁ela ▁na o ▁tira va ▁nada , ▁mas ▁do ▁Rio ▁Negro ▁com ▁certeza ▁sair ia ▁algum ▁triunfo , ▁e ▁de ▁la ▁trouxeram ▁alguns ▁jogadores ▁de ▁certo ▁renome , ▁logo , [MASK] ▁clube ▁teria ▁como ▁seus ▁maiores ▁destaques [MASK] [MASK] ▁Ian [MASK] [MASK] ▁o ▁meia ▁Ro linha ▁e ▁o ▁centroavante ▁Den tinho . [SEP] [MASK] ▁momento ▁ja ▁aposentado , ▁reside ▁no ▁Rio ▁de [MASK] . [SEP]\n",
            "I1209 17:37:22.414515 140407190394752 create_pretraining_data.py:187] tokens: [CLS] hara [MASK] ▁Barroso ▁clube ▁sabia ▁que ▁do ▁Nacional ▁ela ▁na o ▁tira va ▁nada , ▁mas ▁do ▁Rio ▁Negro ▁com ▁certeza ▁sair ia ▁algum ▁triunfo , ▁e ▁de ▁la ▁trouxeram ▁alguns ▁jogadores ▁de ▁certo ▁renome , ▁logo , [MASK] ▁clube ▁teria ▁como ▁seus ▁maiores ▁destaques [MASK] [MASK] ▁Ian [MASK] [MASK] ▁o ▁meia ▁Ro linha ▁e ▁o ▁centroavante ▁Den tinho . [SEP] [MASK] ▁momento ▁ja ▁aposentado , ▁reside ▁no ▁Rio ▁de [MASK] . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 11080 4 15477 252 6707 15 12 338 157 25 52 4969 84 1801 5 68 12 176 3995 21 7314 2655 128 1195 10231 5 9 6 671 17120 215 1078 6 2185 9980 5 637 5 4 252 845 31 78 638 12457 4 4 8719 4 4 11 2869 997 5787 9 11 26309 9624 5899 7 3 4 684 3579 12843 5 9490 22 176 6 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.414642 140407190394752 create_pretraining_data.py:197] input_ids: 2 11080 4 15477 252 6707 15 12 338 157 25 52 4969 84 1801 5 68 12 176 3995 21 7314 2655 128 1195 10231 5 9 6 671 17120 215 1078 6 2185 9980 5 637 5 4 252 845 31 78 638 12457 4 4 8719 4 4 11 2869 997 5787 9 11 26309 9624 5899 7 3 4 684 3579 12843 5 9490 22 176 6 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.414743 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.414835 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.414933 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 3 39 46 47 48 49 50 62 71 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.414997 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 1 2 3 39 46 47 48 49 50 62 71 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 28 7257 12 11 11 3939 8719 70 5 1330 245 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.415060 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 28 7257 12 11 11 3939 8719 70 5 1330 245 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.415127 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.415185 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.415631 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Estende - se [MASK] [MASK] ▁a rea ▁de ▁33 , 39 ▁km 2. [SEP] ▁Mar ck ol sheim ▁e ▁uma ▁comuna ▁francesa ▁na [MASK] [MASK] [MASK] ▁administrativa ▁de ▁Grande ▁Leste , ▁no ▁departamento [MASK] ▁Reno . [SEP]\n",
            "I1209 17:37:22.415738 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁Estende - se [MASK] [MASK] ▁a rea ▁de ▁33 , 39 ▁km 2. [SEP] ▁Mar ck ol sheim ▁e ▁uma ▁comuna ▁francesa ▁na [MASK] [MASK] [MASK] ▁administrativa ▁de ▁Grande ▁Leste , ▁no ▁departamento [MASK] ▁Reno . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 161 16 34 4 4 8 3711 6 3470 5 3345 90 133 3 652 676 1508 16759 9 18 98 155 25 4 4 4 164 6 371 1780 5 22 154 4 2191 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.415848 140407190394752 create_pretraining_data.py:197] input_ids: 2 161 16 34 4 4 8 3711 6 3470 5 3345 90 133 3 652 676 1508 16759 9 18 98 155 25 4 4 4 164 6 371 1780 5 22 154 4 2191 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.415942 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.416031 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.416118 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 5 24 25 26 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.416182 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 4 5 24 25 26 34 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 26 18 172 2094 52 4283 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.416244 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 26 18 172 2094 52 4283 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.416335 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.416398 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:22.416809 140407190394752 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁\" Se ra ▁a ▁com enda ▁constitui da ▁por ▁Medalha ▁do ▁Bra sa o , ▁e s mal tada ▁em ▁cores ▁fixar [MASK] [MASK] ▁em ▁metal ▁ouro ▁ou ▁prata , ▁fin cada ▁a [MASK] [MASK] [MASK] ▁as ▁cores ▁municipais ▁acompanhada ▁de ▁Diploma ▁de [MASK] . \" [SEP] ▁Estende - se ▁por [MASK] ▁a rea [MASK] ▁24 , 61 ▁km 2. [SEP]\n",
            "I1209 17:37:22.416921 140407190394752 create_pretraining_data.py:187] tokens: [CLS] ▁\" Se ra ▁a ▁com enda ▁constitui da ▁por ▁Medalha ▁do ▁Bra sa o , ▁e s mal tada ▁em ▁cores ▁fixar [MASK] [MASK] ▁em ▁metal ▁ouro ▁ou ▁prata , ▁fin cada ▁a [MASK] [MASK] [MASK] ▁as ▁cores ▁municipais ▁acompanhada ▁de ▁Diploma ▁de [MASK] . \" [SEP] ▁Estende - se ▁por [MASK] ▁a rea [MASK] ▁24 , 61 ▁km 2. [SEP]\n",
            "INFO:tensorflow:input_ids: 2 17 1617 153 8 21 6038 4144 62 26 7637 12 2445 372 52 5 9 10 4082 2131 14 1665 16519 4 4 14 1229 1093 51 2855 5 11792 5105 8 4 4 4 40 1665 8020 7776 6 24163 6 4 7 27 3 161 16 34 26 4 8 3711 4 618 5 4112 90 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.417036 140407190394752 create_pretraining_data.py:197] input_ids: 2 17 1617 153 8 21 6038 4144 62 26 7637 12 2445 372 52 5 9 10 4082 2131 14 1665 16519 4 4 14 1229 1093 51 2855 5 11792 5105 8 4 4 4 40 1665 8020 7776 6 24163 6 4 7 27 3 161 16 34 26 4 8 3711 4 618 5 4112 90 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.417142 140407190394752 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.417244 140407190394752 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.417350 140407190394752 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 22 23 24 34 35 36 44 52 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.417419 140407190394752 create_pretraining_data.py:197] masked_lm_positions: 22 23 24 34 35 36 44 52 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 51 7715 671 13894 21 1212 18 6 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:22.417483 140407190394752 create_pretraining_data.py:197] masked_lm_ids: 5 51 7715 671 13894 21 1212 18 6 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:22.417547 140407190394752 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:22.417605 140407190394752 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:number of instances: 270441\n",
            "I1209 17:37:31.242162 140687693150080 create_pretraining_data.py:638] number of instances: 270441\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I1209 17:37:31.242980 140687693150080 create_pretraining_data.py:641] *** Writing to output files ***\n",
            "INFO:tensorflow:  gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0000.tfrecord\n",
            "I1209 17:37:31.243058 140687693150080 create_pretraining_data.py:643]   gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0000.tfrecord\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1209 17:37:31.243281 140687693150080 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.244411 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁portugueses ▁de ▁sempre . ▁Entre [MASK] [MASK] 67 ▁e ▁1974 / 75 ▁representou [MASK] [MASK] , ▁clube ▁do ▁qual ▁era ▁adepto ▁confe sso . [MASK] [MASK] [MASK] [MASK] ▁para ▁a ▁equipa ▁espanhola ▁do ▁Racing ▁de ▁Santander , ▁onde ▁jogou ▁entre ▁1975 / 76 ▁e ▁1979 / 80 , ▁tendo ▁sido ▁por ▁uma ▁vez ▁considerado ▁o ▁melhor ▁estrangeiro ▁a ▁jogar ▁em ▁Espanha . ▁Voltou ▁a ▁Portugal ▁para ▁jogar [MASK] [MASK] [MASK] ▁de ▁Gui mara es ▁entre ▁1980 / 81 ▁e ▁1982 / 83 , [SEP] ▁Vitor ▁Manuel ▁Afonso [MASK] [MASK] [MASK] ▁Oliveira ▁( Lisboa , ▁8 ▁de ▁outubro ▁de ▁1947 ▁- ▁Lisboa , ▁13 [MASK] ▁setembro ▁de ▁2003) ▁foi ▁um ▁jogador ▁de ▁futebol ▁por tu gues . ▁Morreu ▁com ▁somente ▁55 ▁anos , ▁vitima [MASK] [MASK] [MASK] [SEP]\n",
            "I1209 17:37:31.244607 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁portugueses ▁de ▁sempre . ▁Entre [MASK] [MASK] 67 ▁e ▁1974 / 75 ▁representou [MASK] [MASK] , ▁clube ▁do ▁qual ▁era ▁adepto ▁confe sso . [MASK] [MASK] [MASK] [MASK] ▁para ▁a ▁equipa ▁espanhola ▁do ▁Racing ▁de ▁Santander , ▁onde ▁jogou ▁entre ▁1975 / 76 ▁e ▁1979 / 80 , ▁tendo ▁sido ▁por ▁uma ▁vez ▁considerado ▁o ▁melhor ▁estrangeiro ▁a ▁jogar ▁em ▁Espanha . ▁Voltou ▁a ▁Portugal ▁para ▁jogar [MASK] [MASK] [MASK] ▁de ▁Gui mara es ▁entre ▁1980 / 81 ▁e ▁1982 / 83 , [SEP] ▁Vitor ▁Manuel ▁Afonso [MASK] [MASK] [MASK] ▁Oliveira ▁( Lisboa , ▁8 ▁de ▁outubro ▁de ▁1947 ▁- ▁Lisboa , ▁13 [MASK] ▁setembro ▁de ▁2003) ▁foi ▁um ▁jogador ▁de ▁futebol ▁por tu gues . ▁Morreu ▁com ▁somente ▁55 ▁anos , ▁vitima [MASK] [MASK] [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 2278 6 411 7 615 4 4 4410 9 5087 104 4069 7523 4 4 5 252 12 170 71 26754 15698 1147 7 4 4 4 4 24 8 1894 3629 12 12977 6 23891 5 80 3408 60 2463 104 3838 9 4938 104 2216 5 169 131 26 18 140 590 11 328 6856 8 2138 14 929 7 11724 8 280 24 2138 4 4 4 6 9792 10672 101 60 2648 104 3812 9 4303 104 4179 5 3 11548 1110 2412 4 4 4 1707 29 6760 5 303 6 389 6 3203 81 658 5 366 4 415 6 18029 30 20 700 6 503 26 835 7657 7 7105 21 753 5496 66 5 18876 4 4 4 3\n",
            "I1209 17:37:31.244757 140687693150080 create_pretraining_data.py:197] input_ids: 2 2278 6 411 7 615 4 4 4410 9 5087 104 4069 7523 4 4 5 252 12 170 71 26754 15698 1147 7 4 4 4 4 24 8 1894 3629 12 12977 6 23891 5 80 3408 60 2463 104 3838 9 4938 104 2216 5 169 131 26 18 140 590 11 328 6856 8 2138 14 929 7 11724 8 280 24 2138 4 4 4 6 9792 10672 101 60 2648 104 3812 9 4303 104 4179 5 3 11548 1110 2412 4 4 4 1707 29 6760 5 303 6 389 6 3203 81 658 5 366 4 415 6 18029 30 20 700 6 503 26 835 7657 7 7105 21 753 5496 66 5 18876 4 4 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.244864 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.244962 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.245054 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 7 12 14 15 25 26 27 28 68 69 70 88 89 90 104 124 125 126 0\n",
            "I1209 17:37:31.245121 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 6 7 12 14 15 25 26 27 28 68 69 70 88 89 90 104 124 125 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 5973 104 4069 11 5654 27855 16 34 115 57 11548 128 14476 10 6 6 6 9100 7 0\n",
            "I1209 17:37:31.245186 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 5973 104 4069 11 5654 27855 16 34 115 57 11548 128 14476 10 6 6 6 9100 7 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.245257 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.245343 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.245838 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Globo ▁lhe ▁ ren dia ▁apenas ▁R $ ▁200 ▁mensais ▁– ▁salvo [MASK] [MASK] ▁ganhos ▁com ▁shows ▁e ▁vendas ▁de ▁al bun s ▁– ▁e ▁que ▁a ▁emissora ▁na o ▁havia ▁cumprido ▁com ▁as ▁obriga co es ▁de ▁divulga ca o ▁de ▁seu ▁trabalho , ▁uma ▁vez ▁que [MASK] [MASK] ▁um ▁apenas ▁um ▁videoclipe , [MASK] ▁qual ▁foi ▁exibido ▁somente ▁no ▁\"\" ▁– ▁programa ▁espanhol ▁que ▁deu [SEP] ▁A pesar ▁de ▁ter ▁ganho ▁a ▁e dica o , [MASK] ▁Jackson ▁passou ▁por ▁diversos ▁problemas ▁com ▁a ▁Rede ▁Globo , [MASK] [MASK] ▁que ▁foi ▁impe dida ▁de ▁se ▁apresentar ▁em ▁outras ▁emissoras , ▁embora ▁tambem ▁na o ▁tivesse [MASK] co [MASK] [MASK] [MASK] ▁prop rio s ▁programas ▁do ▁canal : ▁vítimas [MASK] [MASK] [MASK] ▁qualquer ▁carreira . [SEP]\n",
            "I1209 17:37:31.245972 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁Globo ▁lhe ▁ ren dia ▁apenas ▁R $ ▁200 ▁mensais ▁– ▁salvo [MASK] [MASK] ▁ganhos ▁com ▁shows ▁e ▁vendas ▁de ▁al bun s ▁– ▁e ▁que ▁a ▁emissora ▁na o ▁havia ▁cumprido ▁com ▁as ▁obriga co es ▁de ▁divulga ca o ▁de ▁seu ▁trabalho , ▁uma ▁vez ▁que [MASK] [MASK] ▁um ▁apenas ▁um ▁videoclipe , [MASK] ▁qual ▁foi ▁exibido ▁somente ▁no ▁\"\" ▁– ▁programa ▁espanhol ▁que ▁deu [SEP] ▁A pesar ▁de ▁ter ▁ganho ▁a ▁e dica o , [MASK] ▁Jackson ▁passou ▁por ▁diversos ▁problemas ▁com ▁a ▁Rede ▁Globo , [MASK] [MASK] ▁que ▁foi ▁impe dida ▁de ▁se ▁apresentar ▁em ▁outras ▁emissoras , ▁embora ▁tambem ▁na o ▁tivesse [MASK] co [MASK] [MASK] [MASK] ▁prop rio s ▁programas ▁do ▁canal : ▁vítimas [MASK] [MASK] [MASK] ▁qualquer ▁carreira . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 698 588 19 2354 735 139 399 1260 1939 25882 355 8594 4 4 11653 21 1999 9 2312 6 980 13221 10 355 9 15 8 1056 25 52 282 23592 21 40 8729 238 101 6 13911 228 52 6 44 253 5 18 140 15 4 4 20 139 20 4278 5 4 170 30 2202 753 22 283 355 301 1911 15 863 3 28 302 6 137 8252 8 9 4688 52 5 4 2462 310 26 531 683 21 8 783 698 5 4 4 15 30 6830 7045 6 35 1868 14 205 6081 5 578 27557 25 52 3641 4 238 4 4 4 9592 1561 10 1094 12 947 42 5083 4 4 4 401 327 7 3\n",
            "I1209 17:37:31.246095 140687693150080 create_pretraining_data.py:197] input_ids: 2 698 588 19 2354 735 139 399 1260 1939 25882 355 8594 4 4 11653 21 1999 9 2312 6 980 13221 10 355 9 15 8 1056 25 52 282 23592 21 40 8729 238 101 6 13911 228 52 6 44 253 5 18 140 15 4 4 20 139 20 4278 5 4 170 30 2202 753 22 283 355 301 1911 15 863 3 28 302 6 137 8252 8 9 4688 52 5 4 2462 310 26 531 683 21 8 783 698 5 4 4 15 30 6830 7045 6 35 1868 14 205 6081 5 578 27557 25 52 3641 4 238 4 4 4 9592 1561 10 1094 12 947 42 5083 4 4 4 401 327 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.246195 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.246290 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
            "I1209 17:37:31.246417 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 13 14 49 50 56 78 79 90 91 92 108 109 110 111 112 120 121 122 123 0\n",
            "I1209 17:37:31.246484 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 13 14 49 50 56 78 79 90 91 92 108 109 110 111 112 120 121 122 123 0\n",
            "INFO:tensorflow:masked_lm_ids: 32 1608 157 2119 11 5 14057 18 140 15 11879 238 24 4322 85 17 11173 18855 17132 0\n",
            "I1209 17:37:31.246549 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 32 1608 157 2119 11 5 14057 18 140 15 11879 238 24 4322 85 17 11173 18855 17132 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.246616 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.246674 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.247137 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Eles ▁gravaram ▁uma [MASK] ▁quantidade ▁de ▁material ▁como ▁um ▁trio ▁a te ▁1994 , ▁quando ▁Montevidéu ▁deixou ▁a ▁forma ca o , ▁por ▁estar ▁descontente ▁com ▁a ▁uni ao ▁do ▁Mu ti ila tion [MASK] ▁movimento ▁Les ▁Legio ns ▁No ires . [SEP] , ▁o ▁Mu ti ila tion ▁ lan cou ▁um ▁Poder ▁em ▁homenagem ▁ao ▁movimento ▁intitulado ▁\" Ha il ▁Satan as ▁We ▁Are ▁the ▁Black ▁Legio ns \". ▁Pouco ▁tempo ▁depois , ▁Dark [MASK] [MASK] [MASK] ▁iguais ▁Sil ence ▁foi ▁substitui do ▁por ▁Kri ssa gra za be th [MASK] ▁que ▁participou [MASK] ▁grava co es ▁da ▁banda [MASK] [MASK] ▁o ▁\" Vamp ires ▁of ▁Black ▁Imperial [MASK] [MASK] [MASK] ▁da ▁banda ▁mais ▁uma ▁vez ▁devido ▁a ▁discorda ncia s [MASK] [MASK] [MASK] [SEP]\n",
            "I1209 17:37:31.247269 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁Eles ▁gravaram ▁uma [MASK] ▁quantidade ▁de ▁material ▁como ▁um ▁trio ▁a te ▁1994 , ▁quando ▁Montevidéu ▁deixou ▁a ▁forma ca o , ▁por ▁estar ▁descontente ▁com ▁a ▁uni ao ▁do ▁Mu ti ila tion [MASK] ▁movimento ▁Les ▁Legio ns ▁No ires . [SEP] , ▁o ▁Mu ti ila tion ▁ lan cou ▁um ▁Poder ▁em ▁homenagem ▁ao ▁movimento ▁intitulado ▁\" Ha il ▁Satan as ▁We ▁Are ▁the ▁Black ▁Legio ns \". ▁Pouco ▁tempo ▁depois , ▁Dark [MASK] [MASK] [MASK] ▁iguais ▁Sil ence ▁foi ▁substitui do ▁por ▁Kri ssa gra za be th [MASK] ▁que ▁participou [MASK] ▁grava co es ▁da ▁banda [MASK] [MASK] ▁o ▁\" Vamp ires ▁of ▁Black ▁Imperial [MASK] [MASK] [MASK] ▁da ▁banda ▁mais ▁uma ▁vez ▁devido ▁a ▁discorda ncia s [MASK] [MASK] [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1146 12427 18 4 1376 6 1010 31 20 6146 8 204 2795 5 91 13557 960 8 129 228 52 5 26 945 23504 21 8 3282 8372 12 1503 560 2903 1415 4 597 4728 19593 2716 67 15668 7 3 5 11 1503 560 2903 1415 19 1818 4465 20 5004 14 1308 37 597 1904 17 3637 1006 18227 422 2790 8723 359 2911 19593 2716 63 3154 152 115 5 7235 4 4 4 6637 6630 4990 30 10188 61 26 13640 1612 2080 809 596 566 4 15 790 4 7693 238 101 13 147 4 4 11 17 23888 15668 223 2911 3231 4 4 4 13 147 39 18 140 317 8 17082 4428 10 4 4 4 3\n",
            "I1209 17:37:31.247419 140687693150080 create_pretraining_data.py:197] input_ids: 2 1146 12427 18 4 1376 6 1010 31 20 6146 8 204 2795 5 91 13557 960 8 129 228 52 5 26 945 23504 21 8 3282 8372 12 1503 560 2903 1415 4 597 4728 19593 2716 67 15668 7 3 5 11 1503 560 2903 1415 19 1818 4465 20 5004 14 1308 37 597 1904 17 3637 1006 18227 422 2790 8723 359 2911 19593 2716 63 3154 152 115 5 7235 4 4 4 6637 6630 4990 30 10188 61 26 13640 1612 2080 809 596 566 4 15 790 4 7693 238 101 13 147 4 4 11 17 23888 15668 223 2911 3231 4 4 4 13 147 39 18 140 317 8 17082 4428 10 4 4 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.247521 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.247615 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n",
            "I1209 17:37:31.247704 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 4 16 35 54 77 78 79 80 93 96 102 103 111 112 113 114 124 125 126 0\n",
            "I1209 17:37:31.247783 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 4 16 35 54 77 78 79 80 93 96 102 103 111 112 113 114 124 125 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 113 1261 37 3467 3033 6768 2036 223 5 53 8 204 11628 47 9932 13 19 2323 6411 0\n",
            "I1209 17:37:31.247847 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 113 1261 37 3467 3033 6768 2036 223 5 53 8 204 11628 47 9932 13 19 2323 6411 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.247919 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:31.263014 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.263674 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁tri col pa dos ▁( sul co , ▁iso polar es ▁e ▁cla va dos [MASK] [MASK] [MASK] ▁abertura ). . ▁As ▁principais ▁espe cie s ▁ocorre ntes ▁nativas ▁do ▁Brasil [MASK] [MASK] [MASK] ▁gene ros ▁ Dendro ban gia ▁e ▁Ci tron ella , ▁onde ▁somente ▁a ▁ultima ▁e ▁ocorre nte ▁nas ▁re gio es ▁Sul ▁e ▁Sudeste ▁com ▁dois ▁tipos ▁de [SEP] mil ia ▁e ▁caracterizada ▁por ▁plantas ▁de ▁flores ▁pequenas ▁bi ▁ou ▁uni sse [MASK] [MASK] [MASK] [MASK] [MASK] ▁filotaxia ▁foliar ▁espiral ada ▁ou ▁oposta . [MASK] ▁folhas ▁podem ▁ou ▁na o ▁conter ▁espi cula s ▁e ▁os ▁frutos ▁sa o [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁vermelha ▁ou ▁marrom ), ▁este , ▁podendo ▁ser ▁distribui dos ▁a ▁outros ▁ambientes ▁por ▁agentes [SEP]\n",
            "I1209 17:37:31.263832 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁tri col pa dos ▁( sul co , ▁iso polar es ▁e ▁cla va dos [MASK] [MASK] [MASK] ▁abertura ). . ▁As ▁principais ▁espe cie s ▁ocorre ntes ▁nativas ▁do ▁Brasil [MASK] [MASK] [MASK] ▁gene ros ▁ Dendro ban gia ▁e ▁Ci tron ella , ▁onde ▁somente ▁a ▁ultima ▁e ▁ocorre nte ▁nas ▁re gio es ▁Sul ▁e ▁Sudeste ▁com ▁dois ▁tipos ▁de [SEP] mil ia ▁e ▁caracterizada ▁por ▁plantas ▁de ▁flores ▁pequenas ▁bi ▁ou ▁uni sse [MASK] [MASK] [MASK] [MASK] [MASK] ▁filotaxia ▁foliar ▁espiral ada ▁ou ▁oposta . [MASK] ▁folhas ▁podem ▁ou ▁na o ▁conter ▁espi cula s ▁e ▁os ▁frutos ▁sa o [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁vermelha ▁ou ▁marrom ), ▁este , ▁podendo ▁ser ▁distribui dos ▁a ▁outros ▁ambientes ▁por ▁agentes [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1815 4146 534 174 29 5412 238 5 7500 18351 101 9 7807 84 174 4 4 4 1502 73 7 134 443 8073 6686 10 1104 689 14572 12 94 4 4 4 7301 2361 19 27767 3141 2094 9 1726 6818 3278 5 80 753 8 14416 9 1104 291 107 172 2618 101 285 9 9127 21 97 1201 6 3 4607 128 9 7575 26 1405 6 2244 1822 1595 51 3282 502 4 4 4 4 4 28782 23417 15946 497 51 15690 7 4 2086 258 51 25 52 5691 9132 5248 10 9 32 4858 1577 52 4 4 4 4 4 4 4 5506 51 13511 59 211 5 2266 55 9829 174 8 114 5392 26 4713 3\n",
            "I1209 17:37:31.263972 140687693150080 create_pretraining_data.py:197] input_ids: 2 1815 4146 534 174 29 5412 238 5 7500 18351 101 9 7807 84 174 4 4 4 1502 73 7 134 443 8073 6686 10 1104 689 14572 12 94 4 4 4 7301 2361 19 27767 3141 2094 9 1726 6818 3278 5 80 753 8 14416 9 1104 291 107 172 2618 101 285 9 9127 21 97 1201 6 3 4607 128 9 7575 26 1405 6 2244 1822 1595 51 3282 502 4 4 4 4 4 28782 23417 15946 497 51 15690 7 4 2086 258 51 25 52 5691 9132 5248 10 9 32 4858 1577 52 4 4 4 4 4 4 4 5506 51 13511 59 211 5 2266 55 9829 174 8 114 5392 26 4713 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.264078 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.264174 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
            "I1209 17:37:31.264265 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 16 17 18 32 33 34 78 79 80 81 82 90 105 106 107 108 109 110 111 0\n",
            "I1209 17:37:31.264386 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 16 17 18 32 33 34 78 79 80 81 82 90 105 106 107 108 109 110 111 0\n",
            "INFO:tensorflow:masked_lm_ids: 31 129 6 1577 52 36 305 64 1251 5 21 134 11807 10 239 29 8774 4306 52 0\n",
            "I1209 17:37:31.264454 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 31 129 6 1577 52 36 305 64 1251 5 21 134 11807 10 239 29 8774 4306 52 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.264537 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.264599 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.265068 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁mediante ▁Portaria , ▁poder ao [MASK] ▁constitui das ▁outras ▁com isso es , ▁de ▁cara ter ▁tempo ra rio . ▁O ▁Conselho ▁Economic o ▁e ▁Financeiro ▁( CE F ), ▁composto ▁por ▁um ▁búlgaros [MASK] , [MASK] ▁pelo ▁Comandante - Geral , ▁e ▁por ▁um ▁conselho ▁fiscal , ▁presidido ▁pelo ▁Corre ge dor [MASK] Geral , ▁ter a ▁por ▁finalidade ▁aplicar ▁os [MASK] [SEP] [MASK] ▁Diretoria ▁de ▁Ensino [MASK] ▁Pesquisa ▁- ▁D EP ▁Diretoria ▁de ▁Sau de ▁- ▁DS [MASK] [MASK] ▁Apoio ▁Log is tico ▁- ▁D AL ▁Diretoria ▁de ▁Fina nca s ▁- ▁DF ▁Diretoria ▁Graça ▁Desenvolvimento ▁Te c no lo gico ▁e ▁Qualidade ▁- ▁D DT Q ▁Diretoria ▁de Orient ▁Com uni taria ▁de [MASK] ▁Humanos ▁- [MASK] ▁pí ▁Eugène [MASK] ▁Gabinete ▁do ▁Comandante [SEP]\n",
            "I1209 17:37:31.265196 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁mediante ▁Portaria , ▁poder ao [MASK] ▁constitui das ▁outras ▁com isso es , ▁de ▁cara ter ▁tempo ra rio . ▁O ▁Conselho ▁Economic o ▁e ▁Financeiro ▁( CE F ), ▁composto ▁por ▁um ▁búlgaros [MASK] , [MASK] ▁pelo ▁Comandante - Geral , ▁e ▁por ▁um ▁conselho ▁fiscal , ▁presidido ▁pelo ▁Corre ge dor [MASK] Geral , ▁ter a ▁por ▁finalidade ▁aplicar ▁os [MASK] [SEP] [MASK] ▁Diretoria ▁de ▁Ensino [MASK] ▁Pesquisa ▁- ▁D EP ▁Diretoria ▁de ▁Sau de ▁- ▁DS [MASK] [MASK] ▁Apoio ▁Log is tico ▁- ▁D AL ▁Diretoria ▁de ▁Fina nca s ▁- ▁DF ▁Diretoria ▁Graça ▁Desenvolvimento ▁Te c no lo gico ▁e ▁Qualidade ▁- ▁D DT Q ▁Diretoria ▁de Orient ▁Com uni taria ▁de [MASK] ▁Humanos ▁- [MASK] ▁pí ▁Eugène [MASK] ▁Gabinete ▁do ▁Comandante [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5240 21345 5 477 8372 4 4144 190 205 21 16455 101 5 6 3635 410 152 153 1561 7 33 968 27173 52 9 27656 29 4895 459 59 1450 26 20 11431 4 5 4 57 13142 16 6929 5 9 26 20 4585 10814 5 16189 57 9217 668 472 4 6929 5 137 49 26 4336 9021 32 4 3 4 15490 6 6438 4 6717 81 183 8262 15490 6 11404 103 81 11440 4 4 18890 20154 194 3116 81 183 6237 15490 6 18455 3970 10 81 16891 15490 10277 4480 1284 180 171 145 8622 9 20197 81 183 18113 3659 15490 6 20241 173 6826 13935 6 4 11143 81 4 16366 25608 4 14723 12 13142 3\n",
            "I1209 17:37:31.265331 140687693150080 create_pretraining_data.py:197] input_ids: 2 5240 21345 5 477 8372 4 4144 190 205 21 16455 101 5 6 3635 410 152 153 1561 7 33 968 27173 52 9 27656 29 4895 459 59 1450 26 20 11431 4 5 4 57 13142 16 6929 5 9 26 20 4585 10814 5 16189 57 9217 668 472 4 6929 5 137 49 26 4336 9021 32 4 3 4 15490 6 6438 4 6717 81 183 8262 15490 6 11404 103 81 11440 4 4 18890 20154 194 3116 81 183 6237 15490 6 18455 3970 10 81 16891 15490 10277 4480 1284 180 171 145 8622 9 20197 81 183 18113 3659 15490 6 20241 173 6826 13935 6 4 11143 81 4 16366 25608 4 14723 12 13142 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.265436 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.265537 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1\n",
            "I1209 17:37:31.265629 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 34 35 37 54 55 63 65 69 80 81 97 112 117 120 121 122 123 124 0\n",
            "I1209 17:37:31.265695 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 6 34 35 37 54 55 63 65 69 80 81 97 112 117 120 121 122 123 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 55 4585 716 16189 16 6929 1288 9089 9 15490 6 6 21171 10302 183 6074 13193 489 14723 0\n",
            "I1209 17:37:31.265758 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 55 4585 716 16189 16 6929 1288 9089 9 15490 6 6 21171 10302 183 6074 13193 489 14723 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.265823 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.265880 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.266281 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Os ▁coeficiente s ▁de ▁di lata ca o ▁linear ▁de ▁algumas [MASK] [MASK] [MASK] [MASK] [MASK] ▁elementos ▁qui mico s ▁a ▁seguir ▁indicados ▁aplica m - se ▁a ▁faixa ▁de ▁temperaturas ▁indicada . ▁Quando ▁na o ▁indicada ▁presume [MASK] [MASK] ▁uma ▁temperatura ▁ambiente . [SEP] ▁Na ▁realidade ▁estes ▁coeficiente s ▁variam ▁com ▁a ▁temperatura ▁mas ▁assume [MASK] [MASK] ▁a ▁sua ▁e xa tida o ▁na ▁faixa ▁mostrada [MASK] [SEP]\n",
            "I1209 17:37:31.266403 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁Os ▁coeficiente s ▁de ▁di lata ca o ▁linear ▁de ▁algumas [MASK] [MASK] [MASK] [MASK] [MASK] ▁elementos ▁qui mico s ▁a ▁seguir ▁indicados ▁aplica m - se ▁a ▁faixa ▁de ▁temperaturas ▁indicada . ▁Quando ▁na o ▁indicada ▁presume [MASK] [MASK] ▁uma ▁temperatura ▁ambiente . [SEP] ▁Na ▁realidade ▁estes ▁coeficiente s ▁variam ▁com ▁a ▁temperatura ▁mas ▁assume [MASK] [MASK] ▁a ▁sua ▁e xa tida o ▁na ▁faixa ▁mostrada [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 87 12208 10 6 719 7808 228 52 6845 6 341 4 4 4 4 4 969 4790 5622 10 8 1558 15559 5395 48 16 34 8 973 6 6089 2990 7 486 25 52 2990 28673 4 4 18 2271 1343 7 3 95 1750 1232 12208 10 7388 21 8 2271 68 4091 4 4 8 38 9 2130 6394 52 25 973 11884 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.266525 140687693150080 create_pretraining_data.py:197] input_ids: 2 87 12208 10 6 719 7808 228 52 6845 6 341 4 4 4 4 4 969 4790 5622 10 8 1558 15559 5395 48 16 34 8 973 6 6089 2990 7 486 25 52 2990 28673 4 4 18 2271 1343 7 3 95 1750 1232 12208 10 7388 21 8 2271 68 4091 4 4 8 38 9 2130 6394 52 25 973 11884 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.266627 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.266721 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.266811 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 12 13 14 15 16 39 40 57 58 68 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.266875 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 12 13 14 15 16 39 40 57 58 68 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 651 1198 4428 10 9 16 34 16 34 7 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.266939 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 651 1198 4428 10 9 16 34 16 34 7 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:31.267004 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:31.267060 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.267447 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Me ek s ▁tocou ▁todos ▁os [MASK] . [SEP] ▁O ▁album ▁na o ▁teve [MASK] ▁vendas , ▁ainda ▁mais ▁se ▁comparado ▁ao ▁primeiro ▁CD ▁da ▁banda : ▁\" Green \" [MASK] [MASK] [MASK] ▁copia s . [SEP]\n",
            "I1209 17:37:31.267553 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁Me ek s ▁tocou ▁todos ▁os [MASK] . [SEP] ▁O ▁album ▁na o ▁teve [MASK] ▁vendas , ▁ainda ▁mais ▁se ▁comparado ▁ao ▁primeiro ▁CD ▁da ▁banda : ▁\" Green \" [MASK] [MASK] [MASK] ▁copia s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 617 3761 10 5775 187 32 4 7 3 33 22876 25 52 198 4 2312 5 108 39 35 6362 37 86 1384 13 147 42 17 24268 27 4 4 4 11112 10 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.267678 140687693150080 create_pretraining_data.py:197] input_ids: 2 617 3761 10 5775 187 32 4 7 3 33 22876 25 52 198 4 2312 5 108 39 35 6362 37 86 1384 13 147 42 17 24268 27 4 4 4 11112 10 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.267785 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.267888 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.267977 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 6 7 15 31 32 33 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.268042 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 6 7 15 31 32 33 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 32 2562 4900 2940 17442 424 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.268110 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 32 2562 4900 2940 17442 424 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:31.268174 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:31.268232 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.268696 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] _ 40 ▁O ▁sinal ▁original ▁pode ▁ser ▁perfeitamente [MASK] [MASK] [MASK] ▁a ▁partir ▁da ▁soma ▁das ▁fun co es ▁\" d [MASK] [MASK] [MASK] ▁Assim , iço ▁representa ca o ▁por ▁meio [MASK] [MASK] [MASK] ▁divulgou ▁\" d ( t )\" ▁na o ▁leva [MASK] [MASK] [MASK] ▁informa ca o ▁e ▁ainda ▁constitui ▁uma ▁representa ca o ▁mais ▁compacta ▁de ▁\" f ( [SEP] ▁e ▁dada ▁exatamente ▁pelo ▁conjunto ▁das ▁fun co es ▁\" g ( t )\", ▁constitui ▁uma ▁red unda ncia , [MASK] [MASK] [MASK] ▁no ▁processo . ▁A ▁fun co es ▁\" d ( t )\" ▁podem ▁ser ▁computa das ▁de ▁outra ▁forma : ▁por ▁meio ▁berbere ▁uma ▁filtra gem ▁obtida ▁pela ▁corre la ca o ▁do ▁sinal ▁filtra do ▁com ▁uma ▁fun [SEP]\n",
            "I1209 17:37:31.268826 140687693150080 create_pretraining_data.py:187] tokens: [CLS] _ 40 ▁O ▁sinal ▁original ▁pode ▁ser ▁perfeitamente [MASK] [MASK] [MASK] ▁a ▁partir ▁da ▁soma ▁das ▁fun co es ▁\" d [MASK] [MASK] [MASK] ▁Assim , iço ▁representa ca o ▁por ▁meio [MASK] [MASK] [MASK] ▁divulgou ▁\" d ( t )\" ▁na o ▁leva [MASK] [MASK] [MASK] ▁informa ca o ▁e ▁ainda ▁constitui ▁uma ▁representa ca o ▁mais ▁compacta ▁de ▁\" f ( [SEP] ▁e ▁dada ▁exatamente ▁pelo ▁conjunto ▁das ▁fun co es ▁\" g ( t )\", ▁constitui ▁uma ▁red unda ncia , [MASK] [MASK] [MASK] ▁no ▁processo . ▁A ▁fun co es ▁\" d ( t )\" ▁podem ▁ser ▁computa das ▁de ▁outra ▁forma : ▁por ▁meio ▁berbere ▁uma ▁filtra gem ▁obtida ▁pela ▁corre la ca o ▁do ▁sinal ▁filtra do ▁com ▁uma ▁fun [SEP]\n",
            "INFO:tensorflow:input_ids: 2 2828 2242 33 1951 605 110 55 11989 4 4 4 8 192 13 3382 53 12232 238 101 17 143 4 4 4 692 5 13246 1800 228 52 26 299 4 4 4 11022 17 143 765 105 5428 25 52 1553 4 4 4 5589 228 52 9 108 4144 18 1800 228 52 39 13261 6 17 407 765 3 9 3350 4549 57 584 53 12232 238 101 17 286 765 105 11582 4144 18 16726 12217 4428 5 4 4 4 22 420 7 28 12232 238 101 17 143 765 105 5428 258 55 19751 190 6 522 129 42 26 299 24198 18 15367 1047 9545 54 3759 135 228 52 12 1951 15367 61 21 18 12232 3\n",
            "I1209 17:37:31.268945 140687693150080 create_pretraining_data.py:197] input_ids: 2 2828 2242 33 1951 605 110 55 11989 4 4 4 8 192 13 3382 53 12232 238 101 17 143 4 4 4 692 5 13246 1800 228 52 26 299 4 4 4 11022 17 143 765 105 5428 25 52 1553 4 4 4 5589 228 52 9 108 4144 18 1800 228 52 39 13261 6 17 407 765 3 9 3350 4549 57 584 53 12232 238 101 17 286 765 105 11582 4144 18 16726 12217 4428 5 4 4 4 22 420 7 28 12232 238 101 17 143 765 105 5428 258 55 19751 190 6 522 129 42 26 299 24198 18 15367 1047 9545 54 3759 135 228 52 12 1951 15367 61 21 18 12232 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.365673 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.365992 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1\n",
            "I1209 17:37:31.366108 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 0 0 1 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 9 10 11 22 23 24 27 33 34 35 36 45 46 47 85 86 87 110 121 0\n",
            "I1209 17:37:31.366188 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 9 10 11 22 23 24 27 33 34 35 36 45 46 47 85 86 87 110 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 7175 3555 1787 765 105 16143 8 53 12232 238 101 8 2294 6 15 30 14552 6 1951 0\n",
            "I1209 17:37:31.366261 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 7175 3555 1787 765 105 16143 8 53 12232 238 101 8 2294 6 15 30 14552 6 1951 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.366364 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:31.366430 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.367128 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁A ▁musica ▁considerados [MASK] ▁por ▁um ▁total ▁de ▁nove ▁semanas . ▁De ▁acordo ▁com ▁a ▁O fficial ▁Chart s ▁Company , ▁a ▁can ca o ▁ja ▁vendeu ▁2 ▁visitado ▁Pampulha ▁copia s ▁60, . ▁Na ▁Alemanha , [MASK] [MASK] [MASK] o [MASK] ▁na ▁parada ▁Media ▁Control ▁Chart s ▁na ▁pos ica o ▁66 ▁em ▁29 ▁de ▁setembro ▁de ▁1987 [MASK] ▁e ▁subiu ▁a te [MASK] ▁pos ica o ▁14 ▁em ▁sua ▁terceira ▁semana , ▁e ▁passou ▁12 ▁semanas [MASK] ▁parada . [SEP] ▁No ▁Reino ▁Unido , ▁\" Ca us ing ▁a ▁Com motion \" ▁foi ▁ lan cada ▁em ▁19 ▁de ▁setembro [MASK] [MASK] ▁Ela ▁entrou ▁na ▁parada ▁UK ▁Singles ▁Chart ▁em ▁se timo ▁lugar [MASK] ▁e ▁al can cou ▁a ▁pos ica o [MASK] . [SEP]\n",
            "I1209 17:37:31.367326 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁A ▁musica ▁considerados [MASK] ▁por ▁um ▁total ▁de ▁nove ▁semanas . ▁De ▁acordo ▁com ▁a ▁O fficial ▁Chart s ▁Company , ▁a ▁can ca o ▁ja ▁vendeu ▁2 ▁visitado ▁Pampulha ▁copia s ▁60, . ▁Na ▁Alemanha , [MASK] [MASK] [MASK] o [MASK] ▁na ▁parada ▁Media ▁Control ▁Chart s ▁na ▁pos ica o ▁66 ▁em ▁29 ▁de ▁setembro ▁de ▁1987 [MASK] ▁e ▁subiu ▁a te [MASK] ▁pos ica o ▁14 ▁em ▁sua ▁terceira ▁semana , ▁e ▁passou ▁12 ▁semanas [MASK] ▁parada . [SEP] ▁No ▁Reino ▁Unido , ▁\" Ca us ing ▁a ▁Com motion \" ▁foi ▁ lan cada ▁em ▁19 ▁de ▁setembro [MASK] [MASK] ▁Ela ▁entrou ▁na ▁parada ▁UK ▁Singles ▁Chart ▁em ▁se timo ▁lugar [MASK] ▁e ▁al can cou ▁a ▁pos ica o [MASK] . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 28 13733 3097 4 26 20 663 6 1810 1519 7 167 316 21 8 33 29419 8251 10 3703 5 8 3530 228 52 3579 2940 146 14711 28606 11112 10 13690 7 95 761 5 4 4 4 52 4 25 4404 6657 15928 8251 10 25 14191 1840 52 7856 14 889 6 415 6 4297 4 9 8609 8 204 4 14191 1840 52 347 14 38 1053 1158 5 9 310 288 1519 4 4404 7 3 67 733 1213 5 17 1836 339 498 8 173 20315 27 30 19 1818 5105 14 616 6 415 4 4 508 993 25 4404 14756 13471 8251 14 35 11940 290 4 9 980 2816 4465 8 14191 1840 52 4 7 3\n",
            "I1209 17:37:31.367471 140687693150080 create_pretraining_data.py:197] input_ids: 2 28 13733 3097 4 26 20 663 6 1810 1519 7 167 316 21 8 33 29419 8251 10 3703 5 8 3530 228 52 3579 2940 146 14711 28606 11112 10 13690 7 95 761 5 4 4 4 52 4 25 4404 6657 15928 8251 10 25 14191 1840 52 7856 14 889 6 415 6 4297 4 9 8609 8 204 4 14191 1840 52 347 14 38 1053 1158 5 9 310 288 1519 4 4404 7 3 67 733 1213 5 17 1836 339 498 8 173 20315 27 30 19 1818 5105 14 616 6 415 4 4 508 993 25 4404 14756 13471 8251 14 35 11940 290 4 9 980 2816 4465 8 14191 1840 52 4 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.367584 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.367680 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
            "I1209 17:37:31.367781 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 4 29 30 33 38 39 40 41 42 60 65 79 99 103 104 110 116 125 0\n",
            "I1209 17:37:31.367854 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 3 4 29 30 33 38 39 40 41 42 60 65 79 99 103 104 110 116 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 1410 334 1465 424 671 8 3530 228 52 1214 5 8 25 14 6 10486 13471 5 287 0\n",
            "I1209 17:37:31.367919 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 1410 334 1465 424 671 8 3530 228 52 1214 5 8 25 14 6 10486 13471 5 287 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.367987 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.368046 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.368555 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁o ▁coro ▁nacional [MASK] [MASK] [MASK] [MASK] [MASK] ▁\" Sa ty ri con \" [MASK] ▁as ▁melhores ▁po sico es ▁nas ▁paradas ▁musicais ▁na ▁carreira ▁da ▁banda ▁e ▁foi ▁seu ▁primeiro [MASK] [MASK] [MASK] ▁nas [MASK] ▁a us tria ca , ▁su ica ▁e [MASK] . ▁Em ▁sua ▁primeira ▁semana , ▁o ▁album ▁estreou ▁em [MASK] ▁lugar ▁nas [MASK] ▁da ▁Noruega , ▁no ▁entanto ; ▁na ▁semana ▁seguinte , ▁al can cou ▁o ▁numero ▁um , ▁tornando - se [MASK] ▁primeiro ▁album ▁do ▁Sa ty ri [SEP] ▁O [MASK] [MASK] ▁com ▁colabora co es ▁do ▁guitarrista ▁Gil das ▁Le ▁Pa pe ▁( que ▁toca ▁ao ▁vivo ▁com ▁a ▁banda ) ▁e ▁do [MASK] ▁da ▁banda ▁de ▁rock ▁Madruga da ▁Si vert ▁H ø y em . [SEP]\n",
            "I1209 17:37:31.368688 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁o ▁coro ▁nacional [MASK] [MASK] [MASK] [MASK] [MASK] ▁\" Sa ty ri con \" [MASK] ▁as ▁melhores ▁po sico es ▁nas ▁paradas ▁musicais ▁na ▁carreira ▁da ▁banda ▁e ▁foi ▁seu ▁primeiro [MASK] [MASK] [MASK] ▁nas [MASK] ▁a us tria ca , ▁su ica ▁e [MASK] . ▁Em ▁sua ▁primeira ▁semana , ▁o ▁album ▁estreou ▁em [MASK] ▁lugar ▁nas [MASK] ▁da ▁Noruega , ▁no ▁entanto ; ▁na ▁semana ▁seguinte , ▁al can cou ▁o ▁numero ▁um , ▁tornando - se [MASK] ▁primeiro ▁album ▁do ▁Sa ty ri [SEP] ▁O [MASK] [MASK] ▁com ▁colabora co es ▁do ▁guitarrista ▁Gil das ▁Le ▁Pa pe ▁( que ▁toca ▁ao ▁vivo ▁com ▁a ▁banda ) ▁e ▁do [MASK] ▁da ▁banda ▁de ▁rock ▁Madruga da ▁Si vert ▁H ø y em . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 11 6398 446 4 4 4 4 4 17 2157 1583 461 828 27 4 40 919 2360 14710 101 107 4192 1834 25 327 13 147 9 30 44 86 4 4 4 107 4 8 339 7954 228 5 1439 1840 9 4 7 43 38 100 1158 5 11 22876 1214 14 4 290 107 4 13 5401 5 22 363 72 25 1158 322 5 980 2816 4465 11 19308 20 5 1034 16 34 4 86 22876 12 499 1583 461 3 33 4 4 21 8416 238 101 12 2186 2645 190 585 758 505 29 222 4490 37 1060 21 8 147 46 9 12 4 13 147 6 1242 24986 62 1844 10586 624 1 156 136 7 3\n",
            "I1209 17:37:31.368810 140687693150080 create_pretraining_data.py:197] input_ids: 2 11 6398 446 4 4 4 4 4 17 2157 1583 461 828 27 4 40 919 2360 14710 101 107 4192 1834 25 327 13 147 9 30 44 86 4 4 4 107 4 8 339 7954 228 5 1439 1840 9 4 7 43 38 100 1158 5 11 22876 1214 14 4 290 107 4 13 5401 5 22 363 72 25 1158 322 5 980 2816 4465 11 19308 20 5 1034 16 34 4 86 22876 12 499 1583 461 3 33 4 4 21 8416 238 101 12 2186 2645 190 585 758 505 29 222 4490 37 1060 21 8 147 46 9 12 4 13 147 6 1242 24986 62 1844 10586 624 1 156 136 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.368910 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.369004 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            "I1209 17:37:31.369094 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 4 5 6 7 8 15 22 32 33 34 36 45 56 59 80 89 90 113 0\n",
            "I1209 17:37:31.369160 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 3 4 5 6 7 8 15 22 32 33 34 36 45 56 59 80 89 90 113 0\n",
            "INFO:tensorflow:masked_lm_ids: 446 22 1246 70 7657 7 8793 4192 253 8 1724 4192 9858 7392 4192 11 22876 414 2002 0\n",
            "I1209 17:37:31.369224 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 446 22 1246 70 7657 7 8793 4192 253 8 1724 4192 9858 7392 4192 11 22876 414 2002 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.369287 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.369361 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.369812 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁fundamental ▁que ▁se ▁deve ▁cumprir ▁na [MASK] [MASK] [MASK] ▁dos ▁Cost ▁Drive r s ▁e ▁que ▁se ▁produz a ▁uma ▁re la ca o ▁direta ▁entre ▁a ▁medida ▁e [MASK] [MASK] ▁final ; ▁5 ) ▁Distribu ir ▁os ▁custos ▁dos ▁diferentes ▁centros ▁ou ▁departamento s ▁pelas ▁atividades , ▁ou [MASK] ▁Jura ▁uma ▁vez ▁localizados ▁os ▁custos ▁indireto s ▁e [MASK] [MASK] ▁se cco es , [MASK] [MASK] ▁estabelecer a ▁cri ter ios ▁para ▁classificar ▁estes ▁custos ▁e ▁as ▁atividades [SEP] ▁Iglesias [MASK] [MASK] [MASK] [MASK] [MASK] ▁do [MASK] ▁ABC ▁seria ▁determinar ▁os ▁Cost ▁Drive r s ▁ou ▁geradores ▁de ▁custos , ▁podendo ▁utilizar - se ▁como ▁medida ▁de ▁atividade ▁um ▁in put , ▁um ▁o ut put , ▁ou ▁qualquer ▁outro ▁indicado r ▁fi sico . [SEP]\n",
            "I1209 17:37:31.369943 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁fundamental ▁que ▁se ▁deve ▁cumprir ▁na [MASK] [MASK] [MASK] ▁dos ▁Cost ▁Drive r s ▁e ▁que ▁se ▁produz a ▁uma ▁re la ca o ▁direta ▁entre ▁a ▁medida ▁e [MASK] [MASK] ▁final ; ▁5 ) ▁Distribu ir ▁os ▁custos ▁dos ▁diferentes ▁centros ▁ou ▁departamento s ▁pelas ▁atividades , ▁ou [MASK] ▁Jura ▁uma ▁vez ▁localizados ▁os ▁custos ▁indireto s ▁e [MASK] [MASK] ▁se cco es , [MASK] [MASK] ▁estabelecer a ▁cri ter ios ▁para ▁classificar ▁estes ▁custos ▁e ▁as ▁atividades [SEP] ▁Iglesias [MASK] [MASK] [MASK] [MASK] [MASK] ▁do [MASK] ▁ABC ▁seria ▁determinar ▁os ▁Cost ▁Drive r s ▁ou ▁geradores ▁de ▁custos , ▁podendo ▁utilizar - se ▁como ▁medida ▁de ▁atividade ▁um ▁in put , ▁um ▁o ut put , ▁ou ▁qualquer ▁outro ▁indicado r ▁fi sico . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 2174 15 35 582 6056 25 4 4 4 36 18885 14011 41 10 9 15 35 3574 49 18 172 135 228 52 2885 60 8 1527 9 4 4 182 72 196 46 21952 720 32 4705 36 509 4118 51 154 10 550 912 5 51 4 17693 18 140 8472 32 4705 18857 10 9 4 4 35 8163 101 5 4 4 3737 49 7026 410 4839 24 9621 1232 4705 9 40 912 3 18479 4 4 4 4 4 12 4 6218 375 4308 32 18885 14011 41 10 51 23788 6 4705 5 2266 2772 16 34 31 1527 6 1309 20 188 9741 5 20 11 1324 9741 5 51 401 309 3058 41 2836 14710 7 3\n",
            "I1209 17:37:31.370068 140687693150080 create_pretraining_data.py:197] input_ids: 2 2174 15 35 582 6056 25 4 4 4 36 18885 14011 41 10 9 15 35 3574 49 18 172 135 228 52 2885 60 8 1527 9 4 4 182 72 196 46 21952 720 32 4705 36 509 4118 51 154 10 550 912 5 51 4 17693 18 140 8472 32 4705 18857 10 9 4 4 35 8163 101 5 4 4 3737 49 7026 410 4839 24 9621 1232 4705 9 40 912 3 18479 4 4 4 4 4 12 4 6218 375 4308 32 18885 14011 41 10 51 23788 6 4705 5 2266 2772 16 34 31 1527 6 1309 20 188 9741 5 20 11 1324 9741 5 51 401 309 3058 41 2836 14710 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.370166 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.370258 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            "I1209 17:37:31.370377 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 7 8 9 30 31 50 51 52 60 61 66 67 81 82 83 84 85 86 88 0\n",
            "I1209 17:37:31.370444 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 7 8 9 30 31 50 51 52 60 61 66 67 81 82 83 84 85 86 88 0\n",
            "INFO:tensorflow:masked_lm_ids: 5745 228 52 11 1942 329 5 18 40 5446 8 438 178 46 890 3555 228 52 699 0\n",
            "I1209 17:37:31.370512 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 5745 228 52 11 1942 329 5 18 40 5446 8 438 178 46 890 3555 228 52 699 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.370580 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.370638 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.371078 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁para ▁a ▁Trilha ▁Sonora ▁do ▁filme ▁Bill ▁and ▁Ted ’ s ▁Ex cell ent ▁Adventure . ▁Depois ▁de [MASK] [MASK] ▁pela [MASK] ▁do ▁Norte ▁e [MASK] pa [MASK] , ▁o ▁Extreme ▁ lan cou ▁seu ▁segundo [MASK] , ▁ ‘ Por no graf fi tti ’ , ▁em ▁1990. ▁Esse ▁os ▁colocou ▁definitivamente ▁apaixonado ▁ hall [MASK] [MASK] . ▁O ▁som ▁da ▁banda [SEP] ▁soa va ▁o ▁“ Fun k ▁Metal ”, ▁mas ▁o ▁rock [MASK] ▁ascensão ▁hard ▁rock ▁tiveram ▁forte ▁pre se nca ▁em ▁ ‘ Por no graf fi tti ’ . ▁Entra ram ▁em ▁sua ▁segunda [MASK] ne [MASK] ▁Estados ▁Unidos , ▁enquanto [MASK] ▁baladas ▁More ▁Than ▁Word s ▁( o ▁maior ▁hit ▁do ▁Extreme ) ▁e ▁Ho le ▁Heart ed ▁na o [SEP]\n",
            "I1209 17:37:31.371204 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁para ▁a ▁Trilha ▁Sonora ▁do ▁filme ▁Bill ▁and ▁Ted ’ s ▁Ex cell ent ▁Adventure . ▁Depois ▁de [MASK] [MASK] ▁pela [MASK] ▁do ▁Norte ▁e [MASK] pa [MASK] , ▁o ▁Extreme ▁ lan cou ▁seu ▁segundo [MASK] , ▁ ‘ Por no graf fi tti ’ , ▁em ▁1990. ▁Esse ▁os ▁colocou ▁definitivamente ▁apaixonado ▁ hall [MASK] [MASK] . ▁O ▁som ▁da ▁banda [SEP] ▁soa va ▁o ▁“ Fun k ▁Metal ”, ▁mas ▁o ▁rock [MASK] ▁ascensão ▁hard ▁rock ▁tiveram ▁forte ▁pre se nca ▁em ▁ ‘ Por no graf fi tti ’ . ▁Entra ram ▁em ▁sua ▁segunda [MASK] ne [MASK] ▁Estados ▁Unidos , ▁enquanto [MASK] ▁baladas ▁More ▁Than ▁Word s ▁( o ▁maior ▁hit ▁do ▁Extreme ) ▁e ▁Ho le ▁Heart ed ▁na o [SEP]\n",
            "INFO:tensorflow:input_ids: 2 24 8 22674 25002 12 159 4789 627 18702 1721 10 1979 18738 2390 11331 7 469 6 4 4 54 4 12 594 9 4 534 4 5 11 20891 19 1818 4465 44 186 4 5 19 1 7313 171 6551 1456 3495 1721 5 14 5069 1184 32 4311 4910 8502 19 10627 4 4 7 33 1193 13 147 3 12094 84 11 235 16659 304 4369 1194 68 11 1242 4 4220 14261 1242 1426 801 762 34 3970 14 19 1 7313 171 6551 1456 3495 1721 7 20217 125 14 38 343 4 298 4 216 224 5 271 4 17451 7093 15737 24159 10 29 52 130 9517 12 20891 46 9 1270 199 6435 779 25 52 3\n",
            "I1209 17:37:31.467835 140687693150080 create_pretraining_data.py:197] input_ids: 2 24 8 22674 25002 12 159 4789 627 18702 1721 10 1979 18738 2390 11331 7 469 6 4 4 54 4 12 594 9 4 534 4 5 11 20891 19 1818 4465 44 186 4 5 19 1 7313 171 6551 1456 3495 1721 5 14 5069 1184 32 4311 4910 8502 19 10627 4 4 7 33 1193 13 147 3 12094 84 11 235 16659 304 4369 1194 68 11 1242 4 4220 14261 1242 1426 801 762 34 3970 14 19 1 7313 171 6551 1456 3495 1721 7 20217 125 14 38 343 4 298 4 216 224 5 271 4 17451 7093 15737 24159 10 29 52 130 9517 12 20891 46 9 1270 199 6435 779 25 52 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.468005 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.468116 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1\n",
            "I1209 17:37:31.468219 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 19 20 21 22 26 27 28 37 54 57 58 76 77 100 101 102 107 111 112 0\n",
            "I1209 17:37:31.468291 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 19 20 21 22 26 27 28 37 54 57 58 76 77 100 101 102 107 111 112 0\n",
            "INFO:tensorflow:masked_lm_ids: 12675 298 54 4478 1239 534 52 22876 22 13 3988 9 11 12675 298 203 40 24159 10 0\n",
            "I1209 17:37:31.468388 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 12675 298 54 4478 1239 534 52 22876 22 13 3988 9 11 12675 298 203 40 24159 10 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.468465 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:31.468534 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.469076 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] [MASK] ▁ja ▁ocorreu ▁no [MASK] [MASK] ▁nos ▁Estados ▁Unidos , ▁onde ▁100 ▁mil ▁caminho neiro s [MASK] ▁uma ▁para lis aca o ▁de ▁30 ▁dias ▁na ▁de cada ▁de ▁1970. [SEP] ▁Gre ve ▁selvagem ▁e ▁uma ▁greve ▁que ▁e ▁iniciada ▁e / ou [MASK] ▁adiante ▁espontaneamente , ▁pelos ▁trabalhadores , ▁sem ▁a ▁participa ca o ▁ou [MASK] [MASK] [MASK] [MASK] ▁do ▁sindicato ▁que ▁representa ▁a ▁classe . [SEP]\n",
            "I1209 17:37:31.469209 140687693150080 create_pretraining_data.py:187] tokens: [CLS] [MASK] [MASK] ▁ja ▁ocorreu ▁no [MASK] [MASK] ▁nos ▁Estados ▁Unidos , ▁onde ▁100 ▁mil ▁caminho neiro s [MASK] ▁uma ▁para lis aca o ▁de ▁30 ▁dias ▁na ▁de cada ▁de ▁1970. [SEP] ▁Gre ve ▁selvagem ▁e ▁uma ▁greve ▁que ▁e ▁iniciada ▁e / ou [MASK] ▁adiante ▁espontaneamente , ▁pelos ▁trabalhadores , ▁sem ▁a ▁participa ca o ▁ou [MASK] [MASK] [MASK] [MASK] ▁do ▁sindicato ▁que ▁representa ▁a ▁classe . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 4 3579 978 22 4 4 85 216 224 5 80 846 424 1491 12277 10 4 18 24 2060 4306 52 6 506 475 25 6 5105 6 7008 3 5230 398 10646 9 18 8565 15 9 5703 9 104 158 4 10951 26258 5 203 3559 5 181 8 3553 228 52 51 4 4 4 4 12 22667 15 1800 8 1081 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.469347 140687693150080 create_pretraining_data.py:197] input_ids: 2 4 4 3579 978 22 4 4 85 216 224 5 80 846 424 1491 12277 10 4 18 24 2060 4306 52 6 506 475 25 6 5105 6 7008 3 5230 398 10646 9 18 8565 15 9 5703 9 104 158 4 10951 26258 5 203 3559 5 181 8 3553 228 52 51 4 4 4 4 12 22667 15 1800 8 1081 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.469456 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.469556 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.469648 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 6 7 18 45 58 59 60 61 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.469715 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 1 2 6 7 18 45 58 59 60 61 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 1931 597 94 9 1964 7914 8 172 1702 128 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.469779 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 1931 597 94 9 1964 7914 8 172 1702 128 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:31.469845 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.469903 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.470395 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Parti ca o ▁da ▁Polo nia ▁foi [MASK] [MASK] . ▁A ▁primeira ▁das ▁ tre s ▁sucessivas ▁parti co es ▁do ▁ter rito rio ▁da ▁Republic a ▁pela [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁e ▁A us tria ▁no ▁se culo ▁XVIII ▁que ▁risca riam [MASK] [MASK] ▁Nápoles ▁do ▁mapa ▁da ▁Europa , ▁deixou ▁claro ▁para ▁as ▁mente s ▁progressista s ▁que ▁a ▁Republic a ▁precisava ▁de ▁reformas ▁urgente s ▁ou [SEP] [MASK] ▁Rei ▁Stanis ł aw ▁Augusto ▁cedeu ▁a ▁ pressa o ▁e ▁em ▁19 ▁de ▁abril ▁de [MASK] [MASK] [MASK] ▁convocou ▁a ▁ Sejm ▁para ▁a ▁se ssa o . ▁So mente ▁102 ▁deputados ▁atende ram ▁ao ▁pedido ; ▁os ▁restantes , ▁discorda ndo ▁da [MASK] ▁do ▁rei , ▁se ▁recusaram ▁a [MASK] [MASK] [SEP]\n",
            "I1209 17:37:31.470537 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁Parti ca o ▁da ▁Polo nia ▁foi [MASK] [MASK] . ▁A ▁primeira ▁das ▁ tre s ▁sucessivas ▁parti co es ▁do ▁ter rito rio ▁da ▁Republic a ▁pela [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁e ▁A us tria ▁no ▁se culo ▁XVIII ▁que ▁risca riam [MASK] [MASK] ▁Nápoles ▁do ▁mapa ▁da ▁Europa , ▁deixou ▁claro ▁para ▁as ▁mente s ▁progressista s ▁que ▁a ▁Republic a ▁precisava ▁de ▁reformas ▁urgente s ▁ou [SEP] [MASK] ▁Rei ▁Stanis ł aw ▁Augusto ▁cedeu ▁a ▁ pressa o ▁e ▁em ▁19 ▁de ▁abril ▁de [MASK] [MASK] [MASK] ▁convocou ▁a ▁ Sejm ▁para ▁a ▁se ssa o . ▁So mente ▁102 ▁deputados ▁atende ram ▁ao ▁pedido ; ▁os ▁restantes , ▁discorda ndo ▁da [MASK] ▁do ▁rei , ▁se ▁recusaram ▁a [MASK] [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 10989 228 52 13 12331 1747 30 4 4 7 28 100 53 19 1678 10 11958 10395 238 101 12 137 5353 1561 13 13369 49 54 4 4 4 4 4 4 9 28 339 7954 22 35 7224 2949 15 25302 2753 4 4 13248 12 7221 13 549 5 960 2865 24 40 3880 10 19246 10 15 8 13369 49 8578 6 5102 22642 10 51 3 4 1419 23072 1 6772 2439 15731 8 19 11405 52 9 14 616 6 404 6 4 4 4 16637 8 19 17573 24 8 35 1612 52 7 988 122 18713 5833 8015 125 37 2308 72 32 4460 5 17082 65 13 4 12 539 5 35 17268 8 4 4 3\n",
            "I1209 17:37:31.470661 140687693150080 create_pretraining_data.py:197] input_ids: 2 10989 228 52 13 12331 1747 30 4 4 7 28 100 53 19 1678 10 11958 10395 238 101 12 137 5353 1561 13 13369 49 54 4 4 4 4 4 4 9 28 339 7954 22 35 7224 2949 15 25302 2753 4 4 13248 12 7221 13 549 5 960 2865 24 40 3880 10 19246 10 15 8 13369 49 8578 6 5102 22642 10 51 3 4 1419 23072 1 6772 2439 15731 8 19 11405 52 9 14 616 6 404 6 4 4 4 16637 8 19 17573 24 8 35 1612 52 7 988 122 18713 5833 8015 125 37 2308 72 32 4460 5 17082 65 13 4 12 539 5 35 17268 8 4 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.470762 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.470856 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.470947 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 9 29 30 31 32 33 34 46 47 48 51 73 90 91 92 118 125 126 0\n",
            "I1209 17:37:31.471012 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 8 9 29 30 31 32 33 34 46 47 48 51 73 90 91 92 118 125 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 13542 62 9899 3325 5 17673 10 3325 8 12331 1747 13 33 312 4188 5 5665 24363 7 0\n",
            "I1209 17:37:31.471076 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 13542 62 9899 3325 5 17673 10 3325 8 12331 1747 13 33 312 4188 5 5665 24363 7 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.471146 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.471203 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.471673 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] , ▁a ▁ordem ▁Hemi ptera ▁e ▁composta ▁por ▁quatro ▁sub or dens [MASK] ▁Anteriormente [MASK] ▁as ▁classifica co es ▁class icas ▁do ▁agrupamento ▁ taxon o mico ▁Hemi ptera ▁apresentavam ▁Ho mo ptera ▁( S ter nor rhynch a ▁+ ▁A uche nor rhynch a ) ▁como ▁uma ▁ordem ▁separada ▁devido [MASK] ▁difere nca s ▁na ▁estrutura ▁da ▁as a ▁e ▁na ▁pos [SEP] [MASK] [MASK] [MASK] , ▁ja ▁que ▁Stern or rhynch a ▁e ▁grupo - ir ma o ▁de ▁todos ▁os ▁outros ▁hemi pt eros . ▁A ▁classifica ca o ▁e ▁ainda ▁controversa , ▁existem ▁autores ▁que [MASK] [MASK] em [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁na o ▁e ▁mono file tico ▁e , [MASK] , ▁deve [MASK] ▁dividido ▁em ▁duas ▁novas ▁sub [SEP]\n",
            "I1209 17:37:31.471805 140687693150080 create_pretraining_data.py:187] tokens: [CLS] , ▁a ▁ordem ▁Hemi ptera ▁e ▁composta ▁por ▁quatro ▁sub or dens [MASK] ▁Anteriormente [MASK] ▁as ▁classifica co es ▁class icas ▁do ▁agrupamento ▁ taxon o mico ▁Hemi ptera ▁apresentavam ▁Ho mo ptera ▁( S ter nor rhynch a ▁+ ▁A uche nor rhynch a ) ▁como ▁uma ▁ordem ▁separada ▁devido [MASK] ▁difere nca s ▁na ▁estrutura ▁da ▁as a ▁e ▁na ▁pos [SEP] [MASK] [MASK] [MASK] , ▁ja ▁que ▁Stern or rhynch a ▁e ▁grupo - ir ma o ▁de ▁todos ▁os ▁outros ▁hemi pt eros . ▁A ▁classifica ca o ▁e ▁ainda ▁controversa , ▁existem ▁autores ▁que [MASK] [MASK] em [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁na o ▁e ▁mono file tico ▁e , [MASK] , ▁deve [MASK] ▁dividido ▁em ▁duas ▁novas ▁sub [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5 8 583 18726 12372 9 1422 26 287 651 766 17692 4 13336 4 40 8064 238 101 14593 7195 12 11686 19 27620 52 5622 18726 12372 15771 1270 320 12372 29 256 410 5750 29418 49 3585 28 16044 5750 29418 49 46 31 18 583 9124 317 4 12090 3970 10 25 738 13 40 49 9 25 14191 3 4 4 4 5 3579 15 20941 766 29418 49 9 175 16 720 295 52 6 187 32 114 25173 2428 15671 7 28 8064 228 52 9 108 12012 5 1328 1842 15 4 4 136 4 4 4 4 4 4 4 25 52 9 3352 20603 3116 9 5 4 5 582 4 3405 14 168 882 651 3\n",
            "I1209 17:37:31.471925 140687693150080 create_pretraining_data.py:197] input_ids: 2 5 8 583 18726 12372 9 1422 26 287 651 766 17692 4 13336 4 40 8064 238 101 14593 7195 12 11686 19 27620 52 5622 18726 12372 15771 1270 320 12372 29 256 410 5750 29418 49 3585 28 16044 5750 29418 49 46 31 18 583 9124 317 4 12090 3970 10 25 738 13 40 49 9 25 14191 3 4 4 4 5 3579 15 20941 766 29418 49 9 175 16 720 295 52 6 187 32 114 25173 2428 15671 7 28 8064 228 52 9 108 12012 5 1328 1842 15 4 4 136 4 4 4 4 4 4 4 25 52 9 3352 20603 3116 9 5 4 5 582 4 3405 14 168 882 651 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.472026 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.472116 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.472207 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 13 15 52 65 66 67 100 101 102 103 104 105 106 107 108 109 118 120 121 0\n",
            "I1209 17:37:31.472276 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 13 15 52 65 66 67 100 101 102 103 104 105 106 107 108 109 118 120 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 42 5 40 3352 20603 3116 9592 52 136 15 28 16044 5750 41 3726 3970 1373 582 55 0\n",
            "I1209 17:37:31.472356 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 42 5 40 3352 20603 3116 9592 52 136 15 28 16044 5750 41 3726 3970 1373 582 55 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.472421 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:31.472477 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.472930 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁No ▁mesmo ▁ano , ▁Te bal di ▁teve ▁grande ▁sucesso ▁com ▁seu ▁debut e ▁norte - americano ▁em ▁San ▁Francisco , ▁onde ▁cantou ▁Desde mon a ▁e ▁A ida [MASK] [SEP] Cidadão ▁movendo ▁Canto [MASK] ▁embora ▁ela ▁na o ▁fosse ▁ficar ▁muito ▁associada ▁a ▁esse ▁re perto rio ▁futuramente : ▁\" O ▁Si tio ▁de ▁Corinto \" ▁e ▁Guil la ume ▁Tell , ▁ambas [MASK] [MASK] ▁1957) ; ▁\" O lim pia \" ▁e ▁\" F erna nd ▁Corte z \", [MASK] [MASK] [MASK] [MASK] . ▁Em ▁1950 [MASK] [MASK] [MASK] di ▁viajou ▁com ▁a [MASK] ▁do ▁La ▁Scala ▁Chateaubriand [MASK] ▁no ▁Festival ▁de ▁Edimburgo ▁e ▁no ▁famoso ▁Co vent ▁Garden , ▁em ▁Londres , ▁e ▁impressionou ▁as ▁plateia s ▁com ▁sua ▁Desde mon a ▁e [SEP]\n",
            "I1209 17:37:31.473055 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁No ▁mesmo ▁ano , ▁Te bal di ▁teve ▁grande ▁sucesso ▁com ▁seu ▁debut e ▁norte - americano ▁em ▁San ▁Francisco , ▁onde ▁cantou ▁Desde mon a ▁e ▁A ida [MASK] [SEP] Cidadão ▁movendo ▁Canto [MASK] ▁embora ▁ela ▁na o ▁fosse ▁ficar ▁muito ▁associada ▁a ▁esse ▁re perto rio ▁futuramente : ▁\" O ▁Si tio ▁de ▁Corinto \" ▁e ▁Guil la ume ▁Tell , ▁ambas [MASK] [MASK] ▁1957) ; ▁\" O lim pia \" ▁e ▁\" F erna nd ▁Corte z \", [MASK] [MASK] [MASK] [MASK] . ▁Em ▁1950 [MASK] [MASK] [MASK] di ▁viajou ▁com ▁a [MASK] ▁do ▁La ▁Scala ▁Chateaubriand [MASK] ▁no ▁Festival ▁de ▁Edimburgo ▁e ▁no ▁famoso ▁Co vent ▁Garden , ▁em ▁Londres , ▁e ▁impressionou ▁as ▁plateia s ▁com ▁sua ▁Desde mon a ▁e [SEP]\n",
            "INFO:tensorflow:input_ids: 2 67 88 76 5 1284 2300 357 198 113 308 21 44 24905 70 292 16 1133 14 977 831 5 80 6881 920 1345 49 9 28 1535 4 3 29162 20034 12456 4 578 157 25 52 917 1749 126 5073 8 520 172 16848 1561 21891 42 17 162 1844 4186 6 28513 27 9 17278 135 9063 18172 5 2200 4 4 19694 72 17 162 4073 4575 27 9 17 459 14267 1062 4797 284 47 4 4 4 4 7 43 1926 4 4 4 357 6409 21 8 4 12 321 28704 26771 4 22 1651 6 22964 9 22 1786 682 6479 10518 5 14 1445 5 9 27117 40 14589 10 21 38 920 1345 49 9 3\n",
            "I1209 17:37:31.569864 140687693150080 create_pretraining_data.py:197] input_ids: 2 67 88 76 5 1284 2300 357 198 113 308 21 44 24905 70 292 16 1133 14 977 831 5 80 6881 920 1345 49 9 28 1535 4 3 29162 20034 12456 4 578 157 25 52 917 1749 126 5073 8 520 172 16848 1561 21891 42 17 162 1844 4186 6 28513 27 9 17278 135 9063 18172 5 2200 4 4 19694 72 17 162 4073 4575 27 9 17 459 14267 1062 4797 284 47 4 4 4 4 7 43 1926 4 4 4 357 6409 21 8 4 12 321 28704 26771 4 22 1651 6 22964 9 22 1786 682 6479 10518 5 14 1445 5 9 27117 40 14589 10 21 38 920 1345 49 9 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.570041 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.570161 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            "I1209 17:37:31.570263 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 30 32 33 35 65 66 67 82 83 84 85 86 89 90 91 92 96 100 101 0\n",
            "I1209 17:37:31.570425 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 30 32 33 35 65 66 67 82 83 84 85 86 89 90 91 92 96 100 101 0\n",
            "INFO:tensorflow:masked_lm_ids: 7 12 4225 5 6 10137 402 6 193 16438 2800 7 5 1284 2300 357 1400 24 4322 0\n",
            "I1209 17:37:31.570501 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 7 12 4225 5 6 10137 402 6 193 16438 2800 7 5 1284 2300 357 1400 24 4322 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.570576 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.570635 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.571203 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Todas ▁car entes ▁e [MASK] [MASK] ▁para ▁casar . [SEP] ▁Assim , ▁por ▁uma ▁ra za o [MASK] ▁e ▁ma gica ▁abre - se ▁um ▁portal ▁ dimensional ▁e ▁o ▁jovem ▁para ▁em ▁um ▁outro ▁mundo [MASK] [MASK] [MASK] . ▁La ▁ele ▁encontra ▁uma [MASK] [MASK] ▁bela ▁garota ▁chamada ▁Mi har u . ▁Para ▁o ▁a zar ▁do ▁rapaz , [MASK] [MASK] [MASK] ▁estava ▁e ▁constitui do ▁por ▁90% ▁de ▁mulheres . [SEP]\n",
            "I1209 17:37:31.571367 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁Todas ▁car entes ▁e [MASK] [MASK] ▁para ▁casar . [SEP] ▁Assim , ▁por ▁uma ▁ra za o [MASK] ▁e ▁ma gica ▁abre - se ▁um ▁portal ▁ dimensional ▁e ▁o ▁jovem ▁para ▁em ▁um ▁outro ▁mundo [MASK] [MASK] [MASK] . ▁La ▁ele ▁encontra ▁uma [MASK] [MASK] ▁bela ▁garota ▁chamada ▁Mi har u . ▁Para ▁o ▁a zar ▁do ▁rapaz , [MASK] [MASK] [MASK] ▁estava ▁e ▁constitui do ▁por ▁90% ▁de ▁mulheres . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 3799 1427 4987 9 4 4 24 3891 7 3 692 5 26 18 1901 809 52 4 9 983 9581 6602 16 34 20 7640 19 17677 9 11 767 24 14 20 309 219 4 4 4 7 321 69 611 18 4 4 6677 5586 569 1267 3796 64 7 244 11 8 2904 12 8520 5 4 4 4 220 9 4144 61 26 13662 6 974 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.571497 140687693150080 create_pretraining_data.py:197] input_ids: 2 3799 1427 4987 9 4 4 24 3891 7 3 692 5 26 18 1901 809 52 4 9 983 9581 6602 16 34 20 7640 19 17677 9 11 767 24 14 20 309 219 4 4 4 7 321 69 611 18 4 4 6677 5586 569 1267 3796 64 7 244 11 8 2904 12 8520 5 4 4 4 220 9 4144 61 26 13662 6 974 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.571602 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.571698 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.571790 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 6 18 37 38 39 45 46 61 62 63 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.571856 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 5 6 18 37 38 39 45 46 61 62 63 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 23878 10 6658 403 14378 2354 767 9 11 866 80 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:37:31.571922 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 23878 10 6658 403 14378 2354 767 9 11 866 80 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:37:31.571991 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.572050 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.572581 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] 41 ▁reformou ▁a ▁institui ca o [MASK] ▁mantendo ▁a ▁mesma ▁divisa o [MASK] [MASK] [MASK] ▁derrotada ▁por em , ▁detalha ndo ▁um ▁pouco ▁mais ▁as ▁atribui co es ▁de ▁cada [MASK] [MASK] ▁A ▁partir ▁da ▁de cada ▁de [MASK] [MASK] ▁Hot ▁assiste se ▁uma ▁maior ▁estrutura ca o ▁do ▁o r ga o . ▁Ainda ▁em ▁1870 , ▁o ▁arquivo ▁passou ▁a ▁ocupar ▁o ▁antigo ▁e di fici o ▁do ▁Re col hi mento ▁do ▁Par to ▁dos ▁Terceiro s ▁da ▁Ordem ▁do ▁Carmo . ▁Em [MASK] , [MASK] ▁pernambucano ▁Joaquim ▁Pires [MASK] [MASK] [MASK] ▁assumiu ▁a ▁di rec ao ▁e , ▁no ▁ano ▁seguinte , ▁abriu ▁o ▁arquivo ▁a ▁consulta ▁publica . [SEP] ▁Conc eb eu ▁um [MASK] ▁regulamento , ▁aprovado ▁pelo ▁decreto ▁n . [SEP]\n",
            "I1209 17:37:31.572726 140687693150080 create_pretraining_data.py:187] tokens: [CLS] 41 ▁reformou ▁a ▁institui ca o [MASK] ▁mantendo ▁a ▁mesma ▁divisa o [MASK] [MASK] [MASK] ▁derrotada ▁por em , ▁detalha ndo ▁um ▁pouco ▁mais ▁as ▁atribui co es ▁de ▁cada [MASK] [MASK] ▁A ▁partir ▁da ▁de cada ▁de [MASK] [MASK] ▁Hot ▁assiste se ▁uma ▁maior ▁estrutura ca o ▁do ▁o r ga o . ▁Ainda ▁em ▁1870 , ▁o ▁arquivo ▁passou ▁a ▁ocupar ▁o ▁antigo ▁e di fici o ▁do ▁Re col hi mento ▁do ▁Par to ▁dos ▁Terceiro s ▁da ▁Ordem ▁do ▁Carmo . ▁Em [MASK] , [MASK] ▁pernambucano ▁Joaquim ▁Pires [MASK] [MASK] [MASK] ▁assumiu ▁a ▁di rec ao ▁e , ▁no ▁ano ▁seguinte , ▁abriu ▁o ▁arquivo ▁a ▁consulta ▁publica . [SEP] ▁Conc eb eu ▁um [MASK] ▁regulamento , ▁aprovado ▁pelo ▁decreto ▁n . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 3671 29975 8 15618 228 52 4 3994 8 394 7803 52 4 4 4 13749 26 136 5 20233 65 20 470 39 40 11195 238 101 6 209 4 4 28 192 13 6 5105 6 4 4 3060 14086 34 18 130 738 228 52 12 11 41 318 52 7 975 14 8158 5 11 5970 310 8 5310 11 848 9 357 10571 52 12 382 4146 1809 507 12 3318 177 36 12757 10 13 1212 12 6994 7 43 4 5 4 17386 3638 6614 4 4 4 1852 8 719 6040 8372 9 5 22 76 322 5 3595 11 5970 8 6478 7445 7 3 14035 5091 2647 20 4 9870 5 4907 57 3226 1653 7 3\n",
            "I1209 17:37:31.572852 140687693150080 create_pretraining_data.py:197] input_ids: 2 3671 29975 8 15618 228 52 4 3994 8 394 7803 52 4 4 4 13749 26 136 5 20233 65 20 470 39 40 11195 238 101 6 209 4 4 28 192 13 6 5105 6 4 4 3060 14086 34 18 130 738 228 52 12 11 41 318 52 7 975 14 8158 5 11 5970 310 8 5310 11 848 9 357 10571 52 12 382 4146 1809 507 12 3318 177 36 12757 10 13 1212 12 6994 7 43 4 5 4 17386 3638 6614 4 4 4 1852 8 719 6040 8372 9 5 22 76 322 5 3595 11 5970 8 6478 7445 7 3 14035 5091 2647 20 4 9870 5 4907 57 3226 1653 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.572954 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.573049 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.573140 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 7 13 14 15 16 31 32 39 40 41 42 43 87 88 89 93 94 95 119 0\n",
            "I1209 17:37:31.573205 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 7 13 14 15 16 31 32 39 40 41 42 43 87 88 89 93 94 95 119 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 53 9454 101 5 18 7 8158 5 6144 16 34 12637 5 11 3571 262 13735 237 0\n",
            "I1209 17:37:31.573268 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 5 53 9454 101 5 18 7 8158 5 6144 16 34 12637 5 11 3571 262 13735 237 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.573356 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:37:31.573415 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.573865 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁emoções ▁sub trib os [MASK] [MASK] ▁argumentação ▁e ▁O ch n inae , ▁ocorre ▁apenas ▁um ▁o vul o ▁por ▁car pelo . ▁A ▁familia [MASK] [MASK] [MASK] [MASK] [MASK] ▁por ▁August in ▁Py ram us ▁de ▁Ca ndo lle ▁em ▁1811 . [SEP] ▁Sau va ges i eae [MASK] ▁exceto ▁\" Eu the mis \", ▁e ▁para ▁\" Phil a cra \" ▁e ▁\" L ux em burg ia \", ▁o ▁numero ▁de ▁o vul os ▁por ▁car pelo ▁varia ▁de ▁4 ▁a ▁50 . ▁O ▁gene ro ▁\" Eu the mis \" [MASK] ▁dois ▁o vul os ▁por ▁car pelo . ▁No ▁grupo p ▁O ch nea e , ▁o ▁gene ro [MASK] [MASK] [MASK] [MASK] ▁comunicações [MASK] [MASK] ▁4 ▁a ▁50 ▁o vul [SEP]\n",
            "I1209 17:37:31.574002 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁emoções ▁sub trib os [MASK] [MASK] ▁argumentação ▁e ▁O ch n inae , ▁ocorre ▁apenas ▁um ▁o vul o ▁por ▁car pelo . ▁A ▁familia [MASK] [MASK] [MASK] [MASK] [MASK] ▁por ▁August in ▁Py ram us ▁de ▁Ca ndo lle ▁em ▁1811 . [SEP] ▁Sau va ges i eae [MASK] ▁exceto ▁\" Eu the mis \", ▁e ▁para ▁\" Phil a cra \" ▁e ▁\" L ux em burg ia \", ▁o ▁numero ▁de ▁o vul os ▁por ▁car pelo ▁varia ▁de ▁4 ▁a ▁50 . ▁O ▁gene ro ▁\" Eu the mis \" [MASK] ▁dois ▁o vul os ▁por ▁car pelo . ▁No ▁grupo p ▁O ch nea e , ▁o ▁gene ro [MASK] [MASK] [MASK] [MASK] ▁comunicações [MASK] [MASK] ▁4 ▁a ▁50 ▁o vul [SEP]\n",
            "INFO:tensorflow:input_ids: 2 10889 651 14579 239 4 4 23279 9 33 595 111 15628 5 1104 139 20 11 7309 52 26 1427 9068 7 28 25717 4 4 4 4 4 26 11091 234 15140 125 339 6 471 65 2895 14 19091 7 3 11404 84 4344 102 23806 4 4124 17 2259 3088 6385 47 9 24 17 23294 49 3174 27 9 17 544 2996 136 5642 128 47 11 19308 6 11 7309 239 26 1427 9068 3117 6 178 8 1038 7 33 7301 364 17 2259 3088 6385 27 4 97 11 7309 239 26 1427 9068 7 67 175 241 33 595 5516 70 5 11 7301 364 4 4 4 4 6624 4 4 178 8 1038 11 7309 3\n",
            "I1209 17:37:31.574120 140687693150080 create_pretraining_data.py:197] input_ids: 2 10889 651 14579 239 4 4 23279 9 33 595 111 15628 5 1104 139 20 11 7309 52 26 1427 9068 7 28 25717 4 4 4 4 4 26 11091 234 15140 125 339 6 471 65 2895 14 19091 7 3 11404 84 4344 102 23806 4 4124 17 2259 3088 6385 47 9 24 17 23294 49 3174 27 9 17 544 2996 136 5642 128 47 11 19308 6 11 7309 239 26 1427 9068 3117 6 178 8 1038 7 33 7301 364 17 2259 3088 6385 27 4 97 11 7309 239 26 1427 9068 7 67 175 241 33 595 5516 70 5 11 7301 364 4 4 4 4 6624 4 4 178 8 1038 11 7309 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.574219 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.574330 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1\n",
            "I1209 17:37:31.574429 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 0 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 5 6 7 26 27 28 29 30 50 94 95 115 116 117 118 119 120 121 0\n",
            "I1209 17:37:31.574495 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 1 5 6 7 26 27 28 29 30 50 94 95 115 116 117 118 119 120 121 0\n",
            "INFO:tensorflow:masked_lm_ids: 1742 23027 102 15628 28043 30 9 250 3243 5 27 93 17 4054 4736 153 27 888 6 0\n",
            "I1209 17:37:31.574558 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 1742 23027 102 15628 28043 30 9 250 3243 5 27 93 17 4054 4736 153 27 888 6 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.574623 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.574679 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:37:31.575134 140687693150080 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁para ▁24 . ▁Al em [MASK] , ▁o ▁Porsche ▁GT 3 ▁Cup ▁Challenge ▁Brasil ▁e ▁uma ▁das ▁categorias ▁preliminares ▁do ▁Grande ▁Premio ▁do ▁Brasil ▁de ▁Formula ▁1. ▁O ▁ano ▁de ▁2005 [MASK] ▁a [MASK] ▁do ▁Porsche ▁GT 3 ▁Cup ▁Challenge ▁Brasil , ▁o ▁primeiro [MASK] ▁mono marca ▁da ▁Porsche [MASK] ▁America ▁do ▁Sul . ▁Disputa do ▁exclusivamente [MASK] ▁modelos ▁9 11 ▁GT 3 ▁Cup , ▁ele [MASK] [MASK] ▁mesma ▁formula [MASK] ▁sucesso ▁do ▁Porsche ▁Super cup ▁( que ▁realiza ▁todas ▁suas [MASK] [MASK] ▁preliminares ▁dos ▁Grandes ▁Premio s ▁de ▁Formula ▁1 ▁disputados ▁na ▁Europa ▁e ▁Estados ▁Unidos ) ▁e ▁dos ▁Carrera ▁Cup [MASK] [MASK] 3 ▁Cup [SEP] [MASK] [MASK] , [MASK] [MASK] ▁passou ▁a ▁ter [MASK] ▁campeonato [MASK] ▁denominado ▁Porsche ▁GT 3 ▁Cup ▁Challenge ▁Brasil . [SEP]\n",
            "I1209 17:37:31.575261 140687693150080 create_pretraining_data.py:187] tokens: [CLS] ▁para ▁24 . ▁Al em [MASK] , ▁o ▁Porsche ▁GT 3 ▁Cup ▁Challenge ▁Brasil ▁e ▁uma ▁das ▁categorias ▁preliminares ▁do ▁Grande ▁Premio ▁do ▁Brasil ▁de ▁Formula ▁1. ▁O ▁ano ▁de ▁2005 [MASK] ▁a [MASK] ▁do ▁Porsche ▁GT 3 ▁Cup ▁Challenge ▁Brasil , ▁o ▁primeiro [MASK] ▁mono marca ▁da ▁Porsche [MASK] ▁America ▁do ▁Sul . ▁Disputa do ▁exclusivamente [MASK] ▁modelos ▁9 11 ▁GT 3 ▁Cup , ▁ele [MASK] [MASK] ▁mesma ▁formula [MASK] ▁sucesso ▁do ▁Porsche ▁Super cup ▁( que ▁realiza ▁todas ▁suas [MASK] [MASK] ▁preliminares ▁dos ▁Grandes ▁Premio s ▁de ▁Formula ▁1 ▁disputados ▁na ▁Europa ▁e ▁Estados ▁Unidos ) ▁e ▁dos ▁Carrera ▁Cup [MASK] [MASK] 3 ▁Cup [SEP] [MASK] [MASK] , [MASK] [MASK] ▁passou ▁a ▁ter [MASK] ▁campeonato [MASK] ▁denominado ▁Porsche ▁GT 3 ▁Cup ▁Challenge ▁Brasil . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 24 618 7 571 136 4 5 11 19892 9956 622 6243 18575 94 9 18 53 2531 22550 12 371 25548 12 94 6 27028 2496 33 76 6 1331 4 8 4 12 19892 9956 622 6243 18575 94 5 11 86 4 3352 7761 13 19892 4 4478 12 285 7 17159 61 3511 4 2021 349 2884 9956 622 6243 5 69 4 4 394 396 4 308 12 19892 1933 13634 29 222 4098 408 109 4 4 22550 36 14329 25548 10 6 27028 118 13747 25 549 9 216 224 46 9 36 23872 6243 4 4 622 6243 3 4 4 5 4 4 310 8 137 4 1024 4 2798 19892 9956 622 6243 18575 94 7 3\n",
            "I1209 17:37:31.672006 140687693150080 create_pretraining_data.py:197] input_ids: 2 24 618 7 571 136 4 5 11 19892 9956 622 6243 18575 94 9 18 53 2531 22550 12 371 25548 12 94 6 27028 2496 33 76 6 1331 4 8 4 12 19892 9956 622 6243 18575 94 5 11 86 4 3352 7761 13 19892 4 4478 12 285 7 17159 61 3511 4 2021 349 2884 9956 622 6243 5 69 4 4 394 396 4 308 12 19892 1933 13634 29 222 4098 408 109 4 4 22550 36 14329 25548 10 6 27028 118 13747 25 549 9 216 224 46 9 36 23872 6243 4 4 622 6243 3 4 4 5 4 4 310 8 137 4 1024 4 2798 19892 9956 622 6243 18575 94 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.672175 140687693150080 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.672285 140687693150080 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:37:31.672411 140687693150080 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 32 34 45 50 58 67 68 71 82 83 103 104 108 109 111 112 116 118 0\n",
            "I1209 17:37:31.672483 140687693150080 create_pretraining_data.py:197] masked_lm_positions: 6 32 34 45 50 58 67 68 71 82 83 103 104 108 109 111 112 116 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 487 1438 965 1024 25 203 2380 8 6 6958 31 9 9956 43 1331 11 94 44 5 0\n",
            "I1209 17:37:31.672576 140687693150080 create_pretraining_data.py:197] masked_lm_ids: 487 1438 965 1024 25 203 2380 8 6 6958 31 9 9956 43 1331 11 94 44 5 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:37:31.672650 140687693150080 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:37:31.672716 140687693150080 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:Wrote 272922 total instances\n",
            "I1209 17:39:00.028989 140407190394752 create_pretraining_data.py:202] Wrote 272922 total instances\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1209 17:39:04.909183 140365583124352 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1209 17:39:04.986258 140365583124352 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I1209 17:39:04.987255 140365583124352 create_pretraining_data.py:628] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0002\n",
            "I1209 17:39:04.987460 140365583124352 create_pretraining_data.py:630]   ./shards/shard_0002\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1209 17:39:04.988198 140365583124352 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Wrote 270441 total instances\n",
            "I1209 17:39:05.071105 140687693150080 create_pretraining_data.py:202] Wrote 270441 total instances\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W1209 17:39:09.983899 140591368152960 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:618: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W1209 17:39:10.063357 140591368152960 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:626: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I1209 17:39:10.064347 140591368152960 create_pretraining_data.py:628] *** Reading from input files ***\n",
            "INFO:tensorflow:  ./shards/shard_0003\n",
            "I1209 17:39:10.064515 140591368152960 create_pretraining_data.py:630]   ./shards/shard_0003\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1209 17:39:10.065275 140591368152960 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:228: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:number of instances: 251918\n",
            "I1209 17:49:29.869569 140591368152960 create_pretraining_data.py:638] number of instances: 251918\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I1209 17:49:29.870386 140591368152960 create_pretraining_data.py:641] *** Writing to output files ***\n",
            "INFO:tensorflow:  gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0003.tfrecord\n",
            "I1209 17:49:29.870465 140591368152960 create_pretraining_data.py:643]   gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0003.tfrecord\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1209 17:49:29.870703 140591368152960 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.871929 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Trata - se ▁de ▁uma ▁espe cie ▁presente [MASK] ▁ter rito rio ▁por tu gues . [SEP] ▁Plat y der us ▁lu si tan icus ▁e ▁uma ▁espe cie [MASK] ▁insetos ▁cole op tero s ▁pertencente ▁a [MASK] [MASK] . [MASK] ▁autoridade ▁ cientific a ▁da ▁espe cie ▁e ▁Dejean , [MASK] ▁sido ▁descrita ▁no ▁ano [MASK] ▁1828 [MASK] [SEP]\n",
            "I1209 17:49:29.872118 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁Trata - se ▁de ▁uma ▁espe cie ▁presente [MASK] ▁ter rito rio ▁por tu gues . [SEP] ▁Plat y der us ▁lu si tan icus ▁e ▁uma ▁espe cie [MASK] ▁insetos ▁cole op tero s ▁pertencente ▁a [MASK] [MASK] . [MASK] ▁autoridade ▁ cientific a ▁da ▁espe cie ▁e ▁Dejean , [MASK] ▁sido ▁descrita ▁no ▁ano [MASK] ▁1828 [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 536 16 34 6 18 8073 6686 334 4 137 5353 1561 26 835 7657 7 3 20106 156 690 339 4698 1532 2519 12937 9 18 8073 6686 4 911 8829 3128 5385 10 395 8 4 4 7 4 521 19 20102 49 13 8073 6686 9 22169 5 4 131 665 22 76 4 14923 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.872257 140591368152960 create_pretraining_data.py:197] input_ids: 2 536 16 34 6 18 8073 6686 334 4 137 5353 1561 26 835 7657 7 3 20106 156 690 339 4698 1532 2519 12937 9 18 8073 6686 4 911 8829 3128 5385 10 395 8 4 4 7 4 521 19 20102 49 13 8073 6686 9 22169 5 4 131 665 22 76 4 14923 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.872390 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.872491 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.872583 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 9 27 30 38 39 41 52 57 59 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.872649 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 9 27 30 38 39 41 52 57 59 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 22 18 6 25717 5978 28 169 6 7 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.872713 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 22 18 6 25717 5978 28 169 6 7 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:49:29.872781 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:29.872838 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.873344 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁supremo , ▁aquele ▁que ▁e ▁o ▁uni co , ▁proibiu [MASK] ▁o ▁que ▁pre za m : ▁livros [MASK] ▁musica , ▁arte ▁e ▁imagina ca o . [MASK] ▁a ▁crescente ▁for ca ▁da [MASK] ▁dos ▁ir ma os ▁na o ▁foi ▁suficiente ▁para [MASK] ▁colega ▁Ishi ▁mal ▁do ▁Uni co [MASK] ▁e ▁agora ▁ele ▁esta [MASK] ▁a ▁ unica ▁familia ▁que ▁lhe ▁restava [SEP] s ▁e ▁Bruxa s , ▁Whit ▁e ▁Wi s ty , ▁agora ▁membros [MASK] ▁cientificamente [MASK] ▁esta o ▁tentando ▁reconstruir ▁a ▁cidade ▁depois [MASK] ▁derrotar [MASK] ▁Uni co ▁Que ▁E ▁O ▁Uni co , ▁o ▁vila o ▁mais ▁mal va do ▁do ▁mundo . ▁Quando ▁tudo ▁parece ▁correr ▁bem , ▁surge ▁uma [MASK] ▁a me aca [MASK] ▁personifica da ▁na [MASK] ▁do [SEP]\n",
            "I1209 17:49:29.873478 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁supremo , ▁aquele ▁que ▁e ▁o ▁uni co , ▁proibiu [MASK] ▁o ▁que ▁pre za m : ▁livros [MASK] ▁musica , ▁arte ▁e ▁imagina ca o . [MASK] ▁a ▁crescente ▁for ca ▁da [MASK] ▁dos ▁ir ma os ▁na o ▁foi ▁suficiente ▁para [MASK] ▁colega ▁Ishi ▁mal ▁do ▁Uni co [MASK] ▁e ▁agora ▁ele ▁esta [MASK] ▁a ▁ unica ▁familia ▁que ▁lhe ▁restava [SEP] s ▁e ▁Bruxa s , ▁Whit ▁e ▁Wi s ty , ▁agora ▁membros [MASK] ▁cientificamente [MASK] ▁esta o ▁tentando ▁reconstruir ▁a ▁cidade ▁depois [MASK] ▁derrotar [MASK] ▁Uni co ▁Que ▁E ▁O ▁Uni co , ▁o ▁vila o ▁mais ▁mal va do ▁do ▁mundo . ▁Quando ▁tudo ▁parece ▁correr ▁bem , ▁surge ▁uma [MASK] ▁a me aca [MASK] ▁personifica da ▁na [MASK] ▁do [SEP]\n",
            "INFO:tensorflow:input_ids: 2 17636 5 2740 15 9 11 3282 238 5 17064 4 11 15 762 809 48 42 1002 4 13733 5 868 9 9602 228 52 7 4 8 3534 728 228 13 4 36 1311 295 239 25 52 30 2487 24 4 5718 22601 1203 12 3876 238 4 9 849 69 233 4 8 19 20017 25717 15 588 21388 3 10 9 19895 10 5 16132 9 3033 10 1583 5 849 553 4 20069 4 233 52 4647 16916 8 83 115 4 5178 4 3876 238 2303 179 33 3876 238 5 11 1925 52 39 1203 84 61 12 219 7 486 922 1820 9091 197 5 4319 18 4 8 336 4306 4 22261 62 25 4 12 3\n",
            "I1209 17:49:29.873603 140591368152960 create_pretraining_data.py:197] input_ids: 2 17636 5 2740 15 9 11 3282 238 5 17064 4 11 15 762 809 48 42 1002 4 13733 5 868 9 9602 228 52 7 4 8 3534 728 228 13 4 36 1311 295 239 25 52 30 2487 24 4 5718 22601 1203 12 3876 238 4 9 849 69 233 4 8 19 20017 25717 15 588 21388 3 10 9 19895 10 5 16132 9 3033 10 1583 5 849 553 4 20069 4 233 52 4647 16916 8 83 115 4 5178 4 3876 238 2303 179 33 3876 238 5 11 1925 52 39 1203 84 61 12 219 7 486 922 1820 9091 197 5 4319 18 4 8 336 4306 4 22261 62 25 4 12 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.873701 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.873793 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1\n",
            "I1209 17:49:29.873883 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 11 19 20 28 34 44 45 46 51 56 78 79 80 88 90 108 117 121 125 0\n",
            "I1209 17:49:29.873949 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 11 19 20 28 34 44 45 46 51 56 78 79 80 88 90 108 117 121 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 922 5 13733 554 8083 24 41 11 5 22343 12 968 5 6 33 7 314 5 1443 0\n",
            "I1209 17:49:29.874012 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 922 5 13733 554 8083 24 41 11 5 22343 12 968 5 6 33 7 314 5 1443 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:29.874078 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:49:29.874135 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.874612 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁As ▁a udi co es ▁foram ▁realizadas ▁nas ▁seguintes ▁cidades : ▁As ▁a udi co es ▁as ▁cega s ▁( em ▁ ing les , [MASK] [MASK] [MASK] ▁a [MASK] [MASK] [MASK] ▁foram ▁gravadas ▁entre ▁os ▁dias ▁10 ▁e ▁13 ▁de ▁outubro ▁de ▁2013. [SEP] ▁uma ▁vez ▁que ▁Kaufman ▁com e cou ▁a [MASK] [MASK] ▁time ▁de ▁Adam ▁Levi ne . ▁A ▁sexta ▁temporada ▁do ▁\" reality \" ▁tem ▁como ▁grande ▁novidade ▁as ▁volta s ▁de [MASK] [MASK] ▁U s her ▁no ▁lugar ▁de ▁Christina ▁Aguilera ▁e ▁Ce e ▁Lo [MASK] [MASK] [MASK] , ▁os ▁dois ▁ja ▁haviam ▁sido ▁tec nico s ▁na [MASK] ▁e dica o . ▁Adam ▁Levi ne ▁e ▁Blake ▁Shelton ▁permanecem ▁no ▁programa enburg [MASK] [MASK] ▁continua ▁no ▁\" The ▁Voice \" [SEP]\n",
            "I1209 17:49:29.874739 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁As ▁a udi co es ▁foram ▁realizadas ▁nas ▁seguintes ▁cidades : ▁As ▁a udi co es ▁as ▁cega s ▁( em ▁ ing les , [MASK] [MASK] [MASK] ▁a [MASK] [MASK] [MASK] ▁foram ▁gravadas ▁entre ▁os ▁dias ▁10 ▁e ▁13 ▁de ▁outubro ▁de ▁2013. [SEP] ▁uma ▁vez ▁que ▁Kaufman ▁com e cou ▁a [MASK] [MASK] ▁time ▁de ▁Adam ▁Levi ne . ▁A ▁sexta ▁temporada ▁do ▁\" reality \" ▁tem ▁como ▁grande ▁novidade ▁as ▁volta s ▁de [MASK] [MASK] ▁U s her ▁no ▁lugar ▁de ▁Christina ▁Aguilera ▁e ▁Ce e ▁Lo [MASK] [MASK] [MASK] , ▁os ▁dois ▁ja ▁haviam ▁sido ▁tec nico s ▁na [MASK] ▁e dica o . ▁Adam ▁Levi ne ▁e ▁Blake ▁Shelton ▁permanecem ▁no ▁programa enburg [MASK] [MASK] ▁continua ▁no ▁\" The ▁Voice \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 134 8 8543 238 101 75 3055 107 501 891 42 134 8 8543 238 101 40 20397 10 29 136 19 498 1085 5 4 4 4 8 4 4 4 75 7272 60 32 475 243 9 366 6 389 6 2220 3 18 140 15 28236 21 70 4465 8 4 4 702 6 5723 12921 298 7 28 3440 362 12 17 21458 27 93 31 113 13329 40 386 10 6 4 4 572 10 4153 22 290 6 19383 21297 9 2144 70 1088 4 4 4 5 32 97 3579 1849 131 5735 8359 10 25 4 9 4688 52 7 5723 12921 298 9 19193 27018 9331 22 301 17617 4 4 1806 22 17 300 16417 27 3\n",
            "I1209 17:49:29.874858 140591368152960 create_pretraining_data.py:197] input_ids: 2 134 8 8543 238 101 75 3055 107 501 891 42 134 8 8543 238 101 40 20397 10 29 136 19 498 1085 5 4 4 4 8 4 4 4 75 7272 60 32 475 243 9 366 6 389 6 2220 3 18 140 15 28236 21 70 4465 8 4 4 702 6 5723 12921 298 7 28 3440 362 12 17 21458 27 93 31 113 13329 40 386 10 6 4 4 572 10 4153 22 290 6 19383 21297 9 2144 70 1088 4 4 4 5 32 97 3579 1849 131 5735 8359 10 25 4 9 4688 52 7 5723 12921 298 9 19193 27018 9331 22 301 17617 4 4 1806 22 17 300 16417 27 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.874956 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.875047 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            "I1209 17:49:29.875135 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 0 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 26 27 28 29 30 31 32 54 55 68 77 78 91 92 93 104 118 119 120 0\n",
            "I1209 17:49:29.875200 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 26 27 28 29 30 31 32 54 55 68 77 78 91 92 93 104 118 119 120 0\n",
            "INFO:tensorflow:masked_lm_ids: 17 17214 143 8 8543 8670 323 1122 57 27 8019 9 5284 7 13336 2269 7 9974 27557 0\n",
            "I1209 17:49:29.875262 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 17 17214 143 8 8543 8670 323 1122 57 27 8019 9 5284 7 13336 2269 7 9974 27557 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:29.875356 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:29.875416 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.875858 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ter ▁e ▁Gru sin ▁falam ▁de ▁uma ▁re la ca o ▁de ▁depende ncia ▁mu tua ▁entre ▁i media ca o ▁e ▁hiper media ca o . ▁Como ▁exemplo [MASK] ▁eles ▁cita m ▁as ▁\" web cam s \", ▁que , ▁a pesar ▁de ▁funcionar em ▁sob ▁a ▁lo gica ▁da ▁i media ca o , ▁podem ▁ser ▁inserida s ▁em ▁web ▁sites [SEP] e - se ▁a ▁rede ▁de ▁TV [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁com ▁a ▁sua [MASK] [MASK] ▁diferentes [MASK] [MASK] [MASK] [MASK] ▁ou , ▁ainda [MASK] ▁diferentes ▁sites , ▁home ▁pa ges ▁e ▁game s , [MASK] ▁quais ▁diferentes ▁linguagens ▁sa o [MASK] ▁ao ▁mesmo ▁tempo ▁tais ▁como ▁fotografia , ▁video , ▁texto , ▁ ico nes , ▁numero s [MASK] [SEP]\n",
            "I1209 17:49:29.875987 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ter ▁e ▁Gru sin ▁falam ▁de ▁uma ▁re la ca o ▁de ▁depende ncia ▁mu tua ▁entre ▁i media ca o ▁e ▁hiper media ca o . ▁Como ▁exemplo [MASK] ▁eles ▁cita m ▁as ▁\" web cam s \", ▁que , ▁a pesar ▁de ▁funcionar em ▁sob ▁a ▁lo gica ▁da ▁i media ca o , ▁podem ▁ser ▁inserida s ▁em ▁web ▁sites [SEP] e - se ▁a ▁rede ▁de ▁TV [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁com ▁a ▁sua [MASK] [MASK] ▁diferentes [MASK] [MASK] [MASK] [MASK] ▁ou , ▁ainda [MASK] ▁diferentes ▁sites , ▁home ▁pa ges ▁e ▁game s , [MASK] ▁quais ▁diferentes ▁linguagens ▁sa o [MASK] ▁ao ▁mesmo ▁tempo ▁tais ▁como ▁fotografia , ▁video , ▁texto , ▁ ico nes , ▁numero s [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 410 9 12884 4781 11790 6 18 172 135 228 52 6 4940 4428 2750 8960 60 2104 9320 228 52 9 6035 9320 228 52 7 447 313 4 251 6843 48 40 17 19839 9397 10 47 15 5 8 302 6 7729 136 270 8 2763 9581 13 2104 9320 228 52 5 258 55 11598 10 14 8479 11475 3 70 16 34 8 874 6 492 4 4 4 4 4 4 21 8 38 4 4 509 4 4 4 4 51 5 108 4 509 11475 5 11687 2574 4344 9 6254 10 5 4 358 509 9778 1577 52 4 37 88 152 812 31 5247 5 7949 5 1461 5 19 2923 1956 5 19308 10 4 3\n",
            "I1209 17:49:29.940364 140591368152960 create_pretraining_data.py:197] input_ids: 2 410 9 12884 4781 11790 6 18 172 135 228 52 6 4940 4428 2750 8960 60 2104 9320 228 52 9 6035 9320 228 52 7 447 313 4 251 6843 48 40 17 19839 9397 10 47 15 5 8 302 6 7729 136 270 8 2763 9581 13 2104 9320 228 52 5 258 55 11598 10 14 8479 11475 3 70 16 34 8 874 6 492 4 4 4 4 4 4 21 8 38 4 4 509 4 4 4 4 51 5 108 4 509 11475 5 11687 2574 4344 9 6254 10 5 4 358 509 9778 1577 52 4 37 88 152 812 31 5247 5 7949 5 1461 5 19 2923 1956 5 19308 10 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.940543 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.940664 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            "I1209 17:49:29.940873 140591368152960 create_pretraining_data.py:197] token_boundary: 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 1 1 0 0 0 0 1 1 1 0 1 1 0 1 1 1 0 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 30 68 72 73 74 75 76 77 81 82 83 84 85 86 87 91 102 108 126 0\n",
            "I1209 17:49:29.940971 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 30 68 72 73 74 75 76 77 81 82 83 84 85 86 87 91 102 108 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 8 17 279 145 5614 2514 47 3482 3736 509 3649 735 10 5 5 85 10090 5 0\n",
            "I1209 17:49:29.941055 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 5 8 17 279 145 5614 2514 47 3482 3736 509 3649 735 10 5 5 85 10090 5 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:29.941141 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:29.941216 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.941840 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ; ▁ja ▁neste ▁ano ▁participou ▁do ▁1 o ▁Festival ▁da ▁Radio ▁e ▁T v ▁Record [MASK] ▁ficando ▁no ▁segundo ▁lugar ▁com ▁a ▁can ca o ▁\" Trop as ▁e [MASK] [MASK] [MASK] ▁no ▁ano ▁seguinte ▁voltou [MASK] [MASK] [MASK] ▁concurso , ▁em ▁parceria ▁com ▁Jose ▁Fortuna , ▁apresentando ▁ tre s ▁com pos ico es [MASK] ▁ficaram ▁com ▁os ▁ tre s ▁primeiros [SEP] [MASK] [MASK] [MASK] ▁Ce zar ▁Dora cio ▁( Pra do polis , [MASK] [MASK] [MASK] ▁de ▁1942 ▁— ▁Mogi ▁Gua cu , [MASK] ▁de ▁maio ▁de ▁2002) , ▁foi ▁um ▁compositor , ▁instrumentista , ▁produtor ▁e [MASK] [MASK] . ▁A pesar ▁de ▁ter ▁sido ▁registrado ▁como ▁nascido ▁em ▁Prado polis , ▁seu ▁local ▁de ▁nascimento ▁foi ▁as ▁margens ▁do ▁rio ▁Araguaia . [SEP]\n",
            "I1209 17:49:29.942017 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ; ▁ja ▁neste ▁ano ▁participou ▁do ▁1 o ▁Festival ▁da ▁Radio ▁e ▁T v ▁Record [MASK] ▁ficando ▁no ▁segundo ▁lugar ▁com ▁a ▁can ca o ▁\" Trop as ▁e [MASK] [MASK] [MASK] ▁no ▁ano ▁seguinte ▁voltou [MASK] [MASK] [MASK] ▁concurso , ▁em ▁parceria ▁com ▁Jose ▁Fortuna , ▁apresentando ▁ tre s ▁com pos ico es [MASK] ▁ficaram ▁com ▁os ▁ tre s ▁primeiros [SEP] [MASK] [MASK] [MASK] ▁Ce zar ▁Dora cio ▁( Pra do polis , [MASK] [MASK] [MASK] ▁de ▁1942 ▁— ▁Mogi ▁Gua cu , [MASK] ▁de ▁maio ▁de ▁2002) , ▁foi ▁um ▁compositor , ▁instrumentista , ▁produtor ▁e [MASK] [MASK] . ▁A pesar ▁de ▁ter ▁sido ▁registrado ▁como ▁nascido ▁em ▁Prado polis , ▁seu ▁local ▁de ▁nascimento ▁foi ▁as ▁margens ▁do ▁rio ▁Araguaia . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 72 3579 985 76 790 12 118 52 1651 13 8901 9 319 485 3340 4 1996 22 186 290 21 8 3530 228 52 17 24285 422 9 4 4 4 22 76 322 979 4 4 4 3099 5 14 1585 21 12428 21648 5 3736 19 1678 10 21 2718 2923 101 4 2879 21 32 19 1678 10 604 3 4 4 4 2144 2904 19931 1888 29 12670 61 14051 5 4 4 4 6 4125 403 21090 3780 1264 5 4 6 367 6 19431 5 30 20 1639 5 17642 5 1779 9 4 4 7 28 302 6 137 131 8513 31 2400 14 8911 14051 5 44 388 6 2572 30 40 4523 12 731 24436 7 3\n",
            "I1209 17:49:29.942164 140591368152960 create_pretraining_data.py:197] input_ids: 2 72 3579 985 76 790 12 118 52 1651 13 8901 9 319 485 3340 4 1996 22 186 290 21 8 3530 228 52 17 24285 422 9 4 4 4 22 76 322 979 4 4 4 3099 5 14 1585 21 12428 21648 5 3736 19 1678 10 21 2718 2923 101 4 2879 21 32 19 1678 10 604 3 4 4 4 2144 2904 19931 1888 29 12670 61 14051 5 4 4 4 6 4125 403 21090 3780 1264 5 4 6 367 6 19431 5 30 20 1639 5 17642 5 1779 9 4 4 7 28 302 6 137 131 8513 31 2400 14 8911 14051 5 44 388 6 2572 30 40 4523 12 731 24436 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.942278 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.942409 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.942515 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 16 17 30 31 32 37 38 39 56 65 66 67 77 78 79 87 98 101 102 0\n",
            "I1209 17:49:29.942595 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 16 17 30 31 32 37 38 39 56 65 66 67 77 78 79 87 98 101 102 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 1996 12544 1251 2115 8 1725 12 15 2564 8372 494 146 6 418 240 5 1354 340 0\n",
            "I1209 17:49:29.942672 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 5 1996 12544 1251 2115 8 1725 12 15 2564 8372 494 146 6 418 240 5 1354 340 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:29.942754 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:29.942827 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.943257 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] ndo ▁a ▁personagem ▁Clarice . [SEP] ▁Em ▁2018 , ▁a pos ▁estar ▁longe ▁dos ▁palcos ▁e ▁da ▁TV , ▁ luc iana ▁Coutinho ▁volta cre 3,9 desde ▁a ▁pe ca ▁\" Solid ao , ▁que ▁nada \" [SEP]\n",
            "I1209 17:49:29.943423 140591368152960 create_pretraining_data.py:187] tokens: [CLS] [MASK] ndo ▁a ▁personagem ▁Clarice . [SEP] ▁Em ▁2018 , ▁a pos ▁estar ▁longe ▁dos ▁palcos ▁e ▁da ▁TV , ▁ luc iana ▁Coutinho ▁volta cre 3,9 desde ▁a ▁pe ca ▁\" Solid ao , ▁que ▁nada \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 65 8 541 27020 7 3 43 3749 5 8 2718 945 3313 36 9796 9 13 492 5 19 16359 2558 8925 386 2535 26344 16885 8 2363 228 17 27054 8372 5 15 1801 27 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.943551 140591368152960 create_pretraining_data.py:197] input_ids: 2 4 65 8 541 27020 7 3 43 3749 5 8 2718 945 3313 36 9796 9 13 492 5 19 16359 2558 8925 386 2535 26344 16885 8 2363 228 17 27054 8372 5 15 1801 27 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.943653 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.943744 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.943829 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 1 2 13 26 27 28 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.943892 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 1 2 13 26 27 28 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 22189 65 945 119 9796 21 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.943966 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 22189 65 945 119 9796 21 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:49:29.944031 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:29.944087 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.944563 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Dorival ▁Caymmi ▁e ▁com ▁o ▁e nta o ▁vice - presidente ▁Jo ao ▁Goulart . ▁Participou ▁ainda ▁dos ▁primo r dios ▁da ▁tele vis ao ▁brasileira , ▁e ▁causando ▁esca nda lo , ▁como ▁numa ▁e dica o ▁do ▁programa ▁\" Esp eta culos ▁To ne lux \", ▁Basquetebol ▁27 ▁de ▁dezembro ▁de ▁1956 , ▁na ▁TV ▁Continental [MASK] ▁onde ▁apareceu ▁com ▁roupas ▁lançadas rias [MASK] [MASK] ▁re aca o ▁na [SEP] ▁Angel ita ▁Martinez ▁( Sa o ▁Paulo , [MASK] íveis ▁maio ▁de ▁1931 [MASK] ▁Sa o ▁Paulo , ▁13 ▁de ▁janeiro ▁de ▁1980) ▁foi ▁uma ▁ve [MASK] [MASK] , ▁atriz ▁e ▁cantora ▁brasileira . ▁Gravou ▁algumas ▁musica s [MASK] [MASK] [MASK] ▁para ▁carnaval , ▁de ▁sucesso ▁relativo ▁nos [MASK] [MASK] [MASK] [MASK] ▁de ▁1960. [SEP]\n",
            "I1209 17:49:29.944692 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁Dorival ▁Caymmi ▁e ▁com ▁o ▁e nta o ▁vice - presidente ▁Jo ao ▁Goulart . ▁Participou ▁ainda ▁dos ▁primo r dios ▁da ▁tele vis ao ▁brasileira , ▁e ▁causando ▁esca nda lo , ▁como ▁numa ▁e dica o ▁do ▁programa ▁\" Esp eta culos ▁To ne lux \", ▁Basquetebol ▁27 ▁de ▁dezembro ▁de ▁1956 , ▁na ▁TV ▁Continental [MASK] ▁onde ▁apareceu ▁com ▁roupas ▁lançadas rias [MASK] [MASK] ▁re aca o ▁na [SEP] ▁Angel ita ▁Martinez ▁( Sa o ▁Paulo , [MASK] íveis ▁maio ▁de ▁1931 [MASK] ▁Sa o ▁Paulo , ▁13 ▁de ▁janeiro ▁de ▁1980) ▁foi ▁uma ▁ve [MASK] [MASK] , ▁atriz ▁e ▁cantora ▁brasileira . ▁Gravou ▁algumas ▁musica s [MASK] [MASK] [MASK] ▁para ▁carnaval , ▁de ▁sucesso ▁relativo ▁nos [MASK] [MASK] [MASK] [MASK] ▁de ▁1960. [SEP]\n",
            "INFO:tensorflow:input_ids: 2 28264 25603 9 21 11 9 1883 52 773 16 2447 2564 8372 10322 7 4994 108 36 3648 41 12926 13 4461 2959 8372 517 5 9 5492 5879 1597 145 5 31 384 9 4688 52 12 301 17 13074 2823 10822 1004 298 13965 47 23236 787 6 409 6 6417 5 25 492 2818 4 80 1971 21 4392 7946 6993 4 4 172 4306 52 25 3 4564 808 23880 29 2157 52 165 5 4 3229 367 6 5019 4 499 52 165 5 366 6 391 6 16730 30 18 3396 4 4 5 718 9 770 517 7 25395 341 13733 10 4 4 4 24 3250 5 6 308 10589 85 4 4 4 4 6 9321 3\n",
            "I1209 17:49:29.944813 140591368152960 create_pretraining_data.py:197] input_ids: 2 28264 25603 9 21 11 9 1883 52 773 16 2447 2564 8372 10322 7 4994 108 36 3648 41 12926 13 4461 2959 8372 517 5 9 5492 5879 1597 145 5 31 384 9 4688 52 12 301 17 13074 2823 10822 1004 298 13965 47 23236 787 6 409 6 6417 5 25 492 2818 4 80 1971 21 4392 7946 6993 4 4 172 4306 52 25 3 4564 808 23880 29 2157 52 165 5 4 3229 367 6 5019 4 499 52 165 5 366 6 391 6 16730 30 18 3396 4 4 5 718 9 770 517 7 25395 341 13733 10 4 4 4 24 3250 5 6 308 10589 85 4 4 4 4 6 9321 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.944923 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:29.945015 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            "I1209 17:49:29.945104 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 49 59 64 65 66 67 81 82 86 98 99 100 111 112 113 121 122 123 124 0\n",
            "I1209 17:49:29.945170 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 49 59 64 65 66 67 81 82 86 98 99 100 111 112 113 121 122 123 124 0\n",
            "INFO:tensorflow:masked_lm_ids: 6 5 14451 6993 5 5492 312 6 403 3396 103 204 4908 9366 10 66 13 6 5105 0\n",
            "I1209 17:49:29.945233 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 6 5 14451 6993 5 5492 312 6 403 3396 103 204 4908 9366 10 66 13 6 5105 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:29.945310 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:29.945374 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.945802 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁A ▁Che cos lo va quia ▁ competiu ▁nos ▁Jogos [MASK] ▁sigla [MASK] [MASK] ▁de ▁Vera o ▁de ▁1960 [MASK] ducado ▁em ▁Roma , ▁Italia [MASK] [SEP] [MASK] [MASK] [MASK] ▁paga nett ii ▁e ▁uma ▁espe cie ▁de ▁insetos ▁cole op tero s ▁poli fa gos ▁pertencente ▁a ▁familia ▁Hister idae . ▁A ▁autoridade ▁ cientific a ▁da ▁espe cie ▁e ▁Bi ck hard t , ▁tendo ▁sido ▁descrita ▁no ▁ano ▁de ▁1911 . [MASK] - se ▁de ▁uma ▁espe cie [MASK] ▁no ▁ter rito rio ▁por tu gues . [SEP]\n",
            "I1209 17:49:29.945915 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁A ▁Che cos lo va quia ▁ competiu ▁nos ▁Jogos [MASK] ▁sigla [MASK] [MASK] ▁de ▁Vera o ▁de ▁1960 [MASK] ducado ▁em ▁Roma , ▁Italia [MASK] [SEP] [MASK] [MASK] [MASK] ▁paga nett ii ▁e ▁uma ▁espe cie ▁de ▁insetos ▁cole op tero s ▁poli fa gos ▁pertencente ▁a ▁familia ▁Hister idae . ▁A ▁autoridade ▁ cientific a ▁da ▁espe cie ▁e ▁Bi ck hard t , ▁tendo ▁sido ▁descrita ▁no ▁ano ▁de ▁1911 . [MASK] - se ▁de ▁uma ▁espe cie [MASK] ▁no ▁ter rito rio ▁por tu gues . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 28 3253 1584 145 84 4271 19 5972 85 1469 4 8105 4 4 6 8278 52 6 3698 4 28157 14 916 5 19938 4 3 4 4 4 5103 18709 3764 9 18 8073 6686 6 911 8829 3128 5385 10 2128 763 3362 395 8 25717 23278 1487 7 28 521 19 20102 49 13 8073 6686 9 1863 676 8803 105 5 169 131 665 22 76 6 7576 7 4 16 34 6 18 8073 6686 4 22 137 5353 1561 26 835 7657 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.946053 140591368152960 create_pretraining_data.py:197] input_ids: 2 28 3253 1584 145 84 4271 19 5972 85 1469 4 8105 4 4 6 8278 52 6 3698 4 28157 14 916 5 19938 4 3 4 4 4 5103 18709 3764 9 18 8073 6686 6 911 8829 3128 5385 10 2128 763 3362 395 8 25717 23278 1487 7 28 521 19 20102 49 13 8073 6686 9 1863 676 8803 105 5 169 131 665 22 76 6 7576 7 4 16 34 6 18 8073 6686 4 22 137 5353 1561 26 835 7657 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.946151 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.946243 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:29.946353 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 11 12 13 14 15 20 21 26 28 29 30 75 82 83 0 0 0 0 0 0\n",
            "I1209 17:49:29.946421 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 11 12 13 14 15 20 21 26 28 29 30 75 82 83 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 33 4073 11366 10 6 5 2851 7 4309 8646 339 536 334 22 0 0 0 0 0 0\n",
            "I1209 17:49:29.946483 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 33 4073 11366 10 6 5 2851 7 4309 8646 339 536 334 22 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:49:29.946549 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:29.946606 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:29.947118 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] er ▁a ▁carne ▁e [MASK] - la ▁com ▁a lho [MASK] [MASK] [MASK] [MASK] ▁e l ▁ han out , ▁canela ▁e ▁com inho ▁mo idos ▁( se ▁a ▁combina ca o ▁dis po ni vel ▁do ▁ra z ▁e l ▁ han out ▁na o ▁inclui ▁estes ▁tempero s ), ▁ har issa , ▁azeite , [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [SEP] [MASK] ▁Evangelho ▁Franca [MASK] [MASK] ▁pais es ▁a ▁ mer gue z ▁e ▁feita ▁ferroviária [MASK] ▁mistura ▁de ▁carne s ▁de ▁vaca ▁e ▁carneiro ▁e , [MASK] ▁Nova ▁Ze land ia ▁existe ▁mesmo ▁uma ▁prepara ca o ▁comercial ▁com ▁uma ▁mistura ▁carne ▁de ▁vaca ▁e ▁de ▁por co ▁( no ▁Mag re b , ▁as ▁pessoas ▁sa o ▁ maioritariamente ▁mu cul [SEP]\n",
            "I1209 17:49:29.947255 140591368152960 create_pretraining_data.py:187] tokens: [CLS] er ▁a ▁carne ▁e [MASK] - la ▁com ▁a lho [MASK] [MASK] [MASK] [MASK] ▁e l ▁ han out , ▁canela ▁e ▁com inho ▁mo idos ▁( se ▁a ▁combina ca o ▁dis po ni vel ▁do ▁ra z ▁e l ▁ han out ▁na o ▁inclui ▁estes ▁tempero s ), ▁ har issa , ▁azeite , [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [SEP] [MASK] ▁Evangelho ▁Franca [MASK] [MASK] ▁pais es ▁a ▁ mer gue z ▁e ▁feita ▁ferroviária [MASK] ▁mistura ▁de ▁carne s ▁de ▁vaca ▁e ▁carneiro ▁e , [MASK] ▁Nova ▁Ze land ia ▁existe ▁mesmo ▁uma ▁prepara ca o ▁comercial ▁com ▁uma ▁mistura ▁carne ▁de ▁vaca ▁e ▁de ▁por co ▁( no ▁Mag re b , ▁as ▁pessoas ▁sa o ▁ maioritariamente ▁mu cul [SEP]\n",
            "INFO:tensorflow:input_ids: 2 257 8 3148 9 4 16 135 21 8 2078 4 4 4 4 9 106 19 2133 7005 5 23257 9 21 1846 1785 5297 29 34 8 7919 228 52 2573 741 402 1702 12 1901 284 9 106 19 2133 7005 25 52 1169 1232 25273 10 59 19 3796 10585 5 19057 5 4 4 4 4 4 4 3 4 10908 12332 4 4 1480 101 8 19 1407 1389 284 9 952 10500 4 1892 6 3148 10 6 16172 9 24902 9 5 4 260 3364 1393 128 1136 88 18 8183 228 52 1453 21 18 1892 3148 6 16172 9 6 26 238 29 171 3618 250 213 5 40 247 1577 52 19 18405 2750 4596 3\n",
            "I1209 17:49:29.947402 140591368152960 create_pretraining_data.py:197] input_ids: 2 257 8 3148 9 4 16 135 21 8 2078 4 4 4 4 9 106 19 2133 7005 5 23257 9 21 1846 1785 5297 29 34 8 7919 228 52 2573 741 402 1702 12 1901 284 9 106 19 2133 7005 25 52 1169 1232 25273 10 59 19 3796 10585 5 19057 5 4 4 4 4 4 4 3 4 10908 12332 4 4 1480 101 8 19 1407 1389 284 9 952 10500 4 1892 6 3148 10 6 16172 9 24902 9 5 4 260 3364 1393 128 1136 88 18 8183 228 52 1453 21 18 1892 3148 6 16172 9 6 26 238 29 171 3618 250 213 5 40 247 1577 52 19 18405 2750 4596 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.043784 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.044019 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1\n",
            "I1209 17:49:30.044139 140591368152960 create_pretraining_data.py:197] token_boundary: 1 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 0 1 0 1 1 1 0 0 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 0 1 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 11 12 13 14 58 59 60 61 62 63 65 66 68 69 79 80 91 98 0\n",
            "I1209 17:49:30.044229 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 5 11 12 13 14 58 59 60 61 62 63 65 66 68 69 79 80 91 98 0\n",
            "INFO:tensorflow:masked_lm_ids: 1892 25987 5 1901 284 2574 241 2922 9 2741 7 5 25 9 25652 21 18 25 18 0\n",
            "I1209 17:49:30.044345 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 1892 25987 5 1901 284 2574 241 2922 9 2741 7 5 25 9 25652 21 18 25 18 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.044434 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.044513 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.045145 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁O [MASK] ▁foi ▁ lan cado ▁pela [MASK] ▁vez ▁como ▁uma [MASK] [MASK] o ▁beta ▁aberta ▁e ▁mais ▁tarde ▁foi ▁liberado ▁para ▁compra ▁com ▁uma ▁ versa o ▁de ▁demonstra ca o ▁por ▁tempo ▁limitado . [SEP] . ▁O ▁jogador ▁assume ▁o ▁papel ▁de ▁um ▁\" ce re bro \" ▁fixo ▁ou ▁move l , ▁que ▁pode ▁assumir ▁o ▁controle ▁de ▁outras ▁unidades ▁adquirida s [MASK] ▁a ▁fim ▁de ▁al can car ▁os ▁objetivos . ▁Miss o es ▁Messenger ▁variam ▁de ▁tarefas [MASK] [MASK] ▁a ▁recupera ca o ▁de ▁um ▁chip ▁de ▁controle ▁em ▁uma ▁caverna ▁repleta ▁de ▁zumbi s ▁para ▁defender ▁o [MASK] [MASK] [MASK] ▁do ▁ataque . ▁Como ▁o [MASK] [MASK] [MASK] ▁e [MASK] , ▁o ▁jogador ▁deve ▁gerenciar ▁seus ▁recursos ▁com ▁cuidado , [SEP]\n",
            "I1209 17:49:30.045316 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁O [MASK] ▁foi ▁ lan cado ▁pela [MASK] ▁vez ▁como ▁uma [MASK] [MASK] o ▁beta ▁aberta ▁e ▁mais ▁tarde ▁foi ▁liberado ▁para ▁compra ▁com ▁uma ▁ versa o ▁de ▁demonstra ca o ▁por ▁tempo ▁limitado . [SEP] . ▁O ▁jogador ▁assume ▁o ▁papel ▁de ▁um ▁\" ce re bro \" ▁fixo ▁ou ▁move l , ▁que ▁pode ▁assumir ▁o ▁controle ▁de ▁outras ▁unidades ▁adquirida s [MASK] ▁a ▁fim ▁de ▁al can car ▁os ▁objetivos . ▁Miss o es ▁Messenger ▁variam ▁de ▁tarefas [MASK] [MASK] ▁a ▁recupera ca o ▁de ▁um ▁chip ▁de ▁controle ▁em ▁uma ▁caverna ▁repleta ▁de ▁zumbi s ▁para ▁defender ▁o [MASK] [MASK] [MASK] ▁do ▁ataque . ▁Como ▁o [MASK] [MASK] [MASK] ▁e [MASK] , ▁o ▁jogador ▁deve ▁gerenciar ▁seus ▁recursos ▁com ▁cuidado , [SEP]\n",
            "INFO:tensorflow:input_ids: 2 33 4 30 19 1818 7086 54 4 140 31 18 4 4 52 17359 3794 9 39 361 30 7531 24 2602 21 18 19 5733 52 6 5713 228 52 26 152 5269 7 3 7 33 700 4091 11 479 6 20 17 342 250 3971 27 8051 51 8366 106 5 15 110 3022 11 742 6 205 1554 7953 10 4 8 297 6 980 2816 1304 32 3900 7 3929 52 101 28804 7388 6 7099 4 4 8 13682 228 52 6 20 15161 6 742 14 18 16242 23858 6 13399 10 24 3001 11 4 4 4 12 1223 7 447 11 4 4 4 9 4 5 11 700 582 22439 78 1288 21 7481 5 3\n",
            "I1209 17:49:30.045473 140591368152960 create_pretraining_data.py:197] input_ids: 2 33 4 30 19 1818 7086 54 4 140 31 18 4 4 52 17359 3794 9 39 361 30 7531 24 2602 21 18 19 5733 52 6 5713 228 52 26 152 5269 7 3 7 33 700 4091 11 479 6 20 17 342 250 3971 27 8051 51 8366 106 5 15 110 3022 11 742 6 205 1554 7953 10 4 8 297 6 980 2816 1304 32 3900 7 3929 52 101 28804 7388 6 7099 4 4 8 13682 228 52 6 20 15161 6 742 14 18 16242 23858 6 13399 10 24 3001 11 4 4 4 12 1223 7 447 11 4 4 4 9 4 5 11 700 582 22439 78 1288 21 7481 5 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.045589 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.045696 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.045800 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 8 12 13 14 66 79 80 83 84 103 104 105 106 112 113 114 115 116 0\n",
            "I1209 17:49:30.045881 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 2 8 12 13 14 66 79 80 83 84 103 104 105 106 112 113 114 115 116 0\n",
            "INFO:tensorflow:masked_lm_ids: 246 100 19 5733 52 5 2797 7388 5 31 11 4638 70 3971 4638 70 3971 9 10784 0\n",
            "I1209 17:49:30.045959 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 246 100 19 5733 52 5 2797 7388 5 31 11 4638 70 3971 4638 70 3971 9 10784 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.046040 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.046111 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.046585 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁D ys chi rio des ▁cha ly ba eus ▁cha ly ba eus [MASK] ▁uma ▁sub es pe cie ▁de ▁insetos [MASK] [MASK] [MASK] [MASK] ▁pertencente ▁a ▁familia ▁Carabidae . [MASK] ▁autoridade ▁ cientific a [MASK] ▁sub es pe cie ▁e ▁Pu tz ey s , ▁tendo ▁sido ▁descrita ▁no ▁ano ▁de [MASK] . [SEP] ▁Trata - se ▁de ▁uma ▁sub es pe cie ▁presente ▁no ▁ter rito rio ▁por ▁admite [MASK] . [SEP]\n",
            "I1209 17:49:30.046705 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁D ys chi rio des ▁cha ly ba eus ▁cha ly ba eus [MASK] ▁uma ▁sub es pe cie ▁de ▁insetos [MASK] [MASK] [MASK] [MASK] ▁pertencente ▁a ▁familia ▁Carabidae . [MASK] ▁autoridade ▁ cientific a [MASK] ▁sub es pe cie ▁e ▁Pu tz ey s , ▁tendo ▁sido ▁descrita ▁no ▁ano ▁de [MASK] . [SEP] ▁Trata - se ▁de ▁uma ▁sub es pe cie ▁presente ▁no ▁ter rito rio ▁por ▁admite [MASK] . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 183 10683 1069 1561 1100 4826 1070 454 10285 4826 1070 454 10285 4 18 651 101 505 6686 6 911 4 4 4 4 395 8 25717 5978 7 4 521 19 20102 49 4 651 101 505 6686 9 2441 1593 2867 10 5 169 131 665 22 76 6 4 7 3 536 16 34 6 18 651 101 505 6686 334 22 137 5353 1561 26 13657 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.046821 140591368152960 create_pretraining_data.py:197] input_ids: 2 183 10683 1069 1561 1100 4826 1070 454 10285 4826 1070 454 10285 4 18 651 101 505 6686 6 911 4 4 4 4 395 8 25717 5978 7 4 521 19 20102 49 4 651 101 505 6686 9 2441 1593 2867 10 5 169 131 665 22 76 6 4 7 3 536 16 34 6 18 651 101 505 6686 334 22 137 5353 1561 26 13657 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.046919 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.047009 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.047100 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 0 0 0 0 1 0 0 0 1 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 14 22 23 24 25 31 36 53 70 71 72 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.047165 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 14 22 23 24 25 31 36 53 70 71 72 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 9 8829 3128 5385 10 28 13 16073 26 835 7657 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.047229 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 9 8829 3128 5385 10 28 13 16073 26 835 7657 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:49:30.047306 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:49:30.047373 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.047822 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Ele ▁in cumb e ▁Gor hon ▁mitos ▁freira ▁conta ▁da ▁menina ▁e ▁confia ▁a ▁ela [MASK] [MASK] ▁encanta da ▁para ▁o ▁reino ▁sub a qua tico [MASK] [SEP] ▁que ▁se [MASK] [MASK] ▁a ▁terra ▁e ▁com ▁cada ▁nova [MASK] ▁da ▁natureza . ▁Caminha ndo ▁pela ▁costa , ▁Ye ni sey ▁a vista ▁Ang ara , ▁os ▁dois ▁se ▁conhecem ▁e ▁se ▁apaixona m . ▁Ao ▁cair ▁da ▁tarde , ▁Gor hon ▁conduz ▁Ang ara ▁de ▁volta ▁ao ▁seu ▁reino , ▁mas [MASK] ▁menina ▁deixa ▁sua ▁e char pe ▁te cida ▁com ▁a ▁espuma ▁das ▁ondas ▁do ▁lago ▁como ▁presente ▁de ▁despedida [MASK] [MASK] [MASK] [MASK] ▁No [MASK] , ▁a ▁beleza [MASK] [ [MASK] [MASK] ▁de ▁Ang ara ▁tambem ▁atraiu ▁a ▁a ten ca o ▁de ▁um [SEP]\n",
            "I1209 17:49:30.047952 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁Ele ▁in cumb e ▁Gor hon ▁mitos ▁freira ▁conta ▁da ▁menina ▁e ▁confia ▁a ▁ela [MASK] [MASK] ▁encanta da ▁para ▁o ▁reino ▁sub a qua tico [MASK] [SEP] ▁que ▁se [MASK] [MASK] ▁a ▁terra ▁e ▁com ▁cada ▁nova [MASK] ▁da ▁natureza . ▁Caminha ndo ▁pela ▁costa , ▁Ye ni sey ▁a vista ▁Ang ara , ▁os ▁dois ▁se ▁conhecem ▁e ▁se ▁apaixona m . ▁Ao ▁cair ▁da ▁tarde , ▁Gor hon ▁conduz ▁Ang ara ▁de ▁volta ▁ao ▁seu ▁reino , ▁mas [MASK] ▁menina ▁deixa ▁sua ▁e char pe ▁te cida ▁com ▁a ▁espuma ▁das ▁ondas ▁do ▁lago ▁como ▁presente ▁de ▁despedida [MASK] [MASK] [MASK] [MASK] ▁No [MASK] , ▁a ▁beleza [MASK] [ [MASK] [MASK] ▁de ▁Ang ara ▁tambem ▁atraiu ▁a ▁a ten ca o ▁de ▁um [SEP]\n",
            "INFO:tensorflow:input_ids: 2 163 188 14924 70 5394 11471 17784 17668 414 13 5613 9 10708 8 157 4 4 16376 62 24 11 2225 651 49 1919 3116 4 3 15 35 4 4 8 875 9 21 209 314 4 13 1185 7 21537 65 54 2116 5 5740 402 7454 8 8598 9531 2506 5 32 97 35 14830 9 35 4716 48 7 489 6060 13 361 5 5394 11471 9347 9531 2506 6 386 37 44 2225 5 68 4 5613 2581 38 9 9049 505 2154 3380 21 8 21421 53 4721 12 4296 31 334 6 12660 4 4 4 4 67 4 5 8 4070 4 13172 4 4 6 9531 2506 27557 12270 8 8 1907 228 52 6 20 3\n",
            "I1209 17:49:30.048068 140591368152960 create_pretraining_data.py:197] input_ids: 2 163 188 14924 70 5394 11471 17784 17668 414 13 5613 9 10708 8 157 4 4 16376 62 24 11 2225 651 49 1919 3116 4 3 15 35 4 4 8 875 9 21 209 314 4 13 1185 7 21537 65 54 2116 5 5740 402 7454 8 8598 9531 2506 5 32 97 35 14830 9 35 4716 48 7 489 6060 13 361 5 5394 11471 9347 9531 2506 6 386 37 44 2225 5 68 4 5613 2581 38 9 9049 505 2154 3380 21 8 21421 53 4721 12 4296 31 334 6 12660 4 4 4 4 67 4 5 8 4070 4 13172 4 4 6 9531 2506 27557 12270 8 8 1907 228 52 6 20 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.048178 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.048272 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1\n",
            "I1209 17:49:30.048380 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 7 8 16 17 27 31 32 39 82 91 102 103 104 105 107 111 112 113 114 0\n",
            "I1209 17:49:30.048446 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 7 8 16 17 27 31 32 39 82 91 102 103 104 105 107 111 112 113 114 0\n",
            "INFO:tensorflow:masked_lm_ids: 6 2590 8 3911 7 16376 21 2827 8 21 8 5740 402 7454 363 188 533 1650 1702 0\n",
            "I1209 17:49:30.048508 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 6 2590 8 3911 7 16376 21 2827 8 21 8 5740 402 7454 363 188 533 1650 1702 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.048573 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:49:30.048627 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.049094 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Lin nell ▁forneceu ▁a ▁voz ▁profeta ▁trocou ▁o ▁personagem ▁\" Out ro ▁Pai \" ▁do ▁filme ▁\" Cor a line \", ▁em ▁2009 , ▁para ▁o ▁qual ▁The y ▁M ight ▁Be ▁Giant s ▁escreveu [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁determinismo ▁que ▁foi [MASK] ▁na [MASK] ▁sonora . [SEP] ▁e ▁membros ▁da ▁World [MASK] [MASK] [MASK] [MASK] [MASK] ▁Alliance ▁( W HP A ), ▁que ▁combina ▁as ▁for cas ▁das ▁associa co es ▁profissionais ▁internacionais ▁de ▁medi cos ▁( A MM ), ▁enfermeiro s ▁( Conselho ▁Internacional ▁de ▁En fer m eiros ), ▁far ma ceu ticos ▁( Fe der aca o ▁Internacional [MASK] ▁Far ma ceu ticos ), ▁medi cos ▁de ntista s ▁( Fe der aca o ▁Internacional ▁de ▁De ntista s ) [SEP]\n",
            "I1209 17:49:30.049222 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁Lin nell ▁forneceu ▁a ▁voz ▁profeta ▁trocou ▁o ▁personagem ▁\" Out ro ▁Pai \" ▁do ▁filme ▁\" Cor a line \", ▁em ▁2009 , ▁para ▁o ▁qual ▁The y ▁M ight ▁Be ▁Giant s ▁escreveu [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁determinismo ▁que ▁foi [MASK] ▁na [MASK] ▁sonora . [SEP] ▁e ▁membros ▁da ▁World [MASK] [MASK] [MASK] [MASK] [MASK] ▁Alliance ▁( W HP A ), ▁que ▁combina ▁as ▁for cas ▁das ▁associa co es ▁profissionais ▁internacionais ▁de ▁medi cos ▁( A MM ), ▁enfermeiro s ▁( Conselho ▁Internacional ▁de ▁En fer m eiros ), ▁far ma ceu ticos ▁( Fe der aca o ▁Internacional [MASK] ▁Far ma ceu ticos ), ▁medi cos ▁de ntista s ▁( Fe der aca o ▁Internacional ▁de ▁De ntista s ) [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5092 15120 13636 8 1798 8783 14913 11 541 17 13375 364 4840 27 12 159 17 5564 49 2299 47 14 1759 5 24 11 170 331 156 476 4505 904 22000 10 981 4 4 4 4 4 4 27668 15 30 4 25 4 2071 7 3 9 553 13 1626 4 4 4 4 4 22065 29 721 15219 89 59 15 7919 40 728 1607 53 9019 238 101 2092 2012 6 8902 1584 29 89 12288 59 25103 10 29 23054 898 6 1476 2034 48 4226 59 6701 295 7917 9298 29 5719 690 4306 52 898 4 3679 295 7917 9298 59 8902 1584 6 11305 10 29 5719 690 4306 52 898 6 167 11305 10 46 3\n",
            "I1209 17:49:30.049359 140591368152960 create_pretraining_data.py:197] input_ids: 2 5092 15120 13636 8 1798 8783 14913 11 541 17 13375 364 4840 27 12 159 17 5564 49 2299 47 14 1759 5 24 11 170 331 156 476 4505 904 22000 10 981 4 4 4 4 4 4 27668 15 30 4 25 4 2071 7 3 9 553 13 1626 4 4 4 4 4 22065 29 721 15219 89 59 15 7919 40 728 1607 53 9019 238 101 2092 2012 6 8902 1584 29 89 12288 59 25103 10 29 23054 898 6 1476 2034 48 4226 59 6701 295 7917 9298 29 5719 690 4306 52 898 4 3679 295 7917 9298 59 8902 1584 6 11305 10 29 5719 690 4306 52 898 6 167 11305 10 46 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.049459 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.049549 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1\n",
            "I1209 17:49:30.049639 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 7 13 36 37 38 39 40 41 42 45 46 47 55 56 57 58 59 105 0\n",
            "I1209 17:49:30.049710 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 6 7 13 36 37 38 39 40 41 42 45 46 47 55 56 57 58 59 105 0\n",
            "INFO:tensorflow:masked_lm_ids: 7335 24 4840 17 162 2612 1106 2612 9873 47 20158 25 2009 27282 9866 101 3114 10 6 0\n",
            "I1209 17:49:30.049775 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 7335 24 4840 17 162 2612 1106 2612 9873 47 20158 25 2009 27282 9866 101 3114 10 6 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.049839 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.049894 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.050373 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁O ▁canal ▁tem ▁cerca ▁de ▁ 320 ▁km ▁de ▁comprimento ▁e ▁largura ▁media ▁de ▁145 ▁km [MASK] [MASK] ▁sua [MASK] [MASK] [MASK] ▁conhecida ▁e ▁35 2 ▁m . [SEP] ▁Fox e ▁() ▁e ▁um ▁canal ▁mar i timo ▁localizado ▁na [MASK] ▁central ▁do ▁Arqui pela go [MASK] [MASK] [MASK] [MASK] , ▁no ▁extremo ▁setentrional ▁da ▁ba ia ▁de ▁Hudson , ▁sendo ▁o ▁principal ▁acesso ▁a ▁esta ▁ba ia ▁e ▁a ▁bacia ▁de ▁Fox e . [MASK] [MASK] , ▁pertence ▁ao ▁Ter rito rio ▁Auto no mo ▁de ▁Nu na v ut , ▁Canada . ▁O ▁canal ▁de ▁Fox e ▁liga ▁a ▁bacia ▁de ▁viajante [MASK] [MASK] [MASK] ▁norte ), ▁com ▁a ▁ba ia ▁de ▁Hudson ▁( a [MASK] ) ▁e ▁o [MASK] [MASK] ▁Hudson ▁( a [SEP]\n",
            "I1209 17:49:30.050509 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁O ▁canal ▁tem ▁cerca ▁de ▁ 320 ▁km ▁de ▁comprimento ▁e ▁largura ▁media ▁de ▁145 ▁km [MASK] [MASK] ▁sua [MASK] [MASK] [MASK] ▁conhecida ▁e ▁35 2 ▁m . [SEP] ▁Fox e ▁() ▁e ▁um ▁canal ▁mar i timo ▁localizado ▁na [MASK] ▁central ▁do ▁Arqui pela go [MASK] [MASK] [MASK] [MASK] , ▁no ▁extremo ▁setentrional ▁da ▁ba ia ▁de ▁Hudson , ▁sendo ▁o ▁principal ▁acesso ▁a ▁esta ▁ba ia ▁e ▁a ▁bacia ▁de ▁Fox e . [MASK] [MASK] , ▁pertence ▁ao ▁Ter rito rio ▁Auto no mo ▁de ▁Nu na v ut , ▁Canada . ▁O ▁canal ▁de ▁Fox e ▁liga ▁a ▁bacia ▁de ▁viajante [MASK] [MASK] [MASK] ▁norte ), ▁com ▁a ▁ba ia ▁de ▁Hudson ▁( a [MASK] ) ▁e ▁o [MASK] [MASK] ▁Hudson ▁( a [SEP]\n",
            "INFO:tensorflow:input_ids: 2 33 947 93 232 6 19 17045 90 6 1604 9 5314 6963 6 17362 90 4 4 38 4 4 4 518 9 2714 184 813 7 3 4244 70 2006 9 20 947 803 102 11940 883 25 4 1027 12 14442 13894 436 4 4 4 4 5 22 5534 20075 13 1542 128 6 16479 5 92 11 307 892 8 233 1542 128 9 8 6455 6 4244 70 7 4 4 5 2689 37 2723 5353 1561 5096 171 320 6 3742 148 485 1324 5 21177 7 33 947 6 4244 70 2118 8 6455 6 14297 4 4 4 292 59 21 8 1542 128 6 16479 29 49 4 46 9 11 4 4 16479 29 49 3\n",
            "I1209 17:49:30.147183 140591368152960 create_pretraining_data.py:197] input_ids: 2 33 947 93 232 6 19 17045 90 6 1604 9 5314 6963 6 17362 90 4 4 38 4 4 4 518 9 2714 184 813 7 3 4244 70 2006 9 20 947 803 102 11940 883 25 4 1027 12 14442 13894 436 4 4 4 4 5 22 5534 20075 13 1542 128 6 16479 5 92 11 307 892 8 233 1542 128 9 8 6455 6 4244 70 7 4 4 5 2689 37 2723 5353 1561 5096 171 320 6 3742 148 485 1324 5 21177 7 33 947 6 4244 70 2118 8 6455 6 14297 4 4 4 292 59 21 8 1542 128 6 16479 29 49 4 46 9 11 4 4 16479 29 49 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.147365 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.147509 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
            "I1209 17:49:30.147611 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 17 18 20 21 22 41 47 48 49 50 76 77 104 105 106 107 118 122 123 0\n",
            "I1209 17:49:30.147681 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 17 18 20 21 22 41 47 48 49 50 76 77 104 105 106 107 118 122 123 0\n",
            "INFO:tensorflow:masked_lm_ids: 7 28 4553 19225 295 96 906 3116 22900 52 20061 122 4244 70 29 49 480 9416 6 0\n",
            "I1209 17:49:30.147747 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 7 28 4553 19225 295 96 906 3116 22900 52 20061 122 4244 70 29 49 480 9416 6 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.147826 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.147888 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.148566 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Sim ▁e ▁o ▁segundo ▁album ▁de ▁e studio ▁da ▁cantora ▁e ▁compositora ▁brasileira ▁Sandy , ▁ lan cado ▁em ▁11 [MASK] ▁junho [MASK] ▁Provisório [MASK] ▁instrução [MASK] ▁da ▁gravadora ▁Universal ▁Music . [SEP] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁digital mente ▁em ▁2012 , ▁e ▁outras ▁cinco ▁faixas ▁in ed itas . ▁Como ▁compositora , ▁Sandy ▁assina ▁nove [MASK] ▁dez ▁can co es ▁do ▁album , ▁produzido ▁por ▁Lucas ▁Lima ▁e ▁Jason ▁Tar ver . [MASK] [MASK] [MASK] [MASK] ▁escolhidos ▁para ▁divulga ca o ▁do ▁album ▁foram ▁\" A que la ▁dos ▁30 \", ▁\" Escolh o ▁Vo ce \" [MASK] ▁\" Mor ada \". ▁O ▁disco ▁atingiu ▁a ▁no na ▁pos ica o ▁na ▁parada ▁de ▁al bun s ▁da ▁Pro - Music a ▁Brasil [SEP]\n",
            "I1209 17:49:30.148742 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁Sim ▁e ▁o ▁segundo ▁album ▁de ▁e studio ▁da ▁cantora ▁e ▁compositora ▁brasileira ▁Sandy , ▁ lan cado ▁em ▁11 [MASK] ▁junho [MASK] ▁Provisório [MASK] ▁instrução [MASK] ▁da ▁gravadora ▁Universal ▁Music . [SEP] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁digital mente ▁em ▁2012 , ▁e ▁outras ▁cinco ▁faixas ▁in ed itas . ▁Como ▁compositora , ▁Sandy ▁assina ▁nove [MASK] ▁dez ▁can co es ▁do ▁album , ▁produzido ▁por ▁Lucas ▁Lima ▁e ▁Jason ▁Tar ver . [MASK] [MASK] [MASK] [MASK] ▁escolhidos ▁para ▁divulga ca o ▁do ▁album ▁foram ▁\" A que la ▁dos ▁30 \", ▁\" Escolh o ▁Vo ce \" [MASK] ▁\" Mor ada \". ▁O ▁disco ▁atingiu ▁a ▁no na ▁pos ica o ▁na ▁parada ▁de ▁al bun s ▁da ▁Pro - Music a ▁Brasil [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4852 9 11 186 22876 6 9 27356 13 770 9 10042 517 18435 5 19 1818 7086 14 400 4 418 4 20262 4 7969 4 13 1619 3689 1346 7 3 4 4 4 4 4 4 2258 122 14 1206 5 9 205 468 1709 188 779 5339 7 447 10042 5 18435 8180 1810 4 1240 3530 238 101 12 22876 5 1318 26 4973 2019 9 5537 5356 581 7 4 4 4 4 10573 24 13911 228 52 12 22876 75 17 89 222 135 36 506 47 17 28427 52 3386 342 27 4 17 6720 497 63 33 561 3094 8 22 148 14191 1840 52 25 4404 6 980 13221 10 13 932 16 10941 49 94 3\n",
            "I1209 17:49:30.148872 140591368152960 create_pretraining_data.py:197] input_ids: 2 4852 9 11 186 22876 6 9 27356 13 770 9 10042 517 18435 5 19 1818 7086 14 400 4 418 4 20262 4 7969 4 13 1619 3689 1346 7 3 4 4 4 4 4 4 2258 122 14 1206 5 9 205 468 1709 188 779 5339 7 447 10042 5 18435 8180 1810 4 1240 3530 238 101 12 22876 5 1318 26 4973 2019 9 5537 5356 581 7 4 4 4 4 10573 24 13911 228 52 12 22876 75 17 89 222 135 36 506 47 17 28427 52 3386 342 27 4 17 6720 497 63 33 561 3094 8 22 148 14191 1840 52 25 4404 6 980 13221 10 13 932 16 10941 49 94 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.148973 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.149066 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1\n",
            "I1209 17:49:30.149156 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 0 0 1 1 1 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 20 21 23 24 25 26 27 34 35 36 37 38 39 59 76 77 78 79 101 0\n",
            "I1209 17:49:30.149221 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 20 21 23 24 25 26 27 34 35 36 37 38 39 59 76 77 78 79 101 0\n",
            "INFO:tensorflow:masked_lm_ids: 400 6 6 996 8 797 2704 8883 10 47 19 1818 7086 53 87 17 8648 27 9 0\n",
            "I1209 17:49:30.149284 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 400 6 6 996 8 797 2704 8883 10 47 19 1818 7086 53 87 17 8648 27 9 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.149365 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:49:30.149424 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.149918 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁chamado ▁de ▁Gy ps y ▁Horse , ▁Coul o red ▁Co b , ▁e ▁Cavalo ▁Ci ga no ▁no ▁Brasil , ▁e ▁uma ▁ra ca ▁de ▁cavalos ▁recente ▁que ▁passou ▁a ▁ser ▁registrada ▁e ▁reconhecida ▁oficialmente ▁a ▁partir ▁de ▁1996. ▁Esta ▁ra ca ▁foi ▁desenvolvida [MASK] ▁ótimo [MASK] ▁do ▁Reino ▁Unido . ▁Possui ▁patas ▁pe lu das ▁e ▁por ▁este ▁motivo ▁e ▁bastante ▁confundido ▁com ▁o [MASK] [MASK] [MASK] [MASK] . ▁A ▁cor ▁mais ▁comum [MASK] ▁o ▁malha do ▁de [MASK] ▁e ▁branco . ▁Possui ▁mu s culos [MASK] ▁e [MASK] 0,000 [MASK] [MASK] [MASK] ▁para [MASK] ▁de ▁tra ca o [MASK] ▁consagrou [SEP] ▁O ▁projeto ▁para ▁oficial iza - la ▁ainda ▁esta ▁em ▁desenvolvimento , ▁por ▁isso ▁a ▁ra ca ▁ainda ▁e ▁pouco ▁conhecida . [SEP]\n",
            "I1209 17:49:30.150047 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁chamado ▁de ▁Gy ps y ▁Horse , ▁Coul o red ▁Co b , ▁e ▁Cavalo ▁Ci ga no ▁no ▁Brasil , ▁e ▁uma ▁ra ca ▁de ▁cavalos ▁recente ▁que ▁passou ▁a ▁ser ▁registrada ▁e ▁reconhecida ▁oficialmente ▁a ▁partir ▁de ▁1996. ▁Esta ▁ra ca ▁foi ▁desenvolvida [MASK] ▁ótimo [MASK] ▁do ▁Reino ▁Unido . ▁Possui ▁patas ▁pe lu das ▁e ▁por ▁este ▁motivo ▁e ▁bastante ▁confundido ▁com ▁o [MASK] [MASK] [MASK] [MASK] . ▁A ▁cor ▁mais ▁comum [MASK] ▁o ▁malha do ▁de [MASK] ▁e ▁branco . ▁Possui ▁mu s culos [MASK] ▁e [MASK] 0,000 [MASK] [MASK] [MASK] ▁para [MASK] ▁de ▁tra ca o [MASK] ▁consagrou [SEP] ▁O ▁projeto ▁para ▁oficial iza - la ▁ainda ▁esta ▁em ▁desenvolvimento , ▁por ▁isso ▁a ▁ra ca ▁ainda ▁e ▁pouco ▁conhecida . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 370 6 14691 4060 156 20733 5 22039 52 6358 682 213 5 9 21356 1726 318 171 22 94 5 9 18 1901 228 6 7815 3255 15 310 8 55 8244 9 5167 1732 8 192 6 6628 412 1901 228 30 4618 4 11600 4 12 733 1213 7 2212 16870 2363 1712 190 9 26 211 2406 9 856 12974 21 11 4 4 4 4 7 28 736 39 675 4 11 12454 61 6 4 9 1816 7 2212 2750 10 10822 4 9 4 15353 4 4 4 24 4 6 2383 228 52 4 16397 3 33 451 24 456 2710 16 135 108 233 14 493 5 26 272 8 1901 228 108 9 470 518 7 3\n",
            "I1209 17:49:30.150171 140591368152960 create_pretraining_data.py:197] input_ids: 2 370 6 14691 4060 156 20733 5 22039 52 6358 682 213 5 9 21356 1726 318 171 22 94 5 9 18 1901 228 6 7815 3255 15 310 8 55 8244 9 5167 1732 8 192 6 6628 412 1901 228 30 4618 4 11600 4 12 733 1213 7 2212 16870 2363 1712 190 9 26 211 2406 9 856 12974 21 11 4 4 4 4 7 28 736 39 675 4 11 12454 61 6 4 9 1816 7 2212 2750 10 10822 4 9 4 15353 4 4 4 24 4 6 2383 228 52 4 16397 3 33 451 24 456 2710 16 135 108 233 14 493 5 26 272 8 1901 228 108 9 470 518 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.150270 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.150401 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            "I1209 17:49:30.150503 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 46 47 48 49 67 68 69 70 76 81 89 91 92 93 94 95 97 102 103 0\n",
            "I1209 17:49:30.150571 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 46 47 48 49 67 68 69 70 76 81 89 91 92 93 94 95 97 102 103 0\n",
            "INFO:tensorflow:masked_lm_ids: 203 29958 7822 12 21356 8997 191 52 9 3038 9949 8 17581 228 52 8301 7815 7 179 0\n",
            "I1209 17:49:30.150634 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 203 29958 7822 12 21356 8997 191 52 9 3038 9949 8 17581 228 52 8301 7815 7 179 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.150699 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:49:30.150757 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.151208 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] , ▁introduziu ▁o ▁projecto ▁da [MASK] ▁de ▁Ar gan il , ▁que ▁aproveitar ia ▁o ▁tro co ▁ja ▁constr u ido ▁entre [MASK] ▁e ▁Lou sa , ▁e ▁que ▁deveria ▁ser ▁prolongado ▁a te ▁Santa ▁Com ba ▁Da o ▁por ▁Ar gan il ; [MASK] ▁Album [MASK] [MASK] [MASK] [MASK] ▁a ▁Linha ▁de [MASK] [MASK] [MASK] [MASK] ▁a te ▁Viseu ▁por ▁Man gua [SEP] ▁sede ▁da ▁Associa ca o ▁Comercial ▁de ▁Industrial ▁de ▁Viseu , ▁para ▁estudar ▁o ▁plano ▁ferrovia rio ▁em ▁prepara ca o , ▁tendo - se ▁chegado ▁a [MASK] ▁Amália [MASK] ▁deviam ▁ser ▁as ▁linhas ▁prior ita rias ▁a ▁construir ▁na ▁re gia o , ▁sendo ▁uma ▁delas ▁de ▁Viseu ▁a te ▁a [MASK] [MASK] , ▁por ▁Man gua l de , ▁Gouveia [SEP]\n",
            "I1209 17:49:30.151351 140591368152960 create_pretraining_data.py:187] tokens: [CLS] , ▁introduziu ▁o ▁projecto ▁da [MASK] ▁de ▁Ar gan il , ▁que ▁aproveitar ia ▁o ▁tro co ▁ja ▁constr u ido ▁entre [MASK] ▁e ▁Lou sa , ▁e ▁que ▁deveria ▁ser ▁prolongado ▁a te ▁Santa ▁Com ba ▁Da o ▁por ▁Ar gan il ; [MASK] ▁Album [MASK] [MASK] [MASK] [MASK] ▁a ▁Linha ▁de [MASK] [MASK] [MASK] [MASK] ▁a te ▁Viseu ▁por ▁Man gua [SEP] ▁sede ▁da ▁Associa ca o ▁Comercial ▁de ▁Industrial ▁de ▁Viseu , ▁para ▁estudar ▁o ▁plano ▁ferrovia rio ▁em ▁prepara ca o , ▁tendo - se ▁chegado ▁a [MASK] ▁Amália [MASK] ▁deviam ▁ser ▁as ▁linhas ▁prior ita rias ▁a ▁construir ▁na ▁re gia o , ▁sendo ▁uma ▁delas ▁de ▁Viseu ▁a te ▁a [MASK] [MASK] , ▁por ▁Man gua l de , ▁Gouveia [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5 7283 11 5224 13 4 6 906 2209 1006 5 15 13099 128 11 6511 238 3579 15874 64 1787 60 4 9 3101 372 5 9 15 2044 55 17961 8 204 608 173 454 955 52 26 906 2209 1006 72 4 16243 4 4 4 4 8 2402 6 4 4 4 4 8 204 11379 26 764 2175 3 567 13 15442 228 52 9853 6 6484 6 11379 5 24 2594 11 1226 9102 1561 14 8183 228 52 5 169 16 34 9391 8 4 20569 4 18437 55 40 1652 12170 808 6993 8 2555 25 172 2094 52 5 92 18 2334 6 11379 8 204 8 4 4 5 26 764 2175 106 103 5 18121 3\n",
            "I1209 17:49:30.151476 140591368152960 create_pretraining_data.py:197] input_ids: 2 5 7283 11 5224 13 4 6 906 2209 1006 5 15 13099 128 11 6511 238 3579 15874 64 1787 60 4 9 3101 372 5 9 15 2044 55 17961 8 204 608 173 454 955 52 26 906 2209 1006 72 4 16243 4 4 4 4 8 2402 6 4 4 4 4 8 204 11379 26 764 2175 3 567 13 15442 228 52 9853 6 6484 6 11379 5 24 2594 11 1226 9102 1561 14 8183 228 52 5 169 16 34 9391 8 4 20569 4 18437 55 40 1652 12170 808 6993 8 2555 25 172 2094 52 5 92 18 2334 6 11379 8 204 8 4 4 5 26 764 2175 106 103 5 18121 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.151576 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.151668 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1\n",
            "I1209 17:49:30.151757 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 7 23 24 45 46 47 48 49 50 54 55 56 57 92 93 94 117 118 0\n",
            "I1209 17:49:30.151822 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 6 7 23 24 45 46 47 48 49 50 54 55 56 57 92 93 94 117 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 2402 6 3541 9 14 16879 7741 5 2655 128 18121 5 15 2032 316 79 358 3101 372 0\n",
            "I1209 17:49:30.151885 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 2402 6 3541 9 14 16879 7741 5 2655 128 18121 5 15 2032 316 79 358 3101 372 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.151953 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.152009 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.152525 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁da ▁familia , ▁por em , ▁problemas ▁de ▁sau de ▁o [MASK] [MASK] [MASK] ▁ir ▁morar ▁com ▁alguns ▁familiares ▁em ▁Dun de e , ▁na ▁Esco cia . ▁Ali [MASK] [MASK] ▁vida [MASK] ▁trajeto vel , ▁e [MASK] ▁tornou ▁um ▁leitor ▁in can sa vel [MASK] ▁logo ▁contribuindo ▁com ▁os ▁peri od icos ▁e [MASK] ▁provi ncia nas , ▁escrevendo ▁artigos ▁po e [SEP] ▁o ▁pai ▁dele ▁morreu ▁em ▁1811 , ▁eles ▁se ▁mudaram ▁para ▁\" I s l ington \", ▁onde ▁Thomas ▁Hood ▁teve ▁um [MASK] ▁decresce [MASK] ▁apreciado r ▁de ▁seus [MASK] [MASK] ▁fazia - o [MASK] ▁\" que ▁seria ▁imp o ssi vel ▁al gue m ▁na o ▁tomar ▁gosto ▁pelo ▁aprendizado , ▁quando ▁ele ▁se ▁mostrava ▁ta o ▁interessado ▁em ▁ensinar \" [SEP]\n",
            "I1209 17:49:30.152696 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁da ▁familia , ▁por em , ▁problemas ▁de ▁sau de ▁o [MASK] [MASK] [MASK] ▁ir ▁morar ▁com ▁alguns ▁familiares ▁em ▁Dun de e , ▁na ▁Esco cia . ▁Ali [MASK] [MASK] ▁vida [MASK] ▁trajeto vel , ▁e [MASK] ▁tornou ▁um ▁leitor ▁in can sa vel [MASK] ▁logo ▁contribuindo ▁com ▁os ▁peri od icos ▁e [MASK] ▁provi ncia nas , ▁escrevendo ▁artigos ▁po e [SEP] ▁o ▁pai ▁dele ▁morreu ▁em ▁1811 , ▁eles ▁se ▁mudaram ▁para ▁\" I s l ington \", ▁onde ▁Thomas ▁Hood ▁teve ▁um [MASK] ▁decresce [MASK] ▁apreciado r ▁de ▁seus [MASK] [MASK] ▁fazia - o [MASK] ▁\" que ▁seria ▁imp o ssi vel ▁al gue m ▁na o ▁tomar ▁gosto ▁pelo ▁aprendizado , ▁quando ▁ele ▁se ▁mostrava ▁ta o ▁interessado ▁em ▁ensinar \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 13 25717 5 26 136 5 683 6 10464 103 11 4 4 4 1311 6298 21 215 4653 14 10658 103 70 5 25 10401 1028 7 3018 4 4 195 4 14860 1702 5 9 4 264 20 8868 188 2816 372 1702 4 637 11434 21 32 9536 3461 8143 9 4 9629 4428 2030 5 6775 3106 2360 70 3 11 368 1285 1087 14 19091 5 251 35 7979 24 17 474 10 106 5376 47 80 2498 23060 198 20 4 19133 4 14450 41 6 78 4 4 2235 16 52 4 17 222 375 3923 52 3397 1702 980 1389 48 25 52 2590 5292 57 13258 5 91 69 35 10744 2268 52 13057 14 9940 27 3\n",
            "I1209 17:49:30.249250 140591368152960 create_pretraining_data.py:197] input_ids: 2 13 25717 5 26 136 5 683 6 10464 103 11 4 4 4 1311 6298 21 215 4653 14 10658 103 70 5 25 10401 1028 7 3018 4 4 195 4 14860 1702 5 9 4 264 20 8868 188 2816 372 1702 4 637 11434 21 32 9536 3461 8143 9 4 9629 4428 2030 5 6775 3106 2360 70 3 11 368 1285 1087 14 19091 5 251 35 7979 24 17 474 10 106 5376 47 80 2498 23060 198 20 4 19133 4 14450 41 6 78 4 4 2235 16 52 4 17 222 375 3923 52 3397 1702 980 1389 48 25 52 2590 5292 57 13258 5 91 69 35 10744 2268 52 13057 14 9940 27 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.249450 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.249574 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            "I1209 17:49:30.249670 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 12 13 14 15 30 31 32 33 34 35 38 46 55 87 88 89 94 95 99 0\n",
            "I1209 17:49:30.249740 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 12 13 14 15 30 31 32 33 34 35 38 46 55 87 88 89 94 95 99 0\n",
            "INFO:tensorflow:masked_lm_ids: 8729 125 8 1311 198 18 195 10464 62 1702 35 5 3792 819 15 5 9784 5 6070 0\n",
            "I1209 17:49:30.249812 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 8729 125 8 1311 198 18 195 10464 62 1702 35 5 3792 819 15 5 9784 5 6070 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.249885 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.249945 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.250609 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Ku k le ▁e ▁uma ▁comuna ▁checa ▁localizada Thi [MASK] [MASK] [MASK] ▁de [MASK] [MASK] ▁distrito [MASK] gi [MASK] . [SEP] ▁ano ▁recebeu ▁o ▁cargo ▁de ▁Ji sha - bu gy o ▁( Com issa rio ▁dos ▁Sant u ario s ▁e ▁Templo s ). ▁Em ▁1825 , ▁\" Ta da ku ni \" ▁recebeu [MASK] ▁cargo ▁de ▁Osaka ▁Jo da i ▁( Cast ela o ▁de ▁Osaka [MASK] [MASK] [MASK] ▁No ▁ano ▁seguinte ▁(18 26 ), ▁tornou - se ▁Ky oto ▁Sho shi da i ▁ , ▁representante ▁oficial ▁do ▁shogunato ▁na ▁Corte ▁em ▁Ky oto . ▁Seu ▁titulo ▁na ▁Corte ▁foi ▁mudado ▁de [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] - ka mi \" ▁para ▁\" E chi zen - no - ka mi \" [SEP]\n",
            "I1209 17:49:30.250778 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁Ku k le ▁e ▁uma ▁comuna ▁checa ▁localizada Thi [MASK] [MASK] [MASK] ▁de [MASK] [MASK] ▁distrito [MASK] gi [MASK] . [SEP] ▁ano ▁recebeu ▁o ▁cargo ▁de ▁Ji sha - bu gy o ▁( Com issa rio ▁dos ▁Sant u ario s ▁e ▁Templo s ). ▁Em ▁1825 , ▁\" Ta da ku ni \" ▁recebeu [MASK] ▁cargo ▁de ▁Osaka ▁Jo da i ▁( Cast ela o ▁de ▁Osaka [MASK] [MASK] [MASK] ▁No ▁ano ▁seguinte ▁(18 26 ), ▁tornou - se ▁Ky oto ▁Sho shi da i ▁ , ▁representante ▁oficial ▁do ▁shogunato ▁na ▁Corte ▁em ▁Ky oto . ▁Seu ▁titulo ▁na ▁Corte ▁foi ▁mudado ▁de [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] - ka mi \" ▁para ▁\" E chi zen - no - ka mi \" [SEP]\n",
            "INFO:tensorflow:input_ids: 2 2222 304 199 9 18 98 837 429 24551 4 4 4 6 4 4 433 4 823 4 7 3 76 463 11 643 6 5612 3442 16 1035 6379 52 29 3808 10585 1561 36 7154 64 14936 10 9 7544 10 73 43 13731 5 17 2469 62 1152 402 27 463 4 643 6 14782 2564 62 102 29 18468 2738 52 6 14782 4 4 4 67 76 322 1134 3052 59 264 16 34 6926 7873 4829 1992 62 102 19 5 4339 456 12 29076 25 4797 14 6926 7873 7 464 20370 25 4797 30 9367 6 4 4 4 4 4 4 16 743 836 27 24 17 426 1069 6272 16 171 16 743 836 27 3\n",
            "I1209 17:49:30.250907 140591368152960 create_pretraining_data.py:197] input_ids: 2 2222 304 199 9 18 98 837 429 24551 4 4 4 6 4 4 433 4 823 4 7 3 76 463 11 643 6 5612 3442 16 1035 6379 52 29 3808 10585 1561 36 7154 64 14936 10 9 7544 10 73 43 13731 5 17 2469 62 1152 402 27 463 4 643 6 14782 2564 62 102 29 18468 2738 52 6 14782 4 4 4 67 76 322 1134 3052 59 264 16 34 6926 7873 4829 1992 62 102 19 5 4339 456 12 29076 25 4797 14 6926 7873 7 464 20370 25 4797 30 9367 6 4 4 4 4 4 4 16 743 836 27 24 17 426 1069 6272 16 171 16 743 836 27 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.251007 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:49:30.251101 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
            "I1209 17:49:30.251189 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 0 0 1 1 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 9 10 11 12 14 15 17 18 19 56 69 70 71 106 107 108 109 110 111 0\n",
            "I1209 17:49:30.251254 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 9 10 11 12 14 15 17 18 19 56 69 70 71 106 107 108 109 110 111 0\n",
            "INFO:tensorflow:masked_lm_ids: 25 172 2094 52 5640 5 6 21015 156 11 46 19 7 17 474 2777 836 16 171 0\n",
            "I1209 17:49:30.251329 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 25 172 2094 52 5640 5 6 21015 156 11 46 19 7 17 474 2777 836 16 171 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:49:30.251395 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.251458 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:49:30.251885 140591368152960 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Foi ▁protagonizada ▁por ▁Andrea ▁No li ▁e ▁Luis ▁Miguel ▁Lo m bana ▁com ▁antagoniza ca o ▁de ▁Ross ana ▁Na je ra . [SEP] ▁Se ▁busca ▁un ▁hom bre ▁( tra d . ▁: ▁Procura - Se [MASK] ▁Homem [MASK] ▁e ▁uma ▁telenovela ▁mexicana ▁4 [MASK] [MASK] [MASK] [MASK] ▁por ▁Ge nove va [MASK] Deutsche ▁2007. [SEP]\n",
            "I1209 17:49:30.251992 140591368152960 create_pretraining_data.py:187] tokens: [CLS] ▁Foi ▁protagonizada ▁por ▁Andrea ▁No li ▁e ▁Luis ▁Miguel ▁Lo m bana ▁com ▁antagoniza ca o ▁de ▁Ross ana ▁Na je ra . [SEP] ▁Se ▁busca ▁un ▁hom bre ▁( tra d . ▁: ▁Procura - Se [MASK] ▁Homem [MASK] ▁e ▁uma ▁telenovela ▁mexicana ▁4 [MASK] [MASK] [MASK] [MASK] ▁por ▁Ge nove va [MASK] Deutsche ▁2007. [SEP]\n",
            "INFO:tensorflow:input_ids: 2 142 10968 26 7999 67 423 9 3448 1514 1088 48 12789 21 16911 228 52 6 6546 1351 95 1049 153 7 3 332 1157 6253 15617 2010 29 797 143 7 3932 25826 16 1617 4 3244 4 9 18 1560 4983 178 4 4 4 4 26 2343 17364 84 4 21972 4371 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.252108 140591368152960 create_pretraining_data.py:197] input_ids: 2 142 10968 26 7999 67 423 9 3448 1514 1088 48 12789 21 16911 228 52 6 6546 1351 95 1049 153 7 3 332 1157 6253 15617 2010 29 797 143 7 3932 25826 16 1617 4 3244 4 9 18 1560 4983 178 4 4 4 4 26 2343 17364 84 4 21972 4371 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.252201 140591368152960 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.252305 140591368152960 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.252397 140591368152960 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 38 40 45 46 47 48 49 54 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.252471 140591368152960 create_pretraining_data.py:197] masked_lm_positions: 38 40 45 46 47 48 49 54 55 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 265 46 1498 54 19357 9 1719 23880 14 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:49:30.252538 140591368152960 create_pretraining_data.py:197] masked_lm_ids: 265 46 1498 54 19357 9 1719 23880 14 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:49:30.252601 140591368152960 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:49:30.252657 140591368152960 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:number of instances: 277957\n",
            "I1209 17:50:35.174857 140365583124352 create_pretraining_data.py:638] number of instances: 277957\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I1209 17:50:35.175720 140365583124352 create_pretraining_data.py:641] *** Writing to output files ***\n",
            "INFO:tensorflow:  gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0002.tfrecord\n",
            "I1209 17:50:35.175791 140365583124352 create_pretraining_data.py:643]   gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/pretraining_data_128/shard_0002.tfrecord\n",
            "WARNING:tensorflow:From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1209 17:50:35.176021 140365583124352 module_wrapper.py:139] From ALBERT/create_pretraining_data.py:129: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.177222 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁de ▁todos ▁os ▁seres ▁vivos , ▁na o ▁so ▁o ▁espa co ▁do [MASK] . ▁O [MASK] co ▁geo graf ico ▁foi [MASK] ▁a ▁4,5 ▁bi lho es ▁de ▁anos ▁quando ▁a ▁Terra ▁foi ▁formada . ▁De ▁la ▁para ▁ca ▁houve ▁muda nca s ▁profundas ▁na ▁sua ▁estrutura [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁e [MASK] ▁paisagem ▁geo gra fica . [MASK] [MASK] [MASK] , ▁o xi gen io ▁ficou ▁abundante , ▁devido ▁o ▁papel ▁das ▁algas ▁e ▁plantas ▁superiores . ▁Quando ▁o ▁homem [MASK] ▁na ▁Terra ▁ele [SEP] ▁Para ▁a ▁geografia ▁fi s ica ▁o ▁espa co ▁geo graf ico ▁e ▁o ▁espa co ▁concreto ▁ou ▁fi sico ▁inserido ▁na ▁interface ▁\" lit osfera - hid r osfera - at m osfera \". [SEP]\n",
            "I1209 17:50:35.177473 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁de ▁todos ▁os ▁seres ▁vivos , ▁na o ▁so ▁o ▁espa co ▁do [MASK] . ▁O [MASK] co ▁geo graf ico ▁foi [MASK] ▁a ▁4,5 ▁bi lho es ▁de ▁anos ▁quando ▁a ▁Terra ▁foi ▁formada . ▁De ▁la ▁para ▁ca ▁houve ▁muda nca s ▁profundas ▁na ▁sua ▁estrutura [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁e [MASK] ▁paisagem ▁geo gra fica . [MASK] [MASK] [MASK] , ▁o xi gen io ▁ficou ▁abundante , ▁devido ▁o ▁papel ▁das ▁algas ▁e ▁plantas ▁superiores . ▁Quando ▁o ▁homem [MASK] ▁na ▁Terra ▁ele [SEP] ▁Para ▁a ▁geografia ▁fi s ica ▁o ▁espa co ▁geo graf ico ▁e ▁o ▁espa co ▁concreto ▁ou ▁fi sico ▁inserido ▁na ▁interface ▁\" lit osfera - hid r osfera - at m osfera \". [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6 187 32 3339 6832 5 25 52 2866 11 11879 238 12 4 7 33 4 238 8234 6551 2923 30 4 8 17215 1595 2078 101 6 66 91 8 833 30 1923 7 167 671 24 746 1494 3014 3970 10 11987 25 38 738 4 4 4 4 4 4 4 4 9 4 9081 8234 2080 3557 7 4 4 4 5 11 1510 1658 986 484 13186 5 317 11 479 53 19189 9 1405 4475 7 486 11 712 4 25 833 69 3 244 8 14113 2836 10 1840 11 11879 238 8234 6551 2923 9 11 11879 238 7961 51 2836 14710 9885 25 5162 17 9343 11102 16 13694 41 11102 16 1334 48 11102 63 3\n",
            "I1209 17:50:35.177623 140365583124352 create_pretraining_data.py:197] input_ids: 2 6 187 32 3339 6832 5 25 52 2866 11 11879 238 12 4 7 33 4 238 8234 6551 2923 30 4 8 17215 1595 2078 101 6 66 91 8 833 30 1923 7 167 671 24 746 1494 3014 3970 10 11987 25 38 738 4 4 4 4 4 4 4 4 9 4 9081 8234 2080 3557 7 4 4 4 5 11 1510 1658 986 484 13186 5 317 11 479 53 19189 9 1405 4475 7 486 11 712 4 25 833 69 3 244 8 14113 2836 10 1840 11 11879 238 8234 6551 2923 9 11 11879 238 7961 51 2836 14710 9885 25 5162 17 9343 11102 16 13694 41 11102 16 1334 48 11102 63 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.177724 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.177819 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1\n",
            "I1209 17:50:35.177910 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 0 0 0 1 0 0 0 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 14 17 18 23 49 50 51 52 53 54 55 56 58 59 64 65 66 67 87 0\n",
            "I1209 17:50:35.177976 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 14 17 18 23 49 50 51 52 53 54 55 56 58 59 64 65 66 67 87 0\n",
            "INFO:tensorflow:masked_lm_ids: 712 11879 238 1627 5 21 2718 1840 52 19 10329 1840 25 9081 6611 10 9014 5 2008 0\n",
            "I1209 17:50:35.178040 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 712 11879 238 1627 5 21 2718 1840 52 19 10329 1840 25 9081 6611 10 9014 5 2008 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.178109 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.178166 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.178679 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Em ▁1893 [MASK] [MASK] ▁antrop olo go ▁Arnold ▁Henry ▁Savage ▁Lan dor ▁descreveu ▁os ▁a inus ▁como ▁tendo ▁olhos ▁profundo s ▁e ▁com ▁o ▁formato ▁ti pico [MASK] ▁europeus , ▁com ▁um ▁grande [MASK] ▁saliente ▁arco ▁super cilia r , ▁grandes ▁orelhas , ▁hi r s uto s ▁e ▁propenso s ▁a ▁cal vi cie , ▁nariz ▁levemente ▁a quilino ▁com ▁grandes ▁e ▁larga s ▁na rinas , ▁maca s ▁do ▁rosto [MASK] [MASK] ▁e ▁boca s ▁media s . [SEP] ▁O moto ▁demonstrou [MASK] ▁os ▁a inus [MASK] [MASK] ▁muito ▁mais ▁pro xi mos ▁dos ▁outros [MASK] [MASK] ▁Oriente [MASK] [MASK] ▁mencionados [MASK] ▁mongol s ) ▁do ▁que [MASK] ▁qualquer ▁grupo ▁cau cas iano ▁baseado ▁em ▁impresso es ▁digitais ▁e ▁morfologia ▁ dental . [SEP]\n",
            "I1209 17:50:35.178816 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Em ▁1893 [MASK] [MASK] ▁antrop olo go ▁Arnold ▁Henry ▁Savage ▁Lan dor ▁descreveu ▁os ▁a inus ▁como ▁tendo ▁olhos ▁profundo s ▁e ▁com ▁o ▁formato ▁ti pico [MASK] ▁europeus , ▁com ▁um ▁grande [MASK] ▁saliente ▁arco ▁super cilia r , ▁grandes ▁orelhas , ▁hi r s uto s ▁e ▁propenso s ▁a ▁cal vi cie , ▁nariz ▁levemente ▁a quilino ▁com ▁grandes ▁e ▁larga s ▁na rinas , ▁maca s ▁do ▁rosto [MASK] [MASK] ▁e ▁boca s ▁media s . [SEP] ▁O moto ▁demonstrou [MASK] ▁os ▁a inus [MASK] [MASK] ▁muito ▁mais ▁pro xi mos ▁dos ▁outros [MASK] [MASK] ▁Oriente [MASK] [MASK] ▁mencionados [MASK] ▁mongol s ) ▁do ▁que [MASK] ▁qualquer ▁grupo ▁cau cas iano ▁baseado ▁em ▁impresso es ▁digitais ▁e ▁morfologia ▁ dental . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 43 9008 4 4 14584 6411 436 11806 3717 26186 7114 472 3983 32 8 7724 31 169 2873 6425 10 9 21 11 1526 4908 11366 4 3359 5 21 20 113 4 26306 4216 1423 17495 41 5 387 17828 5 4402 41 10 4323 10 9 25891 10 8 2725 514 6686 5 12688 15612 8 24645 21 387 9 2939 10 25 16588 5 18822 10 12 5203 4 4 9 4745 10 6963 10 7 3 33 6981 8283 4 32 8 7724 4 4 126 39 818 1510 511 36 114 4 4 3032 4 4 16217 4 22644 10 46 12 15 4 401 175 12647 1607 2479 1189 14 8169 101 6139 9 14524 19 18747 7 3 0\n",
            "I1209 17:50:35.179434 140365583124352 create_pretraining_data.py:197] input_ids: 2 43 9008 4 4 14584 6411 436 11806 3717 26186 7114 472 3983 32 8 7724 31 169 2873 6425 10 9 21 11 1526 4908 11366 4 3359 5 21 20 113 4 26306 4216 1423 17495 41 5 387 17828 5 4402 41 10 4323 10 9 25891 10 8 2725 514 6686 5 12688 15612 8 24645 21 387 9 2939 10 25 16588 5 18822 10 12 5203 4 4 9 4745 10 6963 10 7 3 33 6981 8283 4 32 8 7724 4 4 126 39 818 1510 511 36 114 4 4 3032 4 4 16217 4 22644 10 46 12 15 4 401 175 12647 1607 2479 1189 14 8169 101 6139 9 14524 19 18747 7 3 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            "I1209 17:50:35.179551 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            "I1209 17:50:35.179644 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0\n",
            "I1209 17:50:35.179736 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 0\n",
            "INFO:tensorflow:masked_lm_positions: 3 4 28 33 34 72 73 74 85 89 90 91 97 98 99 101 102 104 110 0\n",
            "I1209 17:50:35.179803 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 3 4 28 33 34 72 73 74 85 89 90 91 97 98 99 101 102 104 110 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 11 36 113 9 5203 26306 10 15 1577 52 126 114 714 12 29 16684 31 21 0\n",
            "I1209 17:50:35.179866 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 5 11 36 113 9 5203 26306 10 15 1577 52 126 114 714 12 29 16684 31 21 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.179932 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.179990 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.180478 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁De fini ca o [MASK] ▁di cionar io [MASK] [MASK] : ▁\" s . f . ▁\" pequena ▁copa - co zinha , ▁geralmente ▁em ▁apartamento . [SEP] ▁Normalmente , ▁as ▁pessoas ▁que ▁escolhe m ▁morar ▁em ▁uma ▁qui tine te ▁levam ▁em ▁conta ▁seu ▁baixo ▁pre co ▁e ▁o ▁pouco [MASK] [MASK] ▁ficam ▁na ▁casa , [MASK] [MASK] ▁do ▁pouco ▁trabalho [MASK] [MASK] ▁Online ▁com ▁sua [MASK] [MASK] . ▁E ▁de ▁se ▁esperar ▁que ▁existam ▁mais ▁qui tine tes ▁nos ▁centros [MASK] ▁grandes ▁metro pole s , ▁como ▁Nova ▁Iorque , ▁To quio , [MASK] ▁óptico [MASK] [MASK] ▁Paulo , ▁pelo ▁fato ▁de ▁os ▁apartamento s ▁serem , ▁geralmente , ▁mais ▁caro s ▁nessas ▁localidades . [SEP]\n",
            "I1209 17:50:35.180606 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁De fini ca o [MASK] ▁di cionar io [MASK] [MASK] : ▁\" s . f . ▁\" pequena ▁copa - co zinha , ▁geralmente ▁em ▁apartamento . [SEP] ▁Normalmente , ▁as ▁pessoas ▁que ▁escolhe m ▁morar ▁em ▁uma ▁qui tine te ▁levam ▁em ▁conta ▁seu ▁baixo ▁pre co ▁e ▁o ▁pouco [MASK] [MASK] ▁ficam ▁na ▁casa , [MASK] [MASK] ▁do ▁pouco ▁trabalho [MASK] [MASK] ▁Online ▁com ▁sua [MASK] [MASK] . ▁E ▁de ▁se ▁esperar ▁que ▁existam ▁mais ▁qui tine tes ▁nos ▁centros [MASK] ▁grandes ▁metro pole s , ▁como ▁Nova ▁Iorque , ▁To quio , [MASK] ▁óptico [MASK] [MASK] ▁Paulo , ▁pelo ▁fato ▁de ▁os ▁apartamento s ▁serem , ▁geralmente , ▁mais ▁caro s ▁nessas ▁localidades . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 167 6468 228 52 4 719 15941 986 4 4 42 17 10 7 407 7 17 26918 11844 16 238 12514 5 661 14 5578 7 3 8243 5 40 247 15 9879 48 6298 14 18 4790 11999 204 8008 14 414 44 1277 762 238 9 11 470 4 4 4784 25 346 5 4 4 12 470 253 4 4 17911 21 38 4 4 7 179 6 35 8214 15 18168 39 4790 11999 1164 85 4118 4 387 9710 8849 10 5 31 260 1727 5 1004 16095 5 4 19544 4 4 165 5 57 586 6 32 5578 10 921 5 661 5 39 7278 10 14238 6178 7 3 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.180725 140365583124352 create_pretraining_data.py:197] input_ids: 2 167 6468 228 52 4 719 15941 986 4 4 42 17 10 7 407 7 17 26918 11844 16 238 12514 5 661 14 5578 7 3 8243 5 40 247 15 9879 48 6298 14 18 4790 11999 204 8008 14 414 44 1277 762 238 9 11 470 4 4 4784 25 346 5 4 4 12 470 253 4 4 17911 21 38 4 4 7 179 6 35 8214 15 18168 39 4790 11999 1164 85 4118 4 387 9710 8849 10 5 31 260 1727 5 1004 16095 5 4 19544 4 4 165 5 57 586 6 32 5578 10 921 5 661 5 39 7278 10 14238 6178 7 3 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.180824 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.180916 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.181005 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 0 0 1 1 0 0 1 0 1 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 9 10 52 53 58 59 63 64 65 66 68 69 83 96 97 98 99 0 0\n",
            "I1209 17:50:35.207036 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 5 9 10 52 53 58 59 63 64 65 66 68 69 83 96 97 98 99 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 22 1499 194 152 15 8 9719 15 35 13454 21 11928 19370 6 1445 9 499 52 0 0\n",
            "I1209 17:50:35.207218 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 22 1499 194 152 15 8 9719 15 35 13454 21 11928 19370 6 1445 9 499 52 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "I1209 17:50:35.207334 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.207420 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.207965 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Tra va sso s ▁( Lisboa , ▁– ▁Lisboa , [MASK] ▁tambem ▁conhecido ▁por ▁Ze ▁da ▁Europa ▁por ▁ter ▁sido ▁o ▁primeiro ▁jogador ▁de ▁futebol ▁por [MASK] [MASK] [MASK] [MASK] ▁na ▁se lec ca o ▁da ▁Europa , ▁em ▁1955 , ▁contra ▁a ▁Gra - Bretanha ▁e ▁Irlanda ▁do ▁Norte . ▁Curiosamente ▁nasceu ▁no ▁mesmo ▁local ▁onde ▁se [MASK] ▁vertebral [MASK] cada ▁Nova ▁do ▁antigo ▁esta dio ▁de [SEP] ▁Como ▁jogador ▁de ▁futebol ▁foi ▁35 ▁vezes ▁internacional ▁e ▁representou ▁a ▁C UF ▁( onde ▁foi ▁ne ces s ario ▁autoriza ca o ▁do ▁ministro ▁por ▁ainda [MASK] [MASK] ▁ter ▁idade ▁de ▁jun io r ) ▁e ▁o ▁Sporting ▁Clube ▁de ▁Portugal . ▁Pra tico u ▁ainda ▁atletismo ▁nos ▁anos ▁em ▁que [MASK] [MASK] ▁C UF [MASK] [SEP]\n",
            "I1209 17:50:35.208111 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Tra va sso s ▁( Lisboa , ▁– ▁Lisboa , [MASK] ▁tambem ▁conhecido ▁por ▁Ze ▁da ▁Europa ▁por ▁ter ▁sido ▁o ▁primeiro ▁jogador ▁de ▁futebol ▁por [MASK] [MASK] [MASK] [MASK] ▁na ▁se lec ca o ▁da ▁Europa , ▁em ▁1955 , ▁contra ▁a ▁Gra - Bretanha ▁e ▁Irlanda ▁do ▁Norte . ▁Curiosamente ▁nasceu ▁no ▁mesmo ▁local ▁onde ▁se [MASK] ▁vertebral [MASK] cada ▁Nova ▁do ▁antigo ▁esta dio ▁de [SEP] ▁Como ▁jogador ▁de ▁futebol ▁foi ▁35 ▁vezes ▁internacional ▁e ▁representou ▁a ▁C UF ▁( onde ▁foi ▁ne ces s ario ▁autoriza ca o ▁do ▁ministro ▁por ▁ainda [MASK] [MASK] ▁ter ▁idade ▁de ▁jun io r ) ▁e ▁o ▁Sporting ▁Clube ▁de ▁Portugal . ▁Pra tico u ▁ainda ▁atletismo ▁nos ▁anos ▁em ▁que [MASK] [MASK] ▁C UF [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1631 84 1147 10 29 6760 5 355 658 5 4 27557 255 26 3364 13 549 26 137 131 11 86 700 6 503 26 4 4 4 4 25 35 7412 228 52 13 549 5 14 6959 5 138 8 2932 16 5639 9 5609 12 594 7 16826 909 22 88 388 80 35 4 28938 4 5105 260 12 848 233 3037 6 3 447 700 6 503 30 2714 231 865 9 7523 8 214 8970 29 5980 30 3763 3980 10 14936 17331 228 52 12 2062 26 108 4 4 137 636 6 16824 986 41 46 9 11 5654 826 6 280 7 3643 3116 64 108 13251 85 66 14 15 4 4 214 8970 4 3\n",
            "I1209 17:50:35.208240 140365583124352 create_pretraining_data.py:197] input_ids: 2 1631 84 1147 10 29 6760 5 355 658 5 4 27557 255 26 3364 13 549 26 137 131 11 86 700 6 503 26 4 4 4 4 25 35 7412 228 52 13 549 5 14 6959 5 138 8 2932 16 5639 9 5609 12 594 7 16826 909 22 88 388 80 35 4 28938 4 5105 260 12 848 233 3037 6 3 447 700 6 503 30 2714 231 865 9 7523 8 214 8970 29 5980 30 3763 3980 10 14936 17331 228 52 12 2062 26 108 4 4 137 636 6 16824 986 41 46 9 11 5654 826 6 280 7 3643 3116 64 108 13251 85 66 14 15 4 4 214 8970 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.208358 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.208490 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            "I1209 17:50:35.208580 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 0 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 10 11 26 27 28 29 30 41 58 59 60 61 62 76 97 98 122 123 126 0\n",
            "I1209 17:50:35.208645 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 10 11 26 27 28 29 30 41 58 59 60 61 62 76 97 98 122 123 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 1231 26 835 7657 8 2138 5 35 19293 8 5023 5105 231 25 52 12505 25 7 0\n",
            "I1209 17:50:35.208706 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 5 1231 26 835 7657 8 2138 5 35 19293 8 5023 5105 231 25 52 12505 25 7 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.208771 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.208827 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.209285 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁ zel ador ▁do ▁farol ▁de ▁bo ne ▁ point ▁Red ▁ han , ▁foi ▁rap tada ▁por ▁Jack ▁Ri son ho ▁a pos ▁seu ▁pai [MASK] ▁pensei ▁o ▁capita o ▁\" James ▁Gan t \" ▁( [MASK] [MASK] [MASK] [MASK] ) ▁e ▁ficar ▁devendo ▁dinheiro , ▁ela ▁fica ▁presa ▁na [MASK] ▁do ▁barco ▁Dama ▁da [MASK] te [MASK] ▁Jack ▁Ri son ho . ▁Drag ao ▁do ▁top a zio , ▁ajuda ▁Lie f ▁a ▁destruir ▁a ▁ir ma ▁do [MASK] [MASK] [MASK] ▁na ▁caverna ▁que ▁Lie f , ▁Bar da , ▁Ja s mine ▁e ▁dispostas [MASK] [MASK] ▁para ▁entrar ▁na ▁terra ▁da ▁tribo ▁Plu me . [SEP] ▁Ele ▁e ▁ser vo ▁do ▁Senhor ▁das ▁Som bras ▁e ▁tem ▁alguns ▁poderes ▁ma gico s . [SEP]\n",
            "I1209 17:50:35.209438 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁ zel ador ▁do ▁farol ▁de ▁bo ne ▁ point ▁Red ▁ han , ▁foi ▁rap tada ▁por ▁Jack ▁Ri son ho ▁a pos ▁seu ▁pai [MASK] ▁pensei ▁o ▁capita o ▁\" James ▁Gan t \" ▁( [MASK] [MASK] [MASK] [MASK] ) ▁e ▁ficar ▁devendo ▁dinheiro , ▁ela ▁fica ▁presa ▁na [MASK] ▁do ▁barco ▁Dama ▁da [MASK] te [MASK] ▁Jack ▁Ri son ho . ▁Drag ao ▁do ▁top a zio , ▁ajuda ▁Lie f ▁a ▁destruir ▁a ▁ir ma ▁do [MASK] [MASK] [MASK] ▁na ▁caverna ▁que ▁Lie f , ▁Bar da , ▁Ja s mine ▁e ▁dispostas [MASK] [MASK] ▁para ▁entrar ▁na ▁terra ▁da ▁tribo ▁Plu me . [SEP] ▁Ele ▁e ▁ser vo ▁do ▁Senhor ▁das ▁Som bras ▁e ▁tem ▁alguns ▁poderes ▁ma gico s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 19 7705 3079 12 20393 6 1530 298 19 20137 3073 19 2133 5 30 6170 2131 26 3087 1282 630 1259 8 2718 44 368 4 27025 11 18758 52 17 25187 9444 105 27 29 4 4 4 4 46 9 1749 16528 1449 5 157 1042 8078 25 4 12 9043 14476 13 4 204 4 3087 1282 630 1259 7 20333 8372 12 5495 49 6167 5 1076 10135 407 8 5368 8 1311 295 12 4 4 4 25 16242 15 10135 407 5 1600 62 5 1239 10 10602 9 17328 4 4 24 1724 25 875 13 6944 13168 336 7 3 163 9 55 695 12 3538 53 5152 10534 9 93 215 2433 983 8622 10 7 3\n",
            "I1209 17:50:35.209566 140365583124352 create_pretraining_data.py:197] input_ids: 2 19 7705 3079 12 20393 6 1530 298 19 20137 3073 19 2133 5 30 6170 2131 26 3087 1282 630 1259 8 2718 44 368 4 27025 11 18758 52 17 25187 9444 105 27 29 4 4 4 4 46 9 1749 16528 1449 5 157 1042 8078 25 4 12 9043 14476 13 4 204 4 3087 1282 630 1259 7 20333 8372 12 5495 49 6167 5 1076 10135 407 8 5368 8 1311 295 12 4 4 4 25 16242 15 10135 407 5 1600 62 5 1239 10 10602 9 17328 4 4 24 1724 25 875 13 6944 13168 336 7 3 163 9 55 695 12 3538 53 5152 10534 9 93 215 2433 983 8622 10 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.209665 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.209757 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1\n",
            "I1209 17:50:35.209846 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 27 28 37 38 39 40 41 50 52 57 58 59 71 81 82 83 97 98 99 0\n",
            "I1209 17:50:35.209910 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 27 28 37 38 39 40 41 50 52 57 58 59 71 81 82 83 97 98 99 0\n",
            "INFO:tensorflow:masked_lm_ids: 3015 24 29 22461 1282 630 1259 8078 745 9639 204 6 5 480 30 2407 465 9583 14384 0\n",
            "I1209 17:50:35.209974 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 3015 24 29 22461 1282 630 1259 8078 745 9639 204 6 5 480 30 2407 465 9583 14384 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.210039 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.210095 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.210519 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Thi bou ville ▁e [MASK] [MASK] ▁francesa ▁na ▁re gia o ▁administrativa ▁da ▁Normandia , ▁no ▁departamento ▁de ▁Eure . [SEP] ▁Estende [MASK] [MASK] ▁por ▁uma ▁a rea ▁de ▁8 , 92 [MASK] 2. [SEP]\n",
            "I1209 17:50:35.210622 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Thi bou ville ▁e [MASK] [MASK] ▁francesa ▁na ▁re gia o ▁administrativa ▁da ▁Normandia , ▁no ▁departamento ▁de ▁Eure . [SEP] ▁Estende [MASK] [MASK] ▁por ▁uma ▁a rea ▁de ▁8 , 92 [MASK] 2. [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6988 11236 1402 9 4 4 155 25 172 2094 52 164 13 830 5 22 154 6 2830 7 3 161 4 4 26 18 8 3711 6 303 5 4540 4 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.210744 140365583124352 create_pretraining_data.py:197] input_ids: 2 6988 11236 1402 9 4 4 155 25 172 2094 52 164 13 830 5 22 154 6 2830 7 3 161 4 4 26 18 8 3711 6 303 5 4540 4 133 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.210843 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.210935 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.211023 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 5 6 23 24 33 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.211091 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 5 6 23 24 33 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 18 98 16 34 90 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.211154 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 18 98 16 34 90 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:50:35.211217 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.211275 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.211751 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Como ▁contou ▁Moraes ▁Moreira ▁em ▁2010 , [SEP] [MASK] ▁Novos ▁Baiano s ▁regrav ou ▁a ▁can ca o ▁em ▁1972 , ▁no ▁album ▁\" A ca bou ▁Cho ra re \". ▁A ▁grava ca o ▁de ▁\" Brasil ▁Pan deiro \" ▁pelo ▁grupo ▁foi [MASK] [MASK] ▁music o ▁Jo ao ▁Gilberto , [MASK] [MASK] - lhes ▁uma ▁visita ▁enquanto ▁estavam ▁no ▁Rio ▁de ▁Janeiro , ▁e , ▁no tando ▁seu ▁estilo ▁ele trico , ▁aconselhou - os ▁a ▁levar ▁\" o [MASK] ▁de ▁volta ▁para ▁casa \", ▁a ▁encontrar em ▁suas ▁raiz es , ▁a ▁\" [MASK] rem [MASK] se [MASK] [MASK] [MASK] ▁si ▁mesmos \". ▁Esta ▁su gest ao [MASK] ▁espiritual ▁foi [MASK] [MASK] [MASK] ▁junto ▁a ▁proposta ▁de ▁regra va rem ▁\" Brasil ▁doloroso [SEP]\n",
            "I1209 17:50:35.211886 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Como ▁contou ▁Moraes ▁Moreira ▁em ▁2010 , [SEP] [MASK] ▁Novos ▁Baiano s ▁regrav ou ▁a ▁can ca o ▁em ▁1972 , ▁no ▁album ▁\" A ca bou ▁Cho ra re \". ▁A ▁grava ca o ▁de ▁\" Brasil ▁Pan deiro \" ▁pelo ▁grupo ▁foi [MASK] [MASK] ▁music o ▁Jo ao ▁Gilberto , [MASK] [MASK] - lhes ▁uma ▁visita ▁enquanto ▁estavam ▁no ▁Rio ▁de ▁Janeiro , ▁e , ▁no tando ▁seu ▁estilo ▁ele trico , ▁aconselhou - os ▁a ▁levar ▁\" o [MASK] ▁de ▁volta ▁para ▁casa \", ▁a ▁encontrar em ▁suas ▁raiz es , ▁a ▁\" [MASK] rem [MASK] se [MASK] [MASK] [MASK] ▁si ▁mesmos \". ▁Esta ▁su gest ao [MASK] ▁espiritual ▁foi [MASK] [MASK] [MASK] ▁junto ▁a ▁proposta ▁de ▁regra va rem ▁\" Brasil ▁doloroso [SEP]\n",
            "INFO:tensorflow:input_ids: 2 447 2170 7848 5846 14 1299 5 3 4 15555 15289 10 22684 158 8 3530 228 52 14 6246 5 22 22876 17 89 228 11236 3987 153 250 63 28 7693 228 52 6 17 6076 2066 4925 27 57 175 30 4 4 7720 52 2564 8372 5588 5 4 4 16 6236 18 2559 271 713 22 176 6 245 5 9 5 22 3840 44 655 69 9969 5 28913 16 239 8 2234 17 52 4 6 386 24 346 47 8 1378 136 109 6199 101 5 8 17 4 877 4 34 4 4 4 564 4285 63 412 1439 14744 8372 4 4375 30 4 4 4 540 8 1941 6 4072 84 877 17 6076 26550 3\n",
            "I1209 17:50:35.212005 140365583124352 create_pretraining_data.py:197] input_ids: 2 447 2170 7848 5846 14 1299 5 3 4 15555 15289 10 22684 158 8 3530 228 52 14 6246 5 22 22876 17 89 228 11236 3987 153 250 63 28 7693 228 52 6 17 6076 2066 4925 27 57 175 30 4 4 7720 52 2564 8372 5588 5 4 4 16 6236 18 2559 271 713 22 176 6 245 5 9 5 22 3840 44 655 69 9969 5 28913 16 239 8 2234 17 52 4 6 386 24 346 47 8 1378 136 109 6199 101 5 8 17 4 877 4 34 4 4 4 564 4285 63 412 1439 14744 8372 4 4375 30 4 4 4 540 8 1941 6 4072 84 877 17 6076 26550 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.212102 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.212194 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            "I1209 17:50:35.212283 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 9 45 46 53 54 82 96 97 98 99 100 101 102 103 111 114 115 116 126 0\n",
            "I1209 17:50:35.212370 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 9 45 46 53 54 82 96 97 98 99 100 101 102 103 111 114 115 116 126 0\n",
            "INFO:tensorflow:masked_lm_ids: 175 9360 57 15 225 1491 17 14757 877 16 34 24 516 6 529 3350 26 5588 2066 0\n",
            "I1209 17:50:35.212437 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 175 9360 57 15 225 1491 17 14757 877 16 34 24 516 6 529 3350 26 5588 2066 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.212503 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.212559 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.213016 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] a ▁e ▁composta ▁das ▁cores ▁vermelho ▁e ▁azul ▁a ▁quartos . ▁A ▁dis pos ica o ▁das ▁cores ▁e : ▁azul ▁a ▁direita ▁e ▁vermelho ▁a ▁esquerda , ▁costas ▁e ▁manga s ▁com ▁cores ▁opostas , ▁cal co es ▁azuis ▁e ▁meias ▁vermelhas ▁e ▁azuis ▁com ▁listras ▁horizontais . ▁Desde ▁a ▁funda ca o ▁em ▁1893 ▁foram ▁adotada s ▁no ▁com eco ▁camisa [SEP] ▁suas ▁principais ▁conquistas , ▁ha ▁tambem ▁uma ▁e dica o [MASK] ▁Copa ▁da ▁Italia , [MASK] [MASK] . ▁O ▁Gen o a ▁de tem ▁o ▁recorde ▁de ▁titulo s ▁no [MASK] ▁Serie ▁coruja [MASK] [MASK] ▁total ▁de ▁6 ▁(19 34 - [MASK] [MASK] [MASK] ▁talento [MASK] , ▁1961 - 62 [MASK] ▁1972 - 73 [MASK] ▁1975 - 76 ▁e [MASK] [MASK] 89 [SEP]\n",
            "I1209 17:50:35.213144 140365583124352 create_pretraining_data.py:187] tokens: [CLS] a ▁e ▁composta ▁das ▁cores ▁vermelho ▁e ▁azul ▁a ▁quartos . ▁A ▁dis pos ica o ▁das ▁cores ▁e : ▁azul ▁a ▁direita ▁e ▁vermelho ▁a ▁esquerda , ▁costas ▁e ▁manga s ▁com ▁cores ▁opostas , ▁cal co es ▁azuis ▁e ▁meias ▁vermelhas ▁e ▁azuis ▁com ▁listras ▁horizontais . ▁Desde ▁a ▁funda ca o ▁em ▁1893 ▁foram ▁adotada s ▁no ▁com eco ▁camisa [SEP] ▁suas ▁principais ▁conquistas , ▁ha ▁tambem ▁uma ▁e dica o [MASK] ▁Copa ▁da ▁Italia , [MASK] [MASK] . ▁O ▁Gen o a ▁de tem ▁o ▁recorde ▁de ▁titulo s ▁no [MASK] ▁Serie ▁coruja [MASK] [MASK] ▁total ▁de ▁6 ▁(19 34 - [MASK] [MASK] [MASK] ▁talento [MASK] , ▁1961 - 62 [MASK] ▁1972 - 73 [MASK] ▁1975 - 76 ▁e [MASK] [MASK] 89 [SEP]\n",
            "INFO:tensorflow:input_ids: 2 49 9 1422 53 1665 3341 9 2477 8 13918 7 28 2573 2718 1840 52 53 1665 9 42 2477 8 2543 9 3341 8 2056 5 6238 9 15052 10 21 1665 17029 5 2725 238 101 12018 9 13475 12295 9 12018 21 21013 21295 7 920 8 12345 228 52 14 9008 75 7363 10 22 21 9977 3496 3 109 443 6284 5 2909 27557 18 9 4688 52 4 458 13 19938 5 4 4 7 33 5076 52 49 6 4395 11 2833 6 20370 10 22 4 14948 19161 4 4 663 6 240 607 3979 16 4 4 4 5509 4 5 3204 16 4365 4 6246 16 4188 4 2463 16 3838 9 4 4 3335 3\n",
            "I1209 17:50:35.213260 140365583124352 create_pretraining_data.py:197] input_ids: 2 49 9 1422 53 1665 3341 9 2477 8 13918 7 28 2573 2718 1840 52 53 1665 9 42 2477 8 2543 9 3341 8 2056 5 6238 9 15052 10 21 1665 17029 5 2725 238 101 12018 9 13475 12295 9 12018 21 21013 21295 7 920 8 12345 228 52 14 9008 75 7363 10 22 21 9977 3496 3 109 443 6284 5 2909 27557 18 9 4688 52 4 458 13 19938 5 4 4 7 33 5076 52 49 6 4395 11 2833 6 20370 10 22 4 14948 19161 4 4 663 6 240 607 3979 16 4 4 4 5509 4 5 3204 16 4365 4 6246 16 4188 4 2463 16 3838 9 4 4 3335 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.309714 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.309946 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.310052 140365583124352 create_pretraining_data.py:197] token_boundary: 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 24 47 75 80 81 95 96 97 98 99 106 107 108 109 110 115 119 124 125 0\n",
            "I1209 17:50:35.310125 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 24 47 75 80 81 95 96 97 98 99 106 107 108 109 110 115 119 124 125 0\n",
            "INFO:tensorflow:masked_lm_ids: 9 21013 13 14 5722 1024 14948 249 5 20 2766 5 3414 16 3892 5 5 3824 16 0\n",
            "I1209 17:50:35.310194 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 9 21013 13 14 5722 1024 14948 249 5 20 2766 5 3414 16 3892 5 5 3824 16 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.310266 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.310403 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.311050 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Gre ny ▁e ▁uma ▁comuna ▁francesa ▁na ▁re gia o ▁administrativa ▁da ▁Normandia , ▁no ▁departamento ▁de ▁Sena ▁Mari timo . [SEP] ▁Estende [MASK] ▁(12 ▁grave ▁uma ▁a rea ▁de ▁4 , 11 [MASK] [MASK] [SEP]\n",
            "I1209 17:50:35.311212 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Gre ny ▁e ▁uma ▁comuna ▁francesa ▁na ▁re gia o ▁administrativa ▁da ▁Normandia , ▁no ▁departamento ▁de ▁Sena ▁Mari timo . [SEP] ▁Estende [MASK] ▁(12 ▁grave ▁uma ▁a rea ▁de ▁4 , 11 [MASK] [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5230 1952 9 18 98 155 25 172 2094 52 164 13 830 5 22 154 6 3344 5920 11940 7 3 161 4 9170 4582 18 8 3711 6 178 5 2884 4 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.311357 140365583124352 create_pretraining_data.py:197] input_ids: 2 5230 1952 9 18 98 155 25 172 2094 52 164 13 830 5 22 154 6 3344 5920 11940 7 3 161 4 9170 4582 18 8 3711 6 178 5 2884 4 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.311478 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.311573 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.311662 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 24 25 26 27 34 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.311727 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 24 25 26 27 34 35 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 16 34 26 18 90 133 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.311790 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 16 34 26 18 90 133 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:50:35.311856 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.311914 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.312418 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁existe ▁no ▁mundo ▁ha ▁mais ▁de ▁cem ▁anos , ▁sendo ▁praticada ▁em ▁mais ▁de ▁130 ▁pais es ▁( inclusive ▁nos ▁EUA , ▁Ja pa o ▁e [MASK] [MASK] [MASK] [MASK] ▁vizinhos [MASK] [MASK] ▁e ▁um ▁profissional ▁da ▁a rea ▁da ▁sau [MASK] [MASK] ▁com ▁forma ca o ▁superior [MASK] [MASK] [MASK] , ▁que [MASK] ▁habilitado ▁a [MASK] [MASK] ▁e ▁avaliar ▁o [MASK] ▁da ▁visa o , ▁a tra ves ▁de ▁artefatos ▁o p ticos ▁e ▁equipamentos ▁o pto met ricos , ▁altera co es ▁visuais ▁de ▁origem ▁na o [SEP] ▁Na ▁mesma [MASK] ▁(18 96) ▁nos ▁Estados ▁Unidos ▁foi ▁criada ▁a ▁Associa ca o ▁Americana ▁de ▁O ptica ▁e ▁dois ▁anos ▁depois ▁(18 98) ▁fundada ▁a ▁Associa ca o ▁Americana ▁de ▁O pto met ristas . [SEP]\n",
            "I1209 17:50:35.312572 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁existe ▁no ▁mundo ▁ha ▁mais ▁de ▁cem ▁anos , ▁sendo ▁praticada ▁em ▁mais ▁de ▁130 ▁pais es ▁( inclusive ▁nos ▁EUA , ▁Ja pa o ▁e [MASK] [MASK] [MASK] [MASK] ▁vizinhos [MASK] [MASK] ▁e ▁um ▁profissional ▁da ▁a rea ▁da ▁sau [MASK] [MASK] ▁com ▁forma ca o ▁superior [MASK] [MASK] [MASK] , ▁que [MASK] ▁habilitado ▁a [MASK] [MASK] ▁e ▁avaliar ▁o [MASK] ▁da ▁visa o , ▁a tra ves ▁de ▁artefatos ▁o p ticos ▁e ▁equipamentos ▁o pto met ricos , ▁altera co es ▁visuais ▁de ▁origem ▁na o [SEP] ▁Na ▁mesma [MASK] ▁(18 96) ▁nos ▁Estados ▁Unidos ▁foi ▁criada ▁a ▁Associa ca o ▁Americana ▁de ▁O ptica ▁e ▁dois ▁anos ▁depois ▁(18 98) ▁fundada ▁a ▁Associa ca o ▁Americana ▁de ▁O pto met ristas . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1136 22 219 2909 39 6 6020 66 5 92 13415 14 39 6 8582 1480 101 29 22693 85 1312 5 1239 534 52 9 4 4 4 4 6194 4 4 9 20 943 13 8 3711 13 10464 4 4 21 129 228 52 1107 4 4 4 5 15 4 22934 8 4 4 9 7870 11 4 13 7879 52 5 8 797 2704 6 18261 11 241 9298 9 2582 11 4131 4134 14013 5 13244 238 101 9131 6 557 25 52 3 95 394 4 1134 19940 85 216 224 30 1101 8 15442 228 52 7289 6 33 17706 9 97 66 115 1134 19219 1350 8 15442 228 52 7289 6 33 4131 4134 13608 7 3\n",
            "I1209 17:50:35.312705 140365583124352 create_pretraining_data.py:197] input_ids: 2 1136 22 219 2909 39 6 6020 66 5 92 13415 14 39 6 8582 1480 101 29 22693 85 1312 5 1239 534 52 9 4 4 4 4 6194 4 4 9 20 943 13 8 3711 13 10464 4 4 21 129 228 52 1107 4 4 4 5 15 4 22934 8 4 4 9 7870 11 4 13 7879 52 5 8 797 2704 6 18261 11 241 9298 9 2582 11 4131 4134 14013 5 13244 238 101 9131 6 557 25 52 3 95 394 4 1134 19940 85 216 224 30 1101 8 15442 228 52 7289 6 33 17706 9 97 66 115 1134 19219 1350 8 15442 228 52 7289 6 33 4131 4134 13608 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.312807 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.312899 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1\n",
            "I1209 17:50:35.312988 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 27 28 29 30 31 32 33 40 41 42 43 49 50 51 54 57 58 62 93 0\n",
            "I1209 17:50:35.313051 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 27 28 29 30 31 32 33 40 41 42 43 49 50 51 54 57 58 62 93 0\n",
            "INFO:tensorflow:masked_lm_ids: 549 73 33 33 4131 4134 6396 13 10464 103 5 51 5735 4334 233 10723 41 1048 869 0\n",
            "I1209 17:50:35.313114 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 549 73 33 33 4131 4134 6396 13 10464 103 5 51 5735 4334 233 10723 41 1048 869 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.313178 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.313235 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.313709 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁pode - se ▁distinguir ▁em ▁duas ▁partes : ▁um ▁segmento ▁curva do ▁vertical [MASK] ▁a ▁esca ma [MASK] ▁frontal [MASK] [MASK] qua [MASK] ▁frontal is \"), ▁e ▁um ▁segmento ▁horizontal , ▁a ▁por ca o ▁o r bit ona sal , ▁que ▁e [MASK] [MASK] [MASK] [MASK] ▁triangular es ▁pela ▁inci s ura ▁et mo ida l . ▁Apresenta ▁duas ▁faces : ▁uma ▁posterior ▁e ▁con ca va ▁( face ▁interna ▁ou ▁e ndo cra ni al ) ▁e ▁uma ▁anterior ▁e ▁con ve xa ▁( face ▁externa ▁ou ▁ex oc ran ial ). ▁Mar gem ▁posterior ▁do ▁frontal , ▁que ▁capsula ▁articula ▁com [SEP] ▁Mar gem ▁inferior ▁ser rada ▁da ▁parte [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁aos ▁ossos ▁nas ais ▁e ▁maxila s . [SEP]\n",
            "I1209 17:50:35.313840 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁pode - se ▁distinguir ▁em ▁duas ▁partes : ▁um ▁segmento ▁curva do ▁vertical [MASK] ▁a ▁esca ma [MASK] ▁frontal [MASK] [MASK] qua [MASK] ▁frontal is \"), ▁e ▁um ▁segmento ▁horizontal , ▁a ▁por ca o ▁o r bit ona sal , ▁que ▁e [MASK] [MASK] [MASK] [MASK] ▁triangular es ▁pela ▁inci s ura ▁et mo ida l . ▁Apresenta ▁duas ▁faces : ▁uma ▁posterior ▁e ▁con ca va ▁( face ▁interna ▁ou ▁e ndo cra ni al ) ▁e ▁uma ▁anterior ▁e ▁con ve xa ▁( face ▁externa ▁ou ▁ex oc ran ial ). ▁Mar gem ▁posterior ▁do ▁frontal , ▁que ▁capsula ▁articula ▁com [SEP] ▁Mar gem ▁inferior ▁ser rada ▁da ▁parte [MASK] [MASK] [MASK] [MASK] [MASK] [MASK] ▁aos ▁ossos ▁nas ais ▁e ▁maxila s . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 110 16 34 10516 14 168 1298 42 20 6499 6420 61 7343 4 8 5879 295 4 11608 4 4 1919 4 11608 194 709 9 20 6499 9815 5 8 26 228 52 11 41 4904 3925 4894 5 15 9 4 4 4 4 13117 101 54 7184 10 2167 4498 320 1535 106 7 6381 168 13207 42 18 3676 9 640 228 84 29 10715 2495 51 9 65 3174 402 374 46 9 18 964 9 640 398 2130 29 10715 3827 51 281 5600 1993 5382 73 652 1047 3676 12 11608 5 15 28996 18176 21 3 652 1047 2632 55 4821 13 96 4 4 4 4 4 4 119 9514 107 1755 9 25052 10 7 3\n",
            "I1209 17:50:35.313957 140365583124352 create_pretraining_data.py:197] input_ids: 2 110 16 34 10516 14 168 1298 42 20 6499 6420 61 7343 4 8 5879 295 4 11608 4 4 1919 4 11608 194 709 9 20 6499 9815 5 8 26 228 52 11 41 4904 3925 4894 5 15 9 4 4 4 4 13117 101 54 7184 10 2167 4498 320 1535 106 7 6381 168 13207 42 18 3676 9 640 228 84 29 10715 2495 51 9 65 3174 402 374 46 9 18 964 9 640 398 2130 29 10715 3827 51 281 5600 1993 5382 73 652 1047 3676 12 11608 5 15 28996 18176 21 3 652 1047 2632 55 4821 13 96 4 4 4 4 4 4 119 9514 107 1755 9 25052 10 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.314055 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.314146 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            "I1209 17:50:35.314236 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 1 1 1 1 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 14 18 20 21 22 23 43 44 45 46 47 60 102 113 114 115 116 117 118 0\n",
            "I1209 17:50:35.314315 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 14 18 20 21 22 23 43 44 45 46 47 60 102 113 114 115 116 117 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 5 12 230 10 1919 295 9 3068 14 6983 8570 168 35 107 374 7 1154 16 34 0\n",
            "I1209 17:50:35.314388 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 5 12 230 10 1919 295 9 3068 14 6983 8570 168 35 107 374 7 1154 16 34 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.314455 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.314511 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.314944 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁De ▁acordo ▁com ▁o ▁\" C hr oni con ▁Let hren se [MASK] ▁ dina mar ques , [MASK] ▁supostamente [MASK] [MASK] ▁ao ▁Medi terra neo . [SEP] ▁Haroldo ▁De nte ▁de ▁Guerra ▁e ▁referido ▁na ▁Feito s ▁dos ▁Dan os ▁do ▁historiador ▁ dina mar ques ▁Sa xa o [MASK] ▁1965. [MASK] , [MASK] ▁saga ▁is landes a ▁de ▁Her va rar ▁e ▁no ▁fragmento ▁is landes ▁So gu bro t ▁a f [MASK] [MASK] [MASK] [MASK] ▁for n kon ung um . [SEP]\n",
            "I1209 17:50:35.315062 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁De ▁acordo ▁com ▁o ▁\" C hr oni con ▁Let hren se [MASK] ▁ dina mar ques , [MASK] ▁supostamente [MASK] [MASK] ▁ao ▁Medi terra neo . [SEP] ▁Haroldo ▁De nte ▁de ▁Guerra ▁e ▁referido ▁na ▁Feito s ▁dos ▁Dan os ▁do ▁historiador ▁ dina mar ques ▁Sa xa o [MASK] ▁1965. [MASK] , [MASK] ▁saga ▁is landes a ▁de ▁Her va rar ▁e ▁no ▁fragmento ▁is landes ▁So gu bro t ▁a f [MASK] [MASK] [MASK] [MASK] ▁for n kon ung um . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 167 316 21 11 17 189 5006 4588 828 11959 21814 34 4 19 5918 928 4026 5 4 6414 4 4 37 7558 7011 9734 7 3 18001 167 291 6 452 9 5508 25 24656 10 36 4181 239 12 3521 19 5918 928 4026 499 2130 52 4 16501 4 5 4 10097 5190 11732 49 6 1963 84 7304 9 22 21706 5190 11732 988 1163 3971 105 8 407 4 4 4 4 728 111 13217 3683 491 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.315172 140365583124352 create_pretraining_data.py:197] input_ids: 2 167 316 21 11 17 189 5006 4588 828 11959 21814 34 4 19 5918 928 4026 5 4 6414 4 4 37 7558 7011 9734 7 3 18001 167 291 6 452 9 5508 25 24656 10 36 4181 239 12 3521 19 5918 928 4026 499 2130 52 4 16501 4 5 4 10097 5190 11732 49 6 1963 84 7304 9 22 21706 5190 11732 988 1163 3971 105 8 407 4 4 4 4 728 111 13217 3683 491 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.315267 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.315387 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.315478 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 1 0 0 1 1 1 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 13 19 20 21 22 51 52 53 55 75 76 77 78 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.315544 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 13 19 20 21 22 51 52 53 55 75 76 77 78 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 27 44 6830 1561 14441 2932 295 3116 25 22 304 304 3832 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.315607 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 27 44 6830 1561 14441 2932 295 3116 25 22 304 304 3832 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:50:35.315671 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.315733 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.316175 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] mo ▁de ▁1 3% ▁sobre ▁o ▁ga s ▁boliviano ▁e , ▁em ▁1 o ▁de ▁novembro , ▁o ▁in s um o ▁importa do ▁ter a [MASK] ▁aumento ▁de ▁10% . ▁O ▁design ▁ cera mico ▁trata ▁desde ▁a ▁conforma ca o ▁do ▁produto ▁em ▁si ▁( com pos ica o [MASK] ▁pasta , ▁tipo ▁de ▁queima , aca ba mentos ) ▁a [SEP] ▁empresas ▁absorve m ▁800 ▁milho es ▁de ▁metros ▁cub icos ▁por ▁ano [MASK] ▁volume ▁que ▁equivale ▁a ▁10% ▁de [MASK] [MASK] [MASK] [MASK] ▁importa do ▁da ▁Boli via ▁e [MASK] ▁ 6% ▁do ▁total ▁consumido [MASK] [MASK] . ▁Os ▁fabricantes ▁nacionais [MASK] [MASK] [MASK] [MASK] ▁principais ▁ us u ario s ▁do [MASK] [MASK] ▁sentinela ▁a ▁cerca ▁de ▁30% ▁dos ▁custos ▁de [SEP]\n",
            "I1209 17:50:35.316307 140365583124352 create_pretraining_data.py:187] tokens: [CLS] mo ▁de ▁1 3% ▁sobre ▁o ▁ga s ▁boliviano ▁e , ▁em ▁1 o ▁de ▁novembro , ▁o ▁in s um o ▁importa do ▁ter a [MASK] ▁aumento ▁de ▁10% . ▁O ▁design ▁ cera mico ▁trata ▁desde ▁a ▁conforma ca o ▁do ▁produto ▁em ▁si ▁( com pos ica o [MASK] ▁pasta , ▁tipo ▁de ▁queima , aca ba mentos ) ▁a [SEP] ▁empresas ▁absorve m ▁800 ▁milho es ▁de ▁metros ▁cub icos ▁por ▁ano [MASK] ▁volume ▁que ▁equivale ▁a ▁10% ▁de [MASK] [MASK] [MASK] [MASK] ▁importa do ▁da ▁Boli via ▁e [MASK] ▁ 6% ▁do ▁total ▁consumido [MASK] [MASK] . ▁Os ▁fabricantes ▁nacionais [MASK] [MASK] [MASK] [MASK] ▁principais ▁ us u ario s ▁do [MASK] [MASK] ▁sentinela ▁a ▁cerca ▁de ▁30% ▁dos ▁custos ▁de [SEP]\n",
            "INFO:tensorflow:input_ids: 2 320 6 118 5398 79 11 2880 10 15384 9 5 14 118 52 6 419 5 11 188 10 491 52 5010 61 137 49 4 1394 6 11843 7 33 2715 19 11310 5622 2587 208 8 17581 228 52 12 1942 14 564 29 533 2718 1840 52 4 8474 5 444 6 8614 5 4306 454 2767 46 8 3 1109 14570 48 7971 11666 101 6 811 17431 8143 26 76 4 2550 15 13438 8 11843 6 4 4 4 4 5010 61 13 15906 1057 9 4 19 5915 12 663 14693 4 4 7 87 9775 2156 4 4 4 4 443 19 339 64 14936 10 12 4 4 29385 8 232 6 13972 36 4705 6 3\n",
            "I1209 17:50:35.413168 140365583124352 create_pretraining_data.py:197] input_ids: 2 320 6 118 5398 79 11 2880 10 15384 9 5 14 118 52 6 419 5 11 188 10 491 52 5010 61 137 49 4 1394 6 11843 7 33 2715 19 11310 5622 2587 208 8 17581 228 52 12 1942 14 564 29 533 2718 1840 52 4 8474 5 444 6 8614 5 4306 454 2767 46 8 3 1109 14570 48 7971 11666 101 6 811 17431 8143 26 76 4 2550 15 13438 8 11843 6 4 4 4 4 5010 61 13 15906 1057 9 4 19 5915 12 663 14693 4 4 7 87 9775 2156 4 4 4 4 443 19 339 64 14936 10 12 4 4 29385 8 232 6 13972 36 4705 6 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.413354 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.413477 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.413574 140365583124352 create_pretraining_data.py:197] token_boundary: 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 0 0 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 27 52 56 77 84 85 86 87 94 100 101 102 106 107 108 109 117 118 119 0\n",
            "I1209 17:50:35.413643 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 27 52 56 77 84 85 86 87 94 100 101 102 106 107 108 109 117 118 119 0\n",
            "INFO:tensorflow:masked_lm_ids: 309 13 6 5 311 11 2880 10 8 22 12470 7 233 52 60 32 1942 15 3085 0\n",
            "I1209 17:50:35.413709 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 309 13 6 5 311 11 2880 10 8 22 12470 7 233 52 60 32 1942 15 3085 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.413777 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.413837 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.414436 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁De [MASK] ▁com ▁o ▁pas s iv ismo , ▁nos ▁nossos ▁ra cio cini os ▁e ▁in fer encia s ▁somos ▁completamente ▁passivo s [MASK] [SEP] ▁teoria ▁segundo [MASK] [MASK] [MASK] ▁co g nica o ▁e ▁fruto ▁de ▁processos ▁mentais ▁in volu nta rio s , ▁e s ponta neo s ▁ou ▁inconsciente s . ▁De ▁acordo ▁com ▁o ▁pas s iv ismo , ▁o ▁pensamento [MASK] [MASK] ▁tipo ▁de ▁\" atividade [MASK] ▁mental ▁apenas [MASK] [MASK] ▁em ▁que [MASK] [MASK] ▁de ▁atividade ▁vulcan ica , ▁sem ▁Bradford ▁que ▁pensamentos ▁pre ssu pon ham ▁a co es ▁do ▁separada . ▁Pensamento s ▁sa o ▁acontecimentos ▁e s ponta neo s [MASK] [MASK] [MASK] ▁pas s iv ismo . ▁Eles ▁acontecem ▁sem ▁a ▁interfere ncia ▁do ▁sujeito [SEP]\n",
            "I1209 17:50:35.414588 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁De [MASK] ▁com ▁o ▁pas s iv ismo , ▁nos ▁nossos ▁ra cio cini os ▁e ▁in fer encia s ▁somos ▁completamente ▁passivo s [MASK] [SEP] ▁teoria ▁segundo [MASK] [MASK] [MASK] ▁co g nica o ▁e ▁fruto ▁de ▁processos ▁mentais ▁in volu nta rio s , ▁e s ponta neo s ▁ou ▁inconsciente s . ▁De ▁acordo ▁com ▁o ▁pas s iv ismo , ▁o ▁pensamento [MASK] [MASK] ▁tipo ▁de ▁\" atividade [MASK] ▁mental ▁apenas [MASK] [MASK] ▁em ▁que [MASK] [MASK] ▁de ▁atividade ▁vulcan ica , ▁sem ▁Bradford ▁que ▁pensamentos ▁pre ssu pon ham ▁a co es ▁do ▁separada . ▁Pensamento s ▁sa o ▁acontecimentos ▁e s ponta neo s [MASK] [MASK] [MASK] ▁pas s iv ismo . ▁Eles ▁acontecem ▁sem ▁a ▁interfere ncia ▁do ▁sujeito [SEP]\n",
            "INFO:tensorflow:input_ids: 2 167 4 21 11 16589 10 10241 556 5 85 7122 1901 1888 22051 239 9 188 2034 7367 10 19896 1980 19249 10 4 3 900 186 4 4 4 431 286 4334 52 9 3739 6 1937 8302 188 4604 1883 1561 10 5 9 10 16298 9734 10 51 13208 10 7 167 316 21 11 16589 10 10241 556 5 11 2748 4 4 444 6 17 13641 4 5513 139 4 4 14 15 4 4 6 1309 29715 1840 5 181 25514 15 12409 762 9408 6456 3002 8 238 101 12 9124 7 24239 10 1577 52 4205 9 10 16298 9734 10 4 4 4 16589 10 10241 556 7 1146 16135 181 8 25678 4428 12 6142 3\n",
            "I1209 17:50:35.414711 140365583124352 create_pretraining_data.py:197] input_ids: 2 167 4 21 11 16589 10 10241 556 5 85 7122 1901 1888 22051 239 9 188 2034 7367 10 19896 1980 19249 10 4 3 900 186 4 4 4 431 286 4334 52 9 3739 6 1937 8302 188 4604 1883 1561 10 5 9 10 16298 9734 10 51 13208 10 7 167 316 21 11 16589 10 10241 556 5 11 2748 4 4 444 6 17 13641 4 5513 139 4 4 14 15 4 4 6 1309 29715 1840 5 181 25514 15 12409 762 9408 6456 3002 8 238 101 12 9124 7 24239 10 1577 52 4205 9 10 16298 9734 10 4 4 4 16589 10 10241 556 7 1146 16135 181 8 25678 4428 12 6142 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.414810 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.414904 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1\n",
            "I1209 17:50:35.414994 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 1 1 1 1 1 1 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 4 25 29 30 31 66 67 68 73 76 77 80 81 88 99 111 112 113 0\n",
            "I1209 17:50:35.415059 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 2 4 25 29 30 31 66 67 68 73 76 77 80 81 88 99 111 112 113 0\n",
            "INFO:tensorflow:masked_lm_ids: 316 11 7 8 170 8 2748 9 20 27 22 1048 2198 511 18954 6142 5 24 11 0\n",
            "I1209 17:50:35.415120 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 316 11 7 8 170 8 2748 9 20 27 22 1048 2198 511 18954 6142 5 24 11 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.415185 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.415242 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.415740 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Na ▁quinta ▁temporada , [MASK] [MASK] [MASK] dio ▁\" [MASK] ▁A lone \" ▁foi ▁o ▁primeiro ▁a ▁com e car ▁sem ▁contar ▁a ▁historia ▁de ▁uma ▁morte , ▁mas ▁foca ndo - se ▁em ▁uma ▁morte ▁revelada ▁no ▁final ▁do ▁epi so dio ▁anterior . [SEP] o ▁mostrou ▁deliberadamente ▁uma ▁morte ▁no ▁inicio ▁foi ▁o [MASK] , ▁\" Every one ' s ▁ Wait ing \", ▁que , ▁em ▁vez ▁disso , ▁com eca ▁com ▁um [MASK] [MASK] [MASK] ▁cena [MASK] [MASK] ▁serie ▁e ▁o ▁dia lo go ▁entre [MASK] ▁dos ▁personagens ▁e [MASK] ▁pessoa ▁que [MASK] ▁no ▁inicio ▁do ▁epi so dio . ▁As ▁vezes , ▁a ▁conversa ▁e ▁com ▁personagens [MASK] [MASK] ▁prejudica ▁a ▁familia . [MASK] ▁conversa s ▁representam ▁o ▁dia lo go [SEP]\n",
            "I1209 17:50:35.415868 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Na ▁quinta ▁temporada , [MASK] [MASK] [MASK] dio ▁\" [MASK] ▁A lone \" ▁foi ▁o ▁primeiro ▁a ▁com e car ▁sem ▁contar ▁a ▁historia ▁de ▁uma ▁morte , ▁mas ▁foca ndo - se ▁em ▁uma ▁morte ▁revelada ▁no ▁final ▁do ▁epi so dio ▁anterior . [SEP] o ▁mostrou ▁deliberadamente ▁uma ▁morte ▁no ▁inicio ▁foi ▁o [MASK] , ▁\" Every one ' s ▁ Wait ing \", ▁que , ▁em ▁vez ▁disso , ▁com eca ▁com ▁um [MASK] [MASK] [MASK] ▁cena [MASK] [MASK] ▁serie ▁e ▁o ▁dia lo go ▁entre [MASK] ▁dos ▁personagens ▁e [MASK] ▁pessoa ▁que [MASK] ▁no ▁inicio ▁do ▁epi so dio . ▁As ▁vezes , ▁a ▁conversa ▁e ▁com ▁personagens [MASK] [MASK] ▁prejudica ▁a ▁familia . [MASK] ▁conversa s ▁representam ▁o ▁dia lo go [SEP]\n",
            "INFO:tensorflow:input_ids: 2 95 2593 362 5 4 4 4 3037 17 4 28 17206 27 30 11 86 8 21 70 1304 181 4018 8 15634 6 18 325 5 68 7187 65 16 34 14 18 325 14307 22 182 12 7236 723 3037 964 7 3 52 3373 21830 18 325 22 10974 30 11 4 5 17 22047 3241 121 10 19 24275 498 47 15 5 14 140 487 5 21 9133 21 20 4 4 4 1694 4 4 20640 9 11 123 145 436 60 4 36 805 9 4 824 15 4 22 10974 12 7236 723 3037 7 134 231 5 8 4471 9 21 805 4 4 17132 8 25717 7 4 4471 10 5429 11 123 145 436 3\n",
            "I1209 17:50:35.415985 140365583124352 create_pretraining_data.py:197] input_ids: 2 95 2593 362 5 4 4 4 3037 17 4 28 17206 27 30 11 86 8 21 70 1304 181 4018 8 15634 6 18 325 5 68 7187 65 16 34 14 18 325 14307 22 182 12 7236 723 3037 964 7 3 52 3373 21830 18 325 22 10974 30 11 4 5 17 22047 3241 121 10 19 24275 498 47 15 5 14 140 487 5 21 9133 21 20 4 4 4 1694 4 4 20640 9 11 123 145 436 60 4 36 805 9 4 824 15 4 22 10974 12 7236 723 3037 7 134 231 5 8 4471 9 21 805 4 4 17132 8 25717 7 4 4471 10 5429 11 123 145 436 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.416081 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.416173 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            "I1209 17:50:35.416261 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 6 7 8 9 10 56 77 78 79 81 82 90 94 97 113 114 115 119 0\n",
            "I1209 17:50:35.416340 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 5 6 7 8 9 10 56 77 78 79 81 82 90 94 97 113 114 115 119 0\n",
            "INFO:tensorflow:masked_lm_ids: 11 7236 723 3037 17 8409 23752 2572 7 377 9817 25 20 8 1087 3029 39 4765 2634 0\n",
            "I1209 17:50:35.416412 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 11 7236 723 3037 17 8409 23752 2572 7 377 9817 25 20 8 1087 3029 39 4765 2634 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.416478 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.416535 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.416992 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁ne go cio ▁por ▁sua ▁prop ria ▁produtora , ▁a ▁First ▁Kiss ▁Productions . ▁Silverstone ▁tambem ▁ganhou ▁\" Melhor ▁Performance ▁Feminina \" ▁e ▁\" Mulher ▁Mais [MASK] ▁discreta vel \" ▁no ▁1996 ▁MTV [MASK] ▁Awards ▁por ▁sua ▁atua ca o ▁no ▁filme . [MASK] [MASK] ▁ano , ▁Silverstone ▁estrelou ▁o ▁ thriller [MASK] ro [MASK] [MASK] [MASK] ▁ Objeto ▁de ▁Des ejo , ▁o ▁suspense ▁O ▁Esco nder ijo ▁e ▁o ▁drama ▁franc es ▁Le ▁No uve a ute [MASK] [MASK] . ▁No ▁ano [SEP] ▁Pro xi mo ▁papel ▁de ▁Silverstone ▁foi ▁a ▁Bat girl ▁em ▁Batman ▁& ▁Robin , ▁e ▁enquanto ▁ela ▁na o ▁foi ▁um ▁sucesso ▁de ▁critica , ▁o ▁filme [MASK] [MASK] [MASK] [MASK] [MASK] ▁de ▁do lares ▁em ▁todo ▁o ▁mundo . [SEP]\n",
            "I1209 17:50:35.417117 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁ne go cio ▁por ▁sua ▁prop ria ▁produtora , ▁a ▁First ▁Kiss ▁Productions . ▁Silverstone ▁tambem ▁ganhou ▁\" Melhor ▁Performance ▁Feminina \" ▁e ▁\" Mulher ▁Mais [MASK] ▁discreta vel \" ▁no ▁1996 ▁MTV [MASK] ▁Awards ▁por ▁sua ▁atua ca o ▁no ▁filme . [MASK] [MASK] ▁ano , ▁Silverstone ▁estrelou ▁o ▁ thriller [MASK] ro [MASK] [MASK] [MASK] ▁ Objeto ▁de ▁Des ejo , ▁o ▁suspense ▁O ▁Esco nder ijo ▁e ▁o ▁drama ▁franc es ▁Le ▁No uve a ute [MASK] [MASK] . ▁No ▁ano [SEP] ▁Pro xi mo ▁papel ▁de ▁Silverstone ▁foi ▁a ▁Bat girl ▁em ▁Batman ▁& ▁Robin , ▁e ▁enquanto ▁ela ▁na o ▁foi ▁um ▁sucesso ▁de ▁critica , ▁o ▁filme [MASK] [MASK] [MASK] [MASK] [MASK] ▁de ▁do lares ▁em ▁todo ▁o ▁mundo . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 3763 436 1888 26 38 9592 269 4623 5 8 16516 10732 11676 7 25124 27557 727 17 5089 16909 22151 27 9 17 27063 908 4 13821 1702 27 22 2604 3181 4 2446 26 38 3234 228 52 22 159 7 4 4 76 5 25124 7647 11 19 25501 4 364 4 4 4 19 26047 6 2075 6936 5 11 13025 33 10401 4231 17040 9 11 2424 22559 101 585 67 10638 49 7152 4 4 7 67 76 3 932 1510 320 479 6 25124 30 8 10444 12022 14 5117 752 8838 5 9 271 157 25 52 30 20 308 6 4488 5 11 159 4 4 4 4 4 6 12 8050 14 311 11 219 7 3\n",
            "I1209 17:50:35.417233 140365583124352 create_pretraining_data.py:197] input_ids: 2 3763 436 1888 26 38 9592 269 4623 5 8 16516 10732 11676 7 25124 27557 727 17 5089 16909 22151 27 9 17 27063 908 4 13821 1702 27 22 2604 3181 4 2446 26 38 3234 228 52 22 159 7 4 4 76 5 25124 7647 11 19 25501 4 364 4 4 4 19 26047 6 2075 6936 5 11 13025 33 10401 4231 17040 9 11 2424 22559 101 585 67 10638 49 7152 4 4 7 67 76 3 932 1510 320 479 6 25124 30 8 10444 12022 14 5117 752 8838 5 9 271 157 25 52 30 20 308 6 4488 5 11 159 4 4 4 4 4 6 12 8050 14 311 11 219 7 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.417339 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.417436 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            "I1209 17:50:35.417525 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 13 27 28 29 34 44 45 53 54 55 56 57 80 81 114 115 116 117 118 0\n",
            "I1209 17:50:35.417594 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 13 27 28 29 34 44 45 53 54 55 56 57 80 81 114 115 116 117 118 0\n",
            "INFO:tensorflow:masked_lm_ids: 11676 2075 7930 1702 12450 67 88 9 364 3116 377 22567 2052 103 13339 146 2654 11666 101 0\n",
            "I1209 17:50:35.417656 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 11676 2075 7930 1702 12450 67 88 9 364 3116 377 22567 2052 103 13339 146 2654 11666 101 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.417721 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.417776 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.418227 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁repetidamente [MASK] [MASK] [MASK] [MASK] [MASK] ▁de ▁san co es ▁e con omi cas ▁para ▁com ▁os ▁pais es , [MASK] , ▁cidades ▁e ▁empresas ▁que ▁ou s am ▁critica r ▁a ▁sua [MASK] ▁MHz [MASK] ▁ao ▁Falun ▁Gong . ▁Isso ▁cria ▁um ▁medo , ▁um ▁medo ▁de ▁ser ▁deixado ▁de ▁fora ▁de ▁algum ▁ben ef icio ▁e con o mico , ▁o [SEP] [MASK] [MASK] co [MASK] ▁batalhas ▁de ▁mi dia ▁e ▁noticia ▁a ▁aplicar ▁a ▁auto c ens ura ▁na [MASK] ca [MASK] ▁das ▁viola co es ▁dos ▁direitos ▁humanos [MASK] ▁China , ▁for cado ▁cidades ▁de ▁certo [MASK] ▁de ▁pais es ▁a ▁rescindi r ▁seu ▁apoio ▁moral ▁as ▁vitima s , ▁e ▁a te ▁mesmo ▁co a gido ▁alguns ▁governos ▁de mo cra [SEP]\n",
            "I1209 17:50:35.418383 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁repetidamente [MASK] [MASK] [MASK] [MASK] [MASK] ▁de ▁san co es ▁e con omi cas ▁para ▁com ▁os ▁pais es , [MASK] , ▁cidades ▁e ▁empresas ▁que ▁ou s am ▁critica r ▁a ▁sua [MASK] ▁MHz [MASK] ▁ao ▁Falun ▁Gong . ▁Isso ▁cria ▁um ▁medo , ▁um ▁medo ▁de ▁ser ▁deixado ▁de ▁fora ▁de ▁algum ▁ben ef icio ▁e con o mico , ▁o [SEP] [MASK] [MASK] co [MASK] ▁batalhas ▁de ▁mi dia ▁e ▁noticia ▁a ▁aplicar ▁a ▁auto c ens ura ▁na [MASK] ca [MASK] ▁das ▁viola co es ▁dos ▁direitos ▁humanos [MASK] ▁China , ▁for cado ▁cidades ▁de ▁certo [MASK] ▁de ▁pais es ▁a ▁rescindi r ▁seu ▁apoio ▁moral ▁as ▁vitima s , ▁e ▁a te ▁mesmo ▁co a gido ▁alguns ▁governos ▁de mo cra [SEP]\n",
            "INFO:tensorflow:input_ids: 2 19273 4 4 4 4 4 6 7110 238 101 9 828 9224 1607 24 21 32 1480 101 5 4 5 891 9 1109 15 51 10 217 4488 41 8 38 4 13026 4 37 13566 10900 7 1473 2926 20 4280 5 20 4280 6 55 5265 6 527 6 1195 7670 8056 20013 9 828 52 5622 5 11 3 4 4 238 4 6848 6 3649 735 9 14784 8 9021 8 1338 180 4120 2167 25 4 228 4 53 10069 238 101 36 1167 1777 4 1316 5 728 7086 891 6 2185 4 6 1480 101 8 16988 41 44 782 3834 40 18876 10 5 9 8 204 88 431 49 13174 215 5878 6 320 3174 3\n",
            "I1209 17:50:35.418503 140365583124352 create_pretraining_data.py:197] input_ids: 2 19273 4 4 4 4 4 6 7110 238 101 9 828 9224 1607 24 21 32 1480 101 5 4 5 891 9 1109 15 51 10 217 4488 41 8 38 4 13026 4 37 13566 10900 7 1473 2926 20 4280 5 20 4280 6 55 5265 6 527 6 1195 7670 8056 20013 9 828 52 5622 5 11 3 4 4 238 4 6848 6 3649 735 9 14784 8 9021 8 1338 180 4120 2167 25 4 228 4 53 10069 238 101 36 1167 1777 4 1316 5 728 7086 891 6 2185 4 6 1480 101 8 16988 41 44 782 3834 40 18876 10 5 9 8 204 88 431 49 13174 215 5878 6 320 3174 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.418601 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I1209 17:50:35.418694 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1\n",
            "I1209 17:50:35.418782 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 3 4 5 6 21 34 35 36 65 66 67 68 69 83 84 85 93 101 0\n",
            "I1209 17:50:35.418848 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 2 3 4 5 6 21 34 35 36 65 66 67 68 69 83 84 85 93 101 0\n",
            "INFO:tensorflow:masked_lm_ids: 599 8 336 4306 10 1550 11148 228 52 577 153 238 101 7422 13911 228 52 25 19308 0\n",
            "I1209 17:50:35.418912 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 599 8 336 4306 10 1550 11148 228 52 577 153 238 101 7422 13911 228 52 25 19308 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "I1209 17:50:35.418978 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.419035 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.419464 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁De c lina ca o ▁pode ▁ser : [SEP] ▁Estende - se [MASK] ▁uma ▁a rea ▁de [MASK] , 98 ▁km [MASK] [SEP]\n",
            "I1209 17:50:35.516217 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁De c lina ca o ▁pode ▁ser : [SEP] ▁Estende - se [MASK] ▁uma ▁a rea ▁de [MASK] , 98 ▁km [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 167 180 2870 228 52 110 55 42 3 161 16 34 4 18 8 3711 6 4 5 3652 90 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.516510 140365583124352 create_pretraining_data.py:197] input_ids: 2 167 180 2870 228 52 110 55 42 3 161 16 34 4 18 8 3711 6 4 5 3652 90 4 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.516626 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.516731 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.516830 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 6 13 18 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.516906 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 6 13 18 22 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 110 26 268 133 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.516972 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 110 26 268 133 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:50:35.517041 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.517113 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.517627 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Sua ▁capital ▁e ▁a ▁cidade ▁de ▁Ai ja . [SEP] ▁Ai ja ▁e ▁uma ▁provi ncia ▁do ▁Peru ▁localizada ▁na ▁re gia o [MASK] [MASK] [MASK] [MASK] . [SEP]\n",
            "I1209 17:50:35.517753 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Sua ▁capital ▁e ▁a ▁cidade ▁de ▁Ai ja . [SEP] ▁Ai ja ▁e ▁uma ▁provi ncia ▁do ▁Peru ▁localizada ▁na ▁re gia o [MASK] [MASK] [MASK] [MASK] . [SEP]\n",
            "INFO:tensorflow:input_ids: 2 381 369 9 8 83 6 12610 740 7 3 12610 740 9 18 9629 4428 12 2569 429 25 172 2094 52 4 4 4 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.517876 140365583124352 create_pretraining_data.py:197] input_ids: 2 381 369 9 8 83 6 12610 740 7 3 12610 740 9 18 9629 4428 12 2569 429 25 172 2094 52 4 4 4 4 7 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.517974 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.518064 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.518152 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 24 25 26 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.518215 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 24 25 26 27 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 6 28 3970 1090 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.518276 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 6 28 3970 1090 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:50:35.518361 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I1209 17:50:35.518422 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I1209 17:50:35.518864 140365583124352 create_pretraining_data.py:185] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁Brachy cephal us [MASK] [MASK] [MASK] [MASK] ▁e ▁uma ▁espe cie ▁de ▁an fi bio ▁da ▁familia ▁Brachy cephal idae . [SEP] ▁End em ica [MASK] ▁Hetfield , ▁pode ▁ser ▁encontrada ▁apenas ▁na ▁Serra ▁de ▁fiel [MASK] ▁no ▁ mun ici pio ▁de ▁Nova ▁Friburgo , ▁no ▁estado ▁do ▁Rio ▁de ▁Janeiro . ▁Considera da [MASK] ▁sino ni mo ▁de ▁\" Bra chy cephal us ▁e phi pp ium [MASK] ▁em [MASK] [MASK] ▁foi ▁elevada ▁a ▁espe cie ▁distinta ▁em ▁2010. [SEP]\n",
            "I1209 17:50:35.519008 140365583124352 create_pretraining_data.py:187] tokens: [CLS] ▁Brachy cephal us [MASK] [MASK] [MASK] [MASK] ▁e ▁uma ▁espe cie ▁de ▁an fi bio ▁da ▁familia ▁Brachy cephal idae . [SEP] ▁End em ica [MASK] ▁Hetfield , ▁pode ▁ser ▁encontrada ▁apenas ▁na ▁Serra ▁de ▁fiel [MASK] ▁no ▁ mun ici pio ▁de ▁Nova ▁Friburgo , ▁no ▁estado ▁do ▁Rio ▁de ▁Janeiro . ▁Considera da [MASK] ▁sino ni mo ▁de ▁\" Bra chy cephal us ▁e phi pp ium [MASK] ▁em [MASK] [MASK] ▁foi ▁elevada ▁a ▁espe cie ▁distinta ▁em ▁2010. [SEP]\n",
            "INFO:tensorflow:input_ids: 2 25527 19398 339 4 4 4 4 9 18 8073 6686 6 6469 1456 3164 13 25717 25527 19398 1487 7 3 8786 136 1840 4 28948 5 110 55 2528 139 25 2886 6 6576 4 22 19 11095 5604 4945 6 260 14847 5 22 212 12 176 6 245 7 12721 62 4 12321 402 320 6 17 7172 8586 19398 339 9 4736 2304 5539 4 14 4 4 30 5007 8 8073 6686 10484 14 3499 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.519329 140365583124352 create_pretraining_data.py:197] input_ids: 2 25527 19398 339 4 4 4 4 9 18 8073 6686 6 6469 1456 3164 13 25717 25527 19398 1487 7 3 8786 136 1840 4 28948 5 110 55 2528 139 25 2886 6 6576 4 22 19 11095 5604 4945 6 260 14847 5 22 212 12 176 6 245 7 12721 62 4 12321 402 320 6 17 7172 8586 19398 339 9 4736 2304 5539 4 14 4 4 30 5007 8 8073 6686 10484 14 3499 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.519493 140365583124352 create_pretraining_data.py:197] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.519613 140365583124352 create_pretraining_data.py:197] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:token_boundary: 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.519711 140365583124352 create_pretraining_data.py:197] token_boundary: 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_positions: 4 5 6 7 26 27 36 37 56 70 72 73 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.519779 140365583124352 create_pretraining_data.py:197] masked_lm_positions: 4 5 6 7 26 27 36 37 56 70 72 73 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_ids: 6847 596 49 2976 12 94 2841 8303 20 27 6959 5 0 0 0 0 0 0 0 0\n",
            "I1209 17:50:35.519846 140365583124352 create_pretraining_data.py:197] masked_lm_ids: 6847 596 49 2976 12 94 2841 8303 20 27 6959 5 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "I1209 17:50:35.519912 140365583124352 create_pretraining_data.py:197] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I1209 17:50:35.520149 140365583124352 create_pretraining_data.py:197] next_sentence_labels: 0\n",
            "INFO:tensorflow:Wrote 251918 total instances\n",
            "I1209 17:50:58.137110 140591368152960 create_pretraining_data.py:202] Wrote 251918 total instances\n",
            "INFO:tensorflow:Wrote 277957 total instances\n",
            "I1209 17:52:11.995791 140365583124352 create_pretraining_data.py:202] Wrote 277957 total instances\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gdQEOzhYmSh",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Training the Model\n",
        "\n",
        "If you need to resume from an interrupted training, you may skip steps 2-5 and proceed from here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXAuzsJfYrio",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "a978f083-37f4-4ecc-804b-12a332a479de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "BUCKET_NAME = \"<Insert Bucket Name Here>\" # @param {type: \"string\"}\n",
        "\n",
        "MODEL_DIR = 'albert_cased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "\n",
        "# Input data pipeline config\n",
        "TRAIN_BATCH_SIZE = 256 #@param {type:\"integer\"}\n",
        "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
        "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
        "MASKED_LM_PROB = 0.15 #@param\n",
        "\n",
        "PRETRAINING_DIR = \"pretraining_data_{}\".format(MAX_SEQ_LENGTH)\n",
        "\n",
        "# Training procedure config\n",
        "EVAL_BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.00176\n",
        "TRAIN_STEPS = 175000 #@param {type:\"integer\"}\n",
        "SAVE_CHECKPOINTS_STEPS = 5000 #@param {type:\"integer\"}\n",
        "NUM_TPU_CORES = 8\n",
        "\n",
        "if BUCKET_NAME:\n",
        "  BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
        "else:\n",
        "  BUCKET_PATH = \".\"\n",
        "\n",
        "ALBERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
        "DATA_GCS_DIR = \"{}/{}\".format(ALBERT_GCS_DIR, PRETRAINING_DIR)\n",
        "\n",
        "CONFIG_FILE = os.path.join(ALBERT_GCS_DIR, \"albert_config.json\")\n",
        "\n",
        "INIT_CHECKPOINT = tf.train.latest_checkpoint(ALBERT_GCS_DIR)\n",
        "\n",
        "albert_config = modeling.AlbertConfig.from_json_file(CONFIG_FILE)\n",
        "input_files = tf.gfile.Glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
        "\n",
        "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
        "log.info(\"Using {} data shards\".format(len(input_files)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-09 19:24:57,946:  From ALBERT/modeling.py:115: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "2019-12-09 19:24:58,268:  Using checkpoint: None\n",
            "2019-12-09 19:24:58,274:  Using 4 data shards\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQTFjITdd53F",
        "colab_type": "text"
      },
      "source": [
        "Prepare the training run configuration, build the estimator and input function, power up the bass cannon."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMahsqUnZ55z",
        "colab_type": "code",
        "outputId": "ffca7d76-f6c4-46bc-ea4a-deade3542ded",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "from run_pretraining import input_fn_builder, model_fn_builder\n",
        "\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "      albert_config=albert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      learning_rate=LEARNING_RATE,\n",
        "      num_train_steps=TRAIN_STEPS,\n",
        "      num_warmup_steps=3125,\n",
        "      use_tpu=USE_TPU,\n",
        "      optimizer=\"lamb\",\n",
        "      poly_power=1.0,\n",
        "      start_warmup_step=0,\n",
        "      use_one_hot_embeddings=USE_TPU)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=ALBERT_GCS_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=USE_TPU,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE)\n",
        "  \n",
        "train_input_fn = input_fn_builder(\n",
        "        input_files=input_files,\n",
        "        max_seq_length=MAX_SEQ_LENGTH,\n",
        "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
        "        is_training=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-09 19:25:10,812:  Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f5c7a8df378>) includes params argument, but params are not passed to Estimator.\n",
            "2019-12-09 19:25:10,814:  Using config: {'_model_dir': 'gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 5000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.80.30.250:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "isolate_session_state: true\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5c7cefc6d8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.80.30.250:8470', '_evaluation_master': 'grpc://10.80.30.250:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=5000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f5c7ceffd68>}\n",
            "2019-12-09 19:25:10,815:  _TPUContext: eval_on_tpu True\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNt5ykopeIYB",
        "colab_type": "text"
      },
      "source": [
        "Fire!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrCuEbr6dv8U",
        "colab_type": "code",
        "outputId": "71f4a830-a017-4b78-97db-1020de42a2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-09 19:25:35,194:  Querying Tensorflow master (grpc://10.80.30.250:8470) for TPU system metadata.\n",
            "2019-12-09 19:25:35,210:  Found TPU system:\n",
            "2019-12-09 19:25:35,211:  *** Num TPU Cores: 8\n",
            "2019-12-09 19:25:35,211:  *** Num TPU Workers: 1\n",
            "2019-12-09 19:25:35,212:  *** Num TPU Cores Per Worker: 8\n",
            "2019-12-09 19:25:35,212:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13302816656652693886)\n",
            "2019-12-09 19:25:35,214:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5639868938437605861)\n",
            "2019-12-09 19:25:35,214:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 5966812053291465332)\n",
            "2019-12-09 19:25:35,215:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10829184446052066539)\n",
            "2019-12-09 19:25:35,215:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 13114995123616644068)\n",
            "2019-12-09 19:25:35,216:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 18354148548278109856)\n",
            "2019-12-09 19:25:35,217:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8835660790857004226)\n",
            "2019-12-09 19:25:35,217:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10551033671101366342)\n",
            "2019-12-09 19:25:35,218:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 11103052472234274174)\n",
            "2019-12-09 19:25:35,218:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6212258862365588052)\n",
            "2019-12-09 19:25:35,219:  *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5474076343057050441)\n",
            "2019-12-09 19:25:35,225:  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2019-12-09 19:25:35,227:  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "2019-12-09 19:25:35,238:  Calling model_fn.\n",
            "2019-12-09 19:25:35,240:  From ALBERT/run_pretraining.py:398: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "2019-12-09 19:25:35,246:  From ALBERT/run_pretraining.py:436: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "2019-12-09 19:25:35,247:  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "2019-12-09 19:25:35,273:  From ALBERT/run_pretraining.py:453: map_and_batch_with_legacy_function (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch()\n",
            "2019-12-09 19:25:35,338:  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "2019-12-09 19:25:35,450:  From ALBERT/run_pretraining.py:469: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2019-12-09 19:25:35,468:  <DatasetV1Adapter shapes: {input_ids: (32, 128), input_mask: (32, 128), masked_lm_ids: (32, 20), masked_lm_positions: (32, 20), masked_lm_weights: (32, 20), next_sentence_labels: (32, 1), segment_ids: (32, 128)}, types: {input_ids: tf.int32, input_mask: tf.int32, masked_lm_ids: tf.int32, masked_lm_positions: tf.int32, masked_lm_weights: tf.float32, next_sentence_labels: tf.int32, segment_ids: tf.int32}>\n",
            "2019-12-09 19:25:35,489:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,492:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,494:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,497:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,499:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,501:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,504:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,506:  Found small feature: next_sentence_labels [32, 1]\n",
            "2019-12-09 19:25:35,542:  *** Features ***\n",
            "2019-12-09 19:25:35,543:    name = input_ids, shape = (32, 128)\n",
            "2019-12-09 19:25:35,543:    name = input_mask, shape = (32, 128)\n",
            "2019-12-09 19:25:35,544:    name = masked_lm_ids, shape = (32, 20)\n",
            "2019-12-09 19:25:35,544:    name = masked_lm_positions, shape = (32, 20)\n",
            "2019-12-09 19:25:35,545:    name = masked_lm_weights, shape = (32, 20)\n",
            "2019-12-09 19:25:35,546:    name = next_sentence_labels, shape = (32, 1)\n",
            "2019-12-09 19:25:35,546:    name = segment_ids, shape = (32, 128)\n",
            "2019-12-09 19:25:35,547:  From ALBERT/modeling.py:193: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "2019-12-09 19:25:35,549:  From ALBERT/modeling.py:506: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "2019-12-09 19:25:35,581:  From ALBERT/modeling.py:587: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "2019-12-09 19:25:35,658:  From ALBERT/modeling.py:1024: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "2019-12-09 19:25:37,155:  From ALBERT/modeling.py:252: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "2019-12-09 19:25:37,158:  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "2019-12-09 19:25:37,292:  From ALBERT/run_pretraining.py:185: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "2019-12-09 19:25:37,293:  **** Trainable Variables ****\n",
            "2019-12-09 19:25:37,294:    name = bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "2019-12-09 19:25:37,295:    name = bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "2019-12-09 19:25:37,296:    name = bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "2019-12-09 19:25:37,296:    name = bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "2019-12-09 19:25:37,297:    name = bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "2019-12-09 19:25:37,298:    name = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "2019-12-09 19:25:37,298:    name = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "2019-12-09 19:25:37,299:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "2019-12-09 19:25:37,299:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "2019-12-09 19:25:37,300:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "2019-12-09 19:25:37,300:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "2019-12-09 19:25:37,301:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "2019-12-09 19:25:37,302:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "2019-12-09 19:25:37,302:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "2019-12-09 19:25:37,303:    name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "2019-12-09 19:25:37,303:    name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "2019-12-09 19:25:37,304:    name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "2019-12-09 19:25:37,305:    name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "2019-12-09 19:25:37,305:    name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "2019-12-09 19:25:37,306:    name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "2019-12-09 19:25:37,306:    name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "2019-12-09 19:25:37,307:    name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "2019-12-09 19:25:37,307:    name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "2019-12-09 19:25:37,308:    name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "2019-12-09 19:25:37,309:    name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "2019-12-09 19:25:37,309:    name = cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "2019-12-09 19:25:37,310:    name = cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "2019-12-09 19:25:37,311:    name = cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "2019-12-09 19:25:37,311:    name = cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "2019-12-09 19:25:37,312:    name = cls/predictions/output_bias:0, shape = (30000,)\n",
            "2019-12-09 19:25:37,312:    name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "2019-12-09 19:25:37,313:    name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "2019-12-09 19:25:37,313:  From ALBERT/optimization.py:32: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "2019-12-09 19:25:37,315:  From ALBERT/optimization.py:37: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "2019-12-09 19:25:37,328:  ++++++ warmup starts at step 0, for 3125 steps ++++++\n",
            "2019-12-09 19:25:37,341:  using lamb\n",
            "2019-12-09 19:25:37,586:  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "2019-12-09 19:25:42,792:  Create CheckpointSaverHook.\n",
            "2019-12-09 19:25:42,851:  Done calling model_fn.\n",
            "2019-12-09 19:25:44,856:  TPU job name worker\n",
            "2019-12-09 19:25:45,093:  Graph was finalized.\n",
            "2019-12-09 19:25:47,228:  Running local_init_op.\n",
            "2019-12-09 19:25:47,491:  Done running local_init_op.\n",
            "2019-12-09 19:25:52,212:  Saving checkpoints for 0 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 19:26:01,727:  From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "2019-12-09 19:26:02,361:  Initialized dataset iterators in 0 seconds\n",
            "2019-12-09 19:26:02,362:  Installing graceful shutdown hook.\n",
            "2019-12-09 19:26:02,368:  Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "2019-12-09 19:26:02,370:  Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "2019-12-09 19:26:02,374:  Init TPU system\n",
            "2019-12-09 19:26:09,873:  Initialized TPU in 7 seconds\n",
            "2019-12-09 19:26:09,875:  Starting infeed thread controller.\n",
            "2019-12-09 19:26:09,876:  Starting outfeed thread controller.\n",
            "2019-12-09 19:26:10,153:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 19:26:10,154:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 19:26:25,456:  Outfeed finished for iteration (0, 0)\n",
            "2019-12-09 19:27:25,468:  Outfeed finished for iteration (0, 432)\n",
            "2019-12-09 19:28:25,480:  Outfeed finished for iteration (0, 864)\n",
            "2019-12-09 19:29:25,493:  Outfeed finished for iteration (0, 1296)\n",
            "2019-12-09 19:30:25,506:  Outfeed finished for iteration (0, 1728)\n",
            "2019-12-09 19:31:25,519:  Outfeed finished for iteration (0, 2160)\n",
            "2019-12-09 19:32:25,532:  Outfeed finished for iteration (0, 2592)\n",
            "2019-12-09 19:33:25,544:  Outfeed finished for iteration (0, 3024)\n",
            "2019-12-09 19:34:25,556:  Outfeed finished for iteration (0, 3456)\n",
            "2019-12-09 19:35:25,569:  Outfeed finished for iteration (0, 3888)\n",
            "2019-12-09 19:36:25,582:  Outfeed finished for iteration (0, 4320)\n",
            "2019-12-09 19:37:25,594:  Outfeed finished for iteration (0, 4752)\n",
            "2019-12-09 19:38:00,079:  Saving checkpoints for 5000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 19:38:10,127:  loss = 5.791174, step = 5000\n",
            "2019-12-09 19:38:10,130:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 19:38:10,131:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 19:38:25,633:  Outfeed finished for iteration (1, 100)\n",
            "2019-12-09 19:39:25,675:  Outfeed finished for iteration (1, 532)\n",
            "2019-12-09 19:40:25,730:  Outfeed finished for iteration (1, 964)\n",
            "2019-12-09 19:41:25,778:  Outfeed finished for iteration (1, 1396)\n",
            "2019-12-09 19:42:25,821:  Outfeed finished for iteration (1, 1828)\n",
            "2019-12-09 19:43:25,860:  Outfeed finished for iteration (1, 2260)\n",
            "2019-12-09 19:44:25,895:  Outfeed finished for iteration (1, 2692)\n",
            "2019-12-09 19:45:25,930:  Outfeed finished for iteration (1, 3124)\n",
            "2019-12-09 19:46:25,960:  Outfeed finished for iteration (1, 3556)\n",
            "2019-12-09 19:47:25,990:  Outfeed finished for iteration (1, 3988)\n",
            "2019-12-09 19:48:26,018:  Outfeed finished for iteration (1, 4420)\n",
            "2019-12-09 19:49:26,045:  Outfeed finished for iteration (1, 4852)\n",
            "2019-12-09 19:49:46,599:  Saving checkpoints for 10000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 19:49:56,992:  loss = 3.9823773, step = 10000 (706.864 sec)\n",
            "2019-12-09 19:49:56,994:  global_step/sec: 7.07349\n",
            "2019-12-09 19:49:56,995:  examples/sec: 1810.81\n",
            "2019-12-09 19:49:56,997:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 19:49:56,998:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 19:50:26,056:  Outfeed finished for iteration (2, 208)\n",
            "2019-12-09 19:51:26,079:  Outfeed finished for iteration (2, 640)\n",
            "2019-12-09 19:52:26,102:  Outfeed finished for iteration (2, 1072)\n",
            "2019-12-09 19:53:26,124:  Outfeed finished for iteration (2, 1504)\n",
            "2019-12-09 19:54:26,146:  Outfeed finished for iteration (2, 1936)\n",
            "2019-12-09 19:55:26,167:  Outfeed finished for iteration (2, 2368)\n",
            "2019-12-09 19:56:26,188:  Outfeed finished for iteration (2, 2800)\n",
            "2019-12-09 19:57:26,208:  Outfeed finished for iteration (2, 3232)\n",
            "2019-12-09 19:58:26,230:  Outfeed finished for iteration (2, 3664)\n",
            "2019-12-09 19:59:26,251:  Outfeed finished for iteration (2, 4096)\n",
            "2019-12-09 20:00:26,271:  Outfeed finished for iteration (2, 4528)\n",
            "2019-12-09 20:01:26,292:  Outfeed finished for iteration (2, 4960)\n",
            "2019-12-09 20:01:31,879:  Saving checkpoints for 15000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 20:01:40,907:  loss = 4.578659, step = 15000 (703.915 sec)\n",
            "2019-12-09 20:01:40,909:  global_step/sec: 7.10312\n",
            "2019-12-09 20:01:40,910:  examples/sec: 1818.4\n",
            "2019-12-09 20:01:40,912:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 20:01:40,913:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 20:02:26,366:  Outfeed finished for iteration (3, 326)\n",
            "2019-12-09 20:03:26,384:  Outfeed finished for iteration (3, 758)\n",
            "2019-12-09 20:04:26,404:  Outfeed finished for iteration (3, 1190)\n",
            "2019-12-09 20:05:26,423:  Outfeed finished for iteration (3, 1622)\n",
            "2019-12-09 20:06:26,443:  Outfeed finished for iteration (3, 2054)\n",
            "2019-12-09 20:07:26,462:  Outfeed finished for iteration (3, 2486)\n",
            "2019-12-09 20:08:26,481:  Outfeed finished for iteration (3, 2918)\n",
            "2019-12-09 20:09:26,500:  Outfeed finished for iteration (3, 3350)\n",
            "2019-12-09 20:10:26,520:  Outfeed finished for iteration (3, 3782)\n",
            "2019-12-09 20:11:26,539:  Outfeed finished for iteration (3, 4214)\n",
            "2019-12-09 20:12:26,559:  Outfeed finished for iteration (3, 4646)\n",
            "2019-12-09 20:13:15,769:  Saving checkpoints for 20000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 20:13:26,194:  loss = 3.8479276, step = 20000 (705.287 sec)\n",
            "2019-12-09 20:13:26,196:  global_step/sec: 7.08931\n",
            "2019-12-09 20:13:26,198:  examples/sec: 1814.86\n",
            "2019-12-09 20:13:26,200:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 20:13:26,201:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 20:13:26,648:  Outfeed finished for iteration (4, 2)\n",
            "2019-12-09 20:14:26,663:  Outfeed finished for iteration (4, 434)\n",
            "2019-12-09 20:15:26,680:  Outfeed finished for iteration (4, 866)\n",
            "2019-12-09 20:16:26,697:  Outfeed finished for iteration (4, 1298)\n",
            "2019-12-09 20:17:26,712:  Outfeed finished for iteration (4, 1730)\n",
            "2019-12-09 20:18:26,729:  Outfeed finished for iteration (4, 2162)\n",
            "2019-12-09 20:19:26,745:  Outfeed finished for iteration (4, 2594)\n",
            "2019-12-09 20:20:26,762:  Outfeed finished for iteration (4, 3026)\n",
            "2019-12-09 20:21:26,778:  Outfeed finished for iteration (4, 3458)\n",
            "2019-12-09 20:22:26,795:  Outfeed finished for iteration (4, 3890)\n",
            "2019-12-09 20:23:26,812:  Outfeed finished for iteration (4, 4322)\n",
            "2019-12-09 20:24:26,828:  Outfeed finished for iteration (4, 4754)\n",
            "2019-12-09 20:25:01,034:  Saving checkpoints for 25000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 20:25:10,125:  From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "2019-12-09 20:25:13,730:  loss = 3.5323496, step = 25000 (707.535 sec)\n",
            "2019-12-09 20:25:13,732:  global_step/sec: 7.06678\n",
            "2019-12-09 20:25:13,733:  examples/sec: 1809.1\n",
            "2019-12-09 20:25:13,735:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 20:25:13,735:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 20:25:26,961:  Outfeed finished for iteration (5, 94)\n",
            "2019-12-09 20:26:26,978:  Outfeed finished for iteration (5, 526)\n",
            "2019-12-09 20:27:26,995:  Outfeed finished for iteration (5, 958)\n",
            "2019-12-09 20:28:27,013:  Outfeed finished for iteration (5, 1390)\n",
            "2019-12-09 20:29:27,030:  Outfeed finished for iteration (5, 1822)\n",
            "2019-12-09 20:30:27,047:  Outfeed finished for iteration (5, 2254)\n",
            "2019-12-09 20:31:27,064:  Outfeed finished for iteration (5, 2686)\n",
            "2019-12-09 20:32:27,081:  Outfeed finished for iteration (5, 3118)\n",
            "2019-12-09 20:33:27,098:  Outfeed finished for iteration (5, 3550)\n",
            "2019-12-09 20:34:27,116:  Outfeed finished for iteration (5, 3982)\n",
            "2019-12-09 20:35:27,133:  Outfeed finished for iteration (5, 4414)\n",
            "2019-12-09 20:36:27,150:  Outfeed finished for iteration (5, 4846)\n",
            "2019-12-09 20:36:48,572:  Saving checkpoints for 30000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 20:37:00,489:  loss = 4.231007, step = 30000 (706.759 sec)\n",
            "2019-12-09 20:37:00,491:  global_step/sec: 7.07455\n",
            "2019-12-09 20:37:00,492:  examples/sec: 1811.08\n",
            "2019-12-09 20:37:00,494:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 20:37:00,495:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 20:37:27,199:  Outfeed finished for iteration (6, 191)\n",
            "2019-12-09 20:38:27,217:  Outfeed finished for iteration (6, 623)\n",
            "2019-12-09 20:39:27,237:  Outfeed finished for iteration (6, 1055)\n",
            "2019-12-09 20:40:27,256:  Outfeed finished for iteration (6, 1487)\n",
            "2019-12-09 20:41:27,275:  Outfeed finished for iteration (6, 1919)\n",
            "2019-12-09 20:42:27,294:  Outfeed finished for iteration (6, 2351)\n",
            "2019-12-09 20:43:27,313:  Outfeed finished for iteration (6, 2783)\n",
            "2019-12-09 20:44:27,332:  Outfeed finished for iteration (6, 3215)\n",
            "2019-12-09 20:45:27,351:  Outfeed finished for iteration (6, 3647)\n",
            "2019-12-09 20:46:27,369:  Outfeed finished for iteration (6, 4079)\n",
            "2019-12-09 20:47:27,388:  Outfeed finished for iteration (6, 4511)\n",
            "2019-12-09 20:48:27,406:  Outfeed finished for iteration (6, 4943)\n",
            "2019-12-09 20:48:35,354:  Saving checkpoints for 35000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 20:48:47,492:  loss = 3.6379485, step = 35000 (707.004 sec)\n",
            "2019-12-09 20:48:47,495:  global_step/sec: 7.0721\n",
            "2019-12-09 20:48:47,496:  examples/sec: 1810.46\n",
            "2019-12-09 20:48:47,498:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 20:48:47,498:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 20:49:27,543:  Outfeed finished for iteration (7, 287)\n",
            "2019-12-09 20:50:27,560:  Outfeed finished for iteration (7, 719)\n",
            "2019-12-09 20:51:27,578:  Outfeed finished for iteration (7, 1151)\n",
            "2019-12-09 20:52:27,595:  Outfeed finished for iteration (7, 1583)\n",
            "2019-12-09 20:53:27,613:  Outfeed finished for iteration (7, 2015)\n",
            "2019-12-09 20:54:27,629:  Outfeed finished for iteration (7, 2447)\n",
            "2019-12-09 20:55:27,647:  Outfeed finished for iteration (7, 2879)\n",
            "2019-12-09 20:56:27,663:  Outfeed finished for iteration (7, 3311)\n",
            "2019-12-09 20:57:27,680:  Outfeed finished for iteration (7, 3743)\n",
            "2019-12-09 20:58:27,697:  Outfeed finished for iteration (7, 4175)\n",
            "2019-12-09 20:59:27,715:  Outfeed finished for iteration (7, 4607)\n",
            "2019-12-09 21:00:22,345:  Saving checkpoints for 40000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 21:00:33,092:  loss = 3.4216108, step = 40000 (705.599 sec)\n",
            "2019-12-09 21:00:33,094:  global_step/sec: 7.08617\n",
            "2019-12-09 21:00:33,095:  examples/sec: 1814.06\n",
            "2019-12-09 21:00:33,097:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 21:00:33,098:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 21:00:33,279:  Outfeed finished for iteration (8, 0)\n",
            "2019-12-09 21:01:33,298:  Outfeed finished for iteration (8, 432)\n",
            "2019-12-09 21:02:33,316:  Outfeed finished for iteration (8, 864)\n",
            "2019-12-09 21:03:33,335:  Outfeed finished for iteration (8, 1296)\n",
            "2019-12-09 21:04:33,354:  Outfeed finished for iteration (8, 1728)\n",
            "2019-12-09 21:05:33,372:  Outfeed finished for iteration (8, 2160)\n",
            "2019-12-09 21:06:33,391:  Outfeed finished for iteration (8, 2592)\n",
            "2019-12-09 21:07:33,409:  Outfeed finished for iteration (8, 3024)\n",
            "2019-12-09 21:08:33,427:  Outfeed finished for iteration (8, 3456)\n",
            "2019-12-09 21:09:33,446:  Outfeed finished for iteration (8, 3888)\n",
            "2019-12-09 21:10:33,464:  Outfeed finished for iteration (8, 4320)\n",
            "2019-12-09 21:11:33,483:  Outfeed finished for iteration (8, 4752)\n",
            "2019-12-09 21:12:07,973:  Saving checkpoints for 45000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 21:12:18,920:  loss = 3.5515437, step = 45000 (705.828 sec)\n",
            "2019-12-09 21:12:18,923:  global_step/sec: 7.08387\n",
            "2019-12-09 21:12:18,924:  examples/sec: 1813.47\n",
            "2019-12-09 21:12:18,925:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 21:12:18,926:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 21:12:33,535:  Outfeed finished for iteration (9, 104)\n",
            "2019-12-09 21:13:33,557:  Outfeed finished for iteration (9, 536)\n",
            "2019-12-09 21:14:33,580:  Outfeed finished for iteration (9, 968)\n",
            "2019-12-09 21:15:33,602:  Outfeed finished for iteration (9, 1400)\n",
            "2019-12-09 21:16:33,624:  Outfeed finished for iteration (9, 1832)\n",
            "2019-12-09 21:17:33,647:  Outfeed finished for iteration (9, 2264)\n",
            "2019-12-09 21:18:33,669:  Outfeed finished for iteration (9, 2696)\n",
            "2019-12-09 21:19:33,692:  Outfeed finished for iteration (9, 3128)\n",
            "2019-12-09 21:20:33,714:  Outfeed finished for iteration (9, 3560)\n",
            "2019-12-09 21:21:33,736:  Outfeed finished for iteration (9, 3992)\n",
            "2019-12-09 21:22:33,758:  Outfeed finished for iteration (9, 4424)\n",
            "2019-12-09 21:23:33,781:  Outfeed finished for iteration (9, 4856)\n",
            "2019-12-09 21:23:53,808:  Saving checkpoints for 50000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 21:24:03,634:  loss = 3.5128822, step = 50000 (704.714 sec)\n",
            "2019-12-09 21:24:03,636:  global_step/sec: 7.09508\n",
            "2019-12-09 21:24:03,637:  examples/sec: 1816.34\n",
            "2019-12-09 21:24:03,639:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 21:24:03,640:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 21:24:33,813:  Outfeed finished for iteration (10, 216)\n",
            "2019-12-09 21:25:33,835:  Outfeed finished for iteration (10, 648)\n",
            "2019-12-09 21:26:33,856:  Outfeed finished for iteration (10, 1080)\n",
            "2019-12-09 21:27:33,879:  Outfeed finished for iteration (10, 1512)\n",
            "2019-12-09 21:28:33,900:  Outfeed finished for iteration (10, 1944)\n",
            "2019-12-09 21:29:33,922:  Outfeed finished for iteration (10, 2376)\n",
            "2019-12-09 21:30:33,944:  Outfeed finished for iteration (10, 2808)\n",
            "2019-12-09 21:31:33,965:  Outfeed finished for iteration (10, 3240)\n",
            "2019-12-09 21:32:33,987:  Outfeed finished for iteration (10, 3672)\n",
            "2019-12-09 21:33:34,009:  Outfeed finished for iteration (10, 4104)\n",
            "2019-12-09 21:34:34,031:  Outfeed finished for iteration (10, 4536)\n",
            "2019-12-09 21:35:34,052:  Outfeed finished for iteration (10, 4968)\n",
            "2019-12-09 21:35:38,525:  Saving checkpoints for 55000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 21:35:51,224:  loss = 3.3327827, step = 55000 (707.590 sec)\n",
            "2019-12-09 21:35:51,227:  global_step/sec: 7.06623\n",
            "2019-12-09 21:35:51,228:  examples/sec: 1808.95\n",
            "2019-12-09 21:35:51,230:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 21:35:51,231:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 21:36:34,056:  Outfeed finished for iteration (11, 307)\n",
            "2019-12-09 21:37:34,078:  Outfeed finished for iteration (11, 739)\n",
            "2019-12-09 21:38:34,100:  Outfeed finished for iteration (11, 1171)\n",
            "2019-12-09 21:39:34,122:  Outfeed finished for iteration (11, 1603)\n",
            "2019-12-09 21:40:34,144:  Outfeed finished for iteration (11, 2035)\n",
            "2019-12-09 21:41:34,166:  Outfeed finished for iteration (11, 2467)\n",
            "2019-12-09 21:42:34,188:  Outfeed finished for iteration (11, 2899)\n",
            "2019-12-09 21:43:34,210:  Outfeed finished for iteration (11, 3331)\n",
            "2019-12-09 21:44:34,232:  Outfeed finished for iteration (11, 3763)\n",
            "2019-12-09 21:45:34,253:  Outfeed finished for iteration (11, 4195)\n",
            "2019-12-09 21:46:34,275:  Outfeed finished for iteration (11, 4627)\n",
            "2019-12-09 21:47:26,143:  Saving checkpoints for 60000 into gs://diego-feijo_datasets/albert_cased_L-12_H-768_A-12/model.ckpt.\n",
            "2019-12-09 21:47:36,613:  loss = 2.8672805, step = 60000 (705.389 sec)\n",
            "2019-12-09 21:47:36,615:  global_step/sec: 7.0883\n",
            "2019-12-09 21:47:36,616:  examples/sec: 1814.61\n",
            "2019-12-09 21:47:36,618:  Enqueue next (5000) batch(es) of data to infeed.\n",
            "2019-12-09 21:47:36,619:  Dequeue next (5000) batch(es) of data from outfeed.\n",
            "2019-12-09 21:47:36,775:  Outfeed finished for iteration (12, 0)\n",
            "2019-12-09 21:48:36,792:  Outfeed finished for iteration (12, 432)\n",
            "2019-12-09 21:49:36,809:  Outfeed finished for iteration (12, 864)\n",
            "2019-12-09 21:50:36,825:  Outfeed finished for iteration (12, 1296)\n",
            "2019-12-09 21:51:36,842:  Outfeed finished for iteration (12, 1728)\n",
            "2019-12-09 21:52:36,859:  Outfeed finished for iteration (12, 2160)\n",
            "2019-12-09 21:53:36,875:  Outfeed finished for iteration (12, 2592)\n",
            "2019-12-09 21:54:36,892:  Outfeed finished for iteration (12, 3024)\n",
            "2019-12-09 21:55:36,908:  Outfeed finished for iteration (12, 3456)\n",
            "2019-12-09 21:56:36,925:  Outfeed finished for iteration (12, 3888)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_OeXod-fHMT",
        "colab_type": "text"
      },
      "source": [
        "Training the model with the default parameters for 175k steps will take ~20 hours. \n",
        "\n",
        "In case the kernel is restarted, you may always continue training from the latest checkpoint. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ZIAAATfzdF",
        "colab_type": "text"
      },
      "source": [
        "This concludes the guide to pre-training BERT from scratch on a cloud TPU. However, the really fun stuff is still  to come, so stay tuned.\n",
        "\n",
        "Keep learning!"
      ]
    }
  ]
}